{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python3\n", "\"\"\" \n", "v30_transformer_decoupled_bottleneck_instrumented.py"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["One-file research Transformer that implements, in a runnable way:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["1) RoPE (rotary positional embeddings).\n", "2) KV-cache quantization (q8_0 / q4_0 / nf4) for generation/inference.\n", "3) Bottleneck and Decoupled Bottleneck attention:\n", "      score = (Q_sem \u00b7 K_sem^T) + (Q_geo \u00b7 K_geo^T)\n", "   with RoPE applied only on the geometric path."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\"Survive scale\" upgrades in this v30 variant:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  D) Training: gradient accumulation, gradient checkpointing, vectorized batch sampler,\n", "     mixed precision on CUDA/MPS/CPU (torch.amp), memory/timing dashboards (rich),\n", "     and lean optimizers (Lion) to push bigger models on modest hardware."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  A) Streaming (\"online softmax\") decode that dequantizes only small sequence blocks.\n", "  B) Optional fused GPU kernels (Triton, if installed).\n", "     - v23: 1-pass fused decode update (dequant + online-softmax update per block).\n", "     - v24: 2-pass \"FlashAttention-style\" split-K decode:\n", "            Pass 1: parallel partitions compute (m_i, l_i, O_i) per partition.\n", "            Pass 2: reduce partitions into a single (m, l, O) for the row.\n", "            This gives sequence-length parallelism (useful when you have 1 query token, huge KV)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  C) v25: Self-optimizing runtime tuning (optional).\n", "     - Online hill-climb / bucketed microbench to pick decode_block + fused mode.\n", "     - Tunable kernel launch params (BLOCK_N / num_warps / num_stages) via cache attributes.\n", "     - JSON persistence so the model 'remembers' what was fastest on a given GPU + shape."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Data format: whitespace-separated integer token IDs in a single file.\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse\n", "import math\n", "import os\n", "import time\n", "import json\n", "import sys\n", "import platform\n", "import datetime\n", "import traceback\n", "import contextlib\n", "from dataclasses import asdict, dataclass\n", "from typing import Any, Dict, Iterable, List, Literal, Optional, Tuple\n", "from pathlib import Path"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import tiktoken\n", "except ImportError:\n", "    tiktoken = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Optional: fused kernels via Triton.<br>\n", "This file runs without Triton; if you install it and run on CUDA, decode can use fused dequant+attn updates."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["TRITON_AVAILABLE = False\n", "try:\n", "    import triton  # type: ignore\n", "    import triton.language as tl  # type: ignore\n", "    TRITON_AVAILABLE = True\n", "except Exception:\n", "    triton = None  # type: ignore\n", "    tl = None  # type: ignore"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "Utils<br>\n", "-----------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pick_device(explicit: Optional[str] = None) -> torch.device:\n", "    if explicit:\n", "        return torch.device(explicit)\n", "    if torch.cuda.is_available():\n", "        return torch.device(\"cuda\")\n", "    if getattr(torch.backends, \"mps\", None) is not None and torch.backends.mps.is_available():\n", "        return torch.device(\"mps\")\n", "    return torch.device(\"cpu\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_seed(seed: int) -> None:\n", "    import random\n", "    random.seed(seed)\n", "    torch.manual_seed(seed)\n", "    if torch.cuda.is_available():\n", "        torch.cuda.manual_seed_all(seed)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "v25: Self-Optimizing Runtime Tuner (decode performance)<br>\n", "-----------------------------<br>\n", "<br>\n", "Motivation:<br>\n", "  - KV-cache bandwidth dominates long-context decode.<br>\n", "  - The \"best\" decode_block / fused kernel choice / launch params are *hardware-dependent*.<br>\n", "  - We treat these as runtime knobs and auto-pick them with a small, guardrailed microbench.<br>\n", "<br>\n", "Design:<br>\n", "  - Bucketed by prefix length (power-of-two) so we don't retune every token.<br>\n", "  - Optional \"online\" mode: occasionally probe a neighbor setting and keep it if faster.<br>\n", "  - JSON persistence (optional) so the script remembers the best plan per GPU + shape."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@dataclass\n", "class KVSelfOptConfig:\n", "    mode: Literal[\"none\", \"startup\", \"online\"] = \"none\"\n\n", "    # v26: which knobs to optimize.\n", "    #   - decode: decode_block, fused kernel choice, launch params (v25 behavior)\n", "    #   - cache : kv_residual length, quantization kinds, qblock sizes (startup only)\n", "    #   - all   : both\n", "    scope: Literal[\"decode\", \"cache\", \"all\"] = \"all\"\n\n", "    # ---------------------------\n", "    # Decode-plan tuning (v25)\n", "    # ---------------------------\n", "    # Candidate decode partition sizes (affects streaming decode slice size and split-K partition size).\n", "    decode_blocks: Tuple[int, ...] = (256, 512, 1024, 2048)\n", "    # Candidate Triton tile sizes (BLOCK_N). Only used for fused kernels.\n", "    block_ns: Tuple[int, ...] = (128,)\n", "    # Candidate launch params (only used for fused kernels).\n", "    warps: Tuple[int, ...] = (4, 8)\n", "    stages: Tuple[int, ...] = (2, 3)\n", "    warmup: int = 1\n", "    iters: int = 3\n\n", "    # online mode: at most once every N decode steps per bucket, try a neighbor and keep it if faster.\n", "    interval: int = 256\n", "    hysteresis: float = 0.03  # require >=3% improvement to switch\n", "    cache_path: Optional[str] = None\n", "    verbose: bool = False\n\n", "    # Optional correctness guardrail when comparing decode candidates (slow, but useful while bringing kernels up).\n", "    verify: bool = False\n", "    verify_tol: float = 5e-3\n\n", "    # ---------------------------\n", "    # Cache-policy tuning (v26)\n", "    # ---------------------------\n", "    # Candidate kv_residual hot-window lengths (fp16 ring) for quantized caches.\n", "    residuals: Tuple[int, ...] = (0, 32, 64, 128)\n", "    # Candidate quantization block sizes (qblock). For q4/nf4 we enforce evenness in make_quantspec().\n", "    qblocks: Tuple[int, ...] = (16, 32, 64)\n\n", "    # Candidate quantization kinds (decoupled only).\n", "    # These are ordered roughly from \"more compressed\" -> \"less compressed\".\n", "    k_sem_kinds: Tuple[\"KVCacheKind\", ...] = (\"q4_0\", \"nf4\", \"q8_0\", \"fp16\")\n", "    k_geo_kinds: Tuple[\"KVCacheKind\", ...] = (\"q8_0\", \"q4_0\", \"fp16\")\n", "    v_kinds: Tuple[\"KVCacheKind\", ...] = (\"q4_0\", \"q8_0\", \"fp16\")\n\n", "    # Memory budget for cache-policy tuning.\n", "    # If mem_budget_mb is None, we set a budget as: baseline(residual=0) * (1 + mem_overhead_frac).\n", "    mem_budget_mb: Optional[float] = None\n", "    mem_overhead_frac: float = 0.10  # 10% headroom by default (keeps memory-reduction objective intact)\n\n", "    # Policy tuning benchmark details\n", "    policy_prefix_len: Optional[int] = None  # if None, derived from prompt/max_seq buckets\n", "    policy_warmup: int = 1\n", "    policy_iters: int = 3\n", "    policy_hysteresis: float = 0.02          # accept >=2% speed improvement when adjusting policy\n", "    prefer_lower_mem_within: float = 0.02    # tie-break: if speed within 2%, prefer lower mem\n\n", "    # Optional quality guard for policy tuning (slow).\n", "    # Compares teacher-forced logits vs an fp16-cache baseline on a short calibration sequence.\n", "    policy_quality: bool = False\n", "    calib_tokens: Optional[str] = None   # whitespace-separated ints OR a path to a token file\n", "    calib_prefill: int = 128\n", "    calib_decode_steps: int = 32\n", "    quality_tol: float = 0.5             # max abs logit error vs fp16 baseline allowed (safety fuse)\n", "    # Defaults are intentionally conservative: this is a startup sanity check, not a full eval.\n", "    # 0.02 nats/token ~= 2% perplexity hit (because exp(0.02) ~= 1.0202).\n", "    quality_delta_nll_tol: Optional[float] = 0.02  # \u0394NLL (nats/token) allowed vs fp16 baseline\n", "    quality_ppl_ratio_tol: Optional[float] = 1.02  # ppl_cand / ppl_base allowed (exp(\u0394NLL))\n", "    quality_kl_tol: Optional[float] = None         # KL(p_base || p_cand) allowed (nats/token)\n", "    quality_compute_kl: bool = False               # compute KL even if no kl tol (for logging)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_token_ids_spec(spec: str) -> List[int]:\n", "    \"\"\"Load token IDs from either:\n", "      - a path to a file containing whitespace-separated ints\n", "      - a path to a .npy file (np.load)\n", "      - an inline whitespace-separated string of ints\n", "    \"\"\"\n", "    s = str(spec)\n", "    p = Path(s)\n", "    if os.path.exists(s):\n", "        if p.suffix == \".npy\":\n", "            try:\n", "                import numpy as _np  # type: ignore\n", "            except Exception as e:\n", "                raise RuntimeError(f\"numpy required to load .npy token files: {e}\")\n", "            arr = _np.load(str(p), mmap_mode=\"r\")\n", "            arr = _np.asarray(arr).reshape(-1)\n", "            # Ensure Python int compatibility / torch.long downstream.\n", "            if arr.dtype != _np.int64:\n", "                arr = arr.astype(_np.int64, copy=False)\n", "            return [int(x) for x in arr.tolist()]\n", "        raw = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n", "        return [int(t) for t in raw.strip().split() if t.strip()]\n", "    # Inline spec\n", "    return [int(t) for t in s.strip().split() if t.strip()]\n", "@dataclass\n", "class KVDecodePlan:\n", "    fused: str                    # \"none\" | \"triton1pass\" | \"triton2pass\"\n", "    decode_block: int\n\n", "    # Fused-kernel tunables (ignored for fused=\"none\")\n", "    block_n: int = 128\n", "    num_warps_1pass: int = 4\n", "    num_stages_1pass: int = 2\n", "    num_warps_part: int = 4\n", "    num_stages_part: int = 2\n", "    num_warps_reduce: int = 1\n", "    num_stages_reduce: int = 1\n", "    def apply_to_cache(self, cache: Any) -> None:\n", "        # Core knobs used by attention forward path\n", "        cache.decode_block = int(self.decode_block)\n", "        cache.fused = str(self.fused)\n\n", "        # Fused-kernel internal knobs (consumed inside the Triton wrappers).\n", "        cache.block_n = int(self.block_n)\n", "        cache.num_warps_1pass = int(self.num_warps_1pass)\n", "        cache.num_stages_1pass = int(self.num_stages_1pass)\n", "        cache.num_warps_part = int(self.num_warps_part)\n", "        cache.num_stages_part = int(self.num_stages_part)\n", "        cache.num_warps_reduce = int(self.num_warps_reduce)\n", "        cache.num_stages_reduce = int(self.num_stages_reduce)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _pow2_bucket(n: int) -> int:\n", "    # bucket 1,2,4,8,...; clamp n<=0 to 0\n", "    if n <= 0:\n", "        return 0\n", "    return 1 << (int(n - 1).bit_length())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _device_sig(device: torch.device) -> str:\n", "    if device.type == \"cuda\" and torch.cuda.is_available():\n", "        idx = device.index if device.index is not None else torch.cuda.current_device()\n", "        try:\n", "            name = torch.cuda.get_device_name(idx)\n", "        except Exception:\n", "            name = \"cuda\"\n", "        props = torch.cuda.get_device_properties(idx)\n", "        return f\"cuda:{idx}:{name}:cc{props.major}{props.minor}\"\n", "    return device.type"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KVDecodeSelfOptimizer:\n", "    \"\"\"Self-optimizes decode performance knobs per prefix-length bucket.\n", "    This is intentionally conservative:\n", "      - It only targets decode-time knobs (no model weight changes).\n", "      - It only activates for decoupled q4/q8/q4 KV caches when Triton is available.\n", "      - It can optionally verify candidate outputs against a baseline (slow).\n", "    \"\"\"\n", "    def __init__(\n", "        self,\n", "        cfg: KVSelfOptConfig,\n", "        *,\n", "        device: torch.device,\n", "        base_fused: str,\n", "        base_decode_block: int,\n", "        log_callback: Optional[Any] = None,\n", "    ):\n", "        self.cfg = cfg\n", "        self.device = device\n", "        self.base_fused = base_fused\n", "        self.base_decode_block = int(base_decode_block)\n", "        self.log_callback = log_callback\n", "        self._plans: Dict[str, KVDecodePlan] = {}\n", "        self._last_probe_step: Dict[str, int] = {}\n", "        self._step_counter: int = 0\n\n", "        # Persistence\n", "        self._cache_path = cfg.cache_path\n", "        if self._cache_path:\n", "            try:\n", "                if os.path.exists(self._cache_path):\n", "                    with open(self._cache_path, \"r\") as f:\n", "                        raw0 = json.load(f)\n", "                    # Back-compat:\n", "                    #   v25 wrote {key -> KVDecodePlan}\n", "                    #   v26 writes {\"version\": 26, \"decode_plans\": {key -> KVDecodePlan}, ...}\n", "                    raw = raw0.get(\"decode_plans\", raw0) if isinstance(raw0, dict) else {}\n", "                    if isinstance(raw, dict):\n", "                        for k, v in raw.items():\n", "                            self._plans[k] = KVDecodePlan(**v)\n", "            except Exception as e:\n", "                if cfg.verbose:\n", "                    print(f\"[selfopt] Failed to load cache '{self._cache_path}': {e}\")\n", "    def _save(self) -> None:\n", "        if not self._cache_path:\n", "            return\n", "        try:\n", "            os.makedirs(os.path.dirname(self._cache_path) or \".\", exist_ok=True)\n", "            decode_plans = {k: asdict(v) for k, v in self._plans.items()}\n\n", "            # Preserve other sections (e.g., cache policies) if the file already exists.\n", "            root: Dict[str, Any] = {\"version\": 26, \"decode_plans\": decode_plans}\n", "            if os.path.exists(self._cache_path):\n", "                try:\n", "                    with open(self._cache_path, \"r\") as f:\n", "                        prev = json.load(f)\n", "                    if isinstance(prev, dict):\n", "                        if \"decode_plans\" in prev:\n", "                            root = dict(prev)\n", "                            root[\"version\"] = 26\n", "                            root[\"decode_plans\"] = decode_plans\n", "                        else:\n", "                            # Older format: prev itself was the decode_plans mapping.\n", "                            root = {\"version\": 26, \"decode_plans\": decode_plans}\n", "                except Exception:\n", "                    pass\n", "            with open(self._cache_path, \"w\") as f:\n", "                json.dump(root, f, indent=2, sort_keys=True)\n", "        except Exception as e:\n", "            if self.cfg.verbose:\n", "                print(f\"[selfopt] Failed to save cache '{self._cache_path}': {e}\")\n", "    def _key(self, *, attn: Any, cache: Any, L_prefix: int) -> str:\n", "        # Key should be stable across runs on the same GPU/model.\n", "        bucket = _pow2_bucket(L_prefix)\n", "        # Capture the quantization policy in the signature (we only tune for q4/q8/q4 anyway).\n", "        try:\n", "            ksig = f\"ksem={cache.k_sem.kind},kgeo={cache.k_geo.kind},v={cache.v.kind}\"\n", "        except Exception:\n", "            ksig = \"kv=unknown\"\n", "        try:\n", "            dims = f\"H={attn.H},hd_sem={attn.sem_head_dim},hd_geo={attn.geo_head_dim},hd_v={attn.v_head_dim}\"\n", "        except Exception:\n", "            dims = \"dims=unknown\"\n", "        return f\"{_device_sig(self.device)}|{bucket}|{dims}|{ksig}\"\n", "    def _allowed_fused_modes(self, *, cache: Any) -> List[str]:\n", "        # Honor base_fused, but allow \"auto\" to explore.\n", "        if self.base_fused == \"none\":\n", "            return [\"none\"]\n", "        # If Triton isn't available, only streaming is possible.\n", "        if not _triton_decoupled_q4q8q4_available():\n", "            return [\"none\"]\n", "        # Only meaningful for the decoupled q4/q8/q4 policy.\n", "        ok = True\n", "        try:\n", "            ok = (cache.k_sem.kind == \"q4_0\" and cache.k_geo.kind == \"q8_0\" and cache.v.kind == \"q4_0\")\n", "        except Exception:\n", "            ok = False\n", "        if not ok:\n", "            return [\"none\"]\n", "        if self.base_fused in (\"triton1pass\", \"triton2pass\"):\n", "            return [self.base_fused]\n", "        # auto: allow exploring all, including streaming (sometimes wins for short prefixes).\n", "        return [\"none\", \"triton1pass\", \"triton2pass\"]\n", "    def _candidate_plans(self, *, cache: Any) -> List[KVDecodePlan]:\n", "        cfg = self.cfg\n", "        fused_modes = self._allowed_fused_modes(cache=cache)\n", "        decode_blocks = list(dict.fromkeys([self.base_decode_block, *cfg.decode_blocks]))\n", "        decode_blocks = [int(x) for x in decode_blocks if int(x) > 0]\n", "        decode_blocks.sort()\n", "        block_ns = [int(x) for x in cfg.block_ns if int(x) > 0]\n", "        if not block_ns:\n", "            block_ns = [128]\n", "        warps = [int(x) for x in cfg.warps if int(x) > 0]\n", "        if not warps:\n", "            warps = [4]\n", "        stages = [int(x) for x in cfg.stages if int(x) > 0]\n", "        if not stages:\n", "            stages = [2]\n", "        plans: List[KVDecodePlan] = []\n", "        for fused in fused_modes:\n", "            for db in decode_blocks:\n", "                if fused == \"none\":\n", "                    plans.append(KVDecodePlan(fused=\"none\", decode_block=db))\n", "                    continue\n", "                # Fused: explore a small menu of launch params.\n", "                for bn in block_ns:\n", "                    if db < bn:\n", "                        continue\n", "                    for w in warps:\n", "                        for st in stages:\n", "                            if fused == \"triton1pass\":\n", "                                plans.append(KVDecodePlan(\n", "                                    fused=fused,\n", "                                    decode_block=db,\n", "                                    block_n=bn,\n", "                                    num_warps_1pass=w,\n", "                                    num_stages_1pass=st,\n", "                                ))\n", "                            else:\n", "                                # 2-pass: tune partition pass mostly; keep reduce simple.\n", "                                plans.append(KVDecodePlan(\n", "                                    fused=fused,\n", "                                    decode_block=db,\n", "                                    block_n=bn,\n", "                                    num_warps_part=w,\n", "                                    num_stages_part=st,\n", "                                    num_warps_reduce=1,\n", "                                    num_stages_reduce=1,\n", "                                ))\n", "        return plans\n", "    def _time_ms(self, fn) -> float:\n", "        # Accurate GPU timing via CUDA events; CPU fallback to perf_counter.\n", "        if self.device.type == \"cuda\" and torch.cuda.is_available():\n", "            torch.cuda.synchronize(self.device)\n", "            start = torch.cuda.Event(enable_timing=True)\n", "            end = torch.cuda.Event(enable_timing=True)\n", "            start.record()\n", "            fn()\n", "            end.record()\n", "            torch.cuda.synchronize(self.device)\n", "            return float(start.elapsed_time(end))\n", "        else:\n", "            t0 = time.perf_counter()\n", "            fn()\n", "            return float((time.perf_counter() - t0) * 1000.0)\n", "    def _run_plan(\n", "        self,\n", "        *,\n", "        attn: Any,\n", "        cache: Any,\n", "        q_sem: torch.Tensor,\n", "        q_geo: torch.Tensor,\n", "        plan: KVDecodePlan,\n", "        sem_scale: float,\n", "        geo_scale: float,\n", "    ) -> torch.Tensor:\n", "        # Apply knobs for fused wrappers (block_n/warps/etc).\n", "        plan.apply_to_cache(cache)\n", "        if plan.fused == \"none\":\n", "            return attn._streaming_decode_attn_decoupled(\n", "                q_sem=q_sem,\n", "                q_geo=q_geo,\n", "                k_sem_cache=cache.k_sem,\n", "                k_geo_cache=cache.k_geo,\n", "                v_cache=cache.v,\n", "                sem_head_dim=attn.sem_head_dim,\n", "                geo_head_dim=attn.geo_head_dim,\n", "                v_head_dim=attn.v_head_dim,\n", "                decode_block=plan.decode_block,\n", "                sem_scale=sem_scale,\n", "                geo_scale=geo_scale,\n", "                k_sem_null=None,\n", "                k_geo_null=None,\n", "                v_null=None,\n", "            )\n", "        elif plan.fused == \"triton1pass\":\n", "            return attn._fused_decode_attn_decoupled_q4q8q4(\n", "                q_sem=q_sem,\n", "                q_geo=q_geo,\n", "                cache=cache,\n", "                sem_head_dim=attn.sem_head_dim,\n", "                geo_head_dim=attn.geo_head_dim,\n", "                v_head_dim=attn.v_head_dim,\n", "                decode_block=plan.decode_block,\n", "                sem_scale=sem_scale,\n", "                geo_scale=geo_scale,\n", "            )\n", "        elif plan.fused == \"triton2pass\":\n", "            return attn._fused_decode_attn_decoupled_q4q8q4_2pass(\n", "                q_sem=q_sem,\n", "                q_geo=q_geo,\n", "                cache=cache,\n", "                sem_head_dim=attn.sem_head_dim,\n", "                geo_head_dim=attn.geo_head_dim,\n", "                v_head_dim=attn.v_head_dim,\n", "                decode_block=plan.decode_block,\n", "                sem_scale=sem_scale,\n", "                geo_scale=geo_scale,\n", "            )\n", "        else:\n", "            raise ValueError(plan.fused)\n", "    def _bench_plan(\n", "        self,\n", "        *,\n", "        attn: Any,\n", "        cache: Any,\n", "        q_sem: torch.Tensor,\n", "        q_geo: torch.Tensor,\n", "        plan: KVDecodePlan,\n", "        sem_scale: float,\n", "        geo_scale: float,\n", "        baseline_out: Optional[torch.Tensor] = None,\n", "    ) -> float:\n", "        # Warmup for compilation + caches.\n", "        with torch.no_grad():\n", "            for _ in range(max(0, int(self.cfg.warmup))):\n", "                _ = self._run_plan(attn=attn, cache=cache, q_sem=q_sem, q_geo=q_geo, plan=plan, sem_scale=sem_scale, geo_scale=geo_scale)\n", "            if self.cfg.verify and baseline_out is not None:\n", "                out = self._run_plan(attn=attn, cache=cache, q_sem=q_sem, q_geo=q_geo, plan=plan, sem_scale=sem_scale, geo_scale=geo_scale)\n", "                err = (out.to(torch.float32) - baseline_out.to(torch.float32)).abs().max().item()\n", "                if err > float(self.cfg.verify_tol):\n", "                    # Treat as invalid plan by returning inf.\n", "                    if self.cfg.verbose:\n", "                        print(f\"[selfopt] reject plan {plan} (max_abs_err={err:.3e} > {self.cfg.verify_tol})\")\n", "                    return float(\"inf\")\n\n", "            # Timed runs.\n", "            times: List[float] = []\n", "            for _ in range(max(1, int(self.cfg.iters))):\n", "                def _call():\n", "                    _ = self._run_plan(attn=attn, cache=cache, q_sem=q_sem, q_geo=q_geo, plan=plan, sem_scale=sem_scale, geo_scale=geo_scale)\n", "                times.append(self._time_ms(_call))\n", "            return float(sum(times) / len(times))\n", "    def maybe_get_plan(self, *, attn: Any, cache: Any, L_prefix: int) -> Optional[KVDecodePlan]:\n", "        if self.cfg.mode == \"none\":\n", "            return None\n", "        self._step_counter += 1\n", "        k = self._key(attn=attn, cache=cache, L_prefix=L_prefix)\n\n", "        # If we already have a plan and we're not doing online probes, just return it.\n", "        if k in self._plans and self.cfg.mode == \"startup\":\n", "            return self._plans[k]\n\n", "        # Online mode: probe at most once per interval.\n", "        if k in self._plans and self.cfg.mode == \"online\":\n", "            last = self._last_probe_step.get(k, -10**9)\n", "            if (self._step_counter - last) < int(self.cfg.interval):\n", "                return self._plans[k]\n\n", "        # No plan yet, or time to probe/tune.\n", "        plans = self._candidate_plans(cache=cache)\n", "        if not plans:\n", "            return None\n\n", "        # Build a stable synthetic query (performance doesn't depend on values, but shape matters).\n", "        # Infer batch size from cache tensors (SeqCacheTensor doesn't store batch_size explicitly).\n", "        B = 1\n", "        try:\n", "            if getattr(cache, \"k_sem\", None) is not None:\n", "                ks = cache.k_sem\n", "                if getattr(ks, \"buf\", None) is not None:\n", "                    B = int(ks.buf.shape[0])\n", "                elif getattr(ks, \"q\", None) is not None:\n", "                    B = int(ks.q.shape[0])\n", "        except Exception:\n", "            B = 1\n", "        H = attn.H if hasattr(attn, \"H\") else 1\n", "        q_sem = torch.randn((B, H, 1, attn.sem_head_dim), device=self.device, dtype=torch.float16)\n", "        q_geo = torch.randn((B, H, 1, attn.geo_head_dim), device=self.device, dtype=torch.float16)\n", "        sem_scale = 1.0 / math.sqrt(float(attn.sem_head_dim))\n", "        geo_scale = 1.0 / math.sqrt(float(attn.geo_head_dim))\n\n", "        # Baseline for optional correctness check.\n", "        baseline_plan = self._plans.get(k, KVDecodePlan(fused=\"none\", decode_block=self.base_decode_block))\n", "        baseline_out = None\n", "        if self.cfg.verify:\n", "            try:\n", "                baseline_out = self._run_plan(attn=attn, cache=cache, q_sem=q_sem, q_geo=q_geo, plan=baseline_plan, sem_scale=sem_scale, geo_scale=geo_scale).detach()\n", "            except Exception:\n", "                baseline_out = None\n\n", "        # Choose the best plan by timing (and optional verify constraint).\n", "        best_plan: Optional[KVDecodePlan] = None\n", "        best_ms: float = float(\"inf\")\n", "        for p in plans:\n", "            try:\n", "                ms = self._bench_plan(attn=attn, cache=cache, q_sem=q_sem, q_geo=q_geo, plan=p, sem_scale=sem_scale, geo_scale=geo_scale, baseline_out=baseline_out)\n", "            except Exception as e:\n", "                if self.cfg.verbose:\n", "                    print(f\"[selfopt] plan failed {p}: {e}\")\n", "                ms = float(\"inf\")\n", "            if ms < best_ms:\n", "                best_ms = ms\n", "                best_plan = p\n\n", "        # Online: require hysteresis if we already had a plan.\n", "        if best_plan is not None and k in self._plans and self.cfg.mode == \"online\":\n", "            old = self._plans[k]\n", "            # Benchmark old quickly for fair comparison (1 iter).\n", "            try:\n", "                old_ms = self._bench_plan(attn=attn, cache=cache, q_sem=q_sem, q_geo=q_geo, plan=old, sem_scale=sem_scale, geo_scale=geo_scale, baseline_out=baseline_out)\n", "            except Exception:\n", "                old_ms = float(\"inf\")\n", "            if not (best_ms < old_ms * (1.0 - float(self.cfg.hysteresis))):\n", "                best_plan = old\n", "                best_ms = old_ms\n", "            self._last_probe_step[k] = self._step_counter\n", "        if best_plan is not None:\n", "            self._plans[k] = best_plan\n", "            self._save()\n", "            if self.cfg.verbose:\n", "                print(f\"[selfopt] bucket_key={k} -> {best_plan} ({best_ms:.3f} ms)\")\n", "            \n", "            if self.log_callback:\n", "                self.log_callback({\n", "                    \"type\": \"analysis\",\n", "                    \"subtype\": \"selfopt_decode\",\n", "                    \"bucket_key\": k,\n", "                    \"decode_block\": int(best_plan.decode_block),\n", "                    \"fused\": str(best_plan.fused),\n", "                    \"block_n\": int(best_plan.block_n),\n", "                    \"best_ms\": float(best_ms)\n", "                })\n", "        return best_plan"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "v26: Cache-policy self-optimizer<br>\n", "-----------------------------<br>\n", "<br>\n", "This targets the \"static\" knobs that materially affect *memory bandwidth* and *quantization error*:<br>\n", "  1) kv_residual hot-window length (fp16 tail in the cache)<br>\n", "  2) quantization kind itself (q4_0 vs nf4 vs q8_0 vs fp16)<br>\n", "  3) qblock sizes<br>\n", "and it does so while keeping the core project constraint front-and-center:<br>\n", "  - memory reduction is the primary objective (we constrain memory with a strict budget)<br>\n", "<br>\n", "Philosophy:<br>\n", "  - Hill-climb locally instead of brute-forcing a combinatorial explosion.<br>\n", "  - Each accepted move must *earn its keep* (>= policy_hysteresis improvement).<br>\n", "  - Hard memory budget; optional quality guard (teacher-forced logits)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@dataclass(frozen=True)\n", "class KVCachePolicy:\n", "    # Decoupled cache policy: K_sem, K_geo, V\n", "    k_sem_kind: \"KVCacheKind\"\n", "    k_geo_kind: \"KVCacheKind\"\n", "    v_kind: \"KVCacheKind\"\n", "    k_sem_qblock: int\n", "    k_geo_qblock: int\n", "    v_qblock: int\n", "    residual_len: int\n", "    def _residual_for(self, kind: \"KVCacheKind\") -> int:\n", "        return int(self.residual_len) if kind not in (\"fp16\", \"fp32\") else 0\n", "    def to_tensor_cfgs(self) -> Tuple[\"KVCacheTensorConfig\", \"KVCacheTensorConfig\", \"KVCacheTensorConfig\"]:\n", "        k_sem = KVCacheTensorConfig(kind=self.k_sem_kind, qblock=int(self.k_sem_qblock), residual_len=self._residual_for(self.k_sem_kind))\n", "        k_geo = KVCacheTensorConfig(kind=self.k_geo_kind, qblock=int(self.k_geo_qblock), residual_len=self._residual_for(self.k_geo_kind))\n", "        v = KVCacheTensorConfig(kind=self.v_kind, qblock=int(self.v_qblock), residual_len=self._residual_for(self.v_kind))\n", "        return k_sem, k_geo, v\n", "    def short(self) -> str:\n", "        return (\n", "            f\"ksem={self.k_sem_kind}@{self.k_sem_qblock},\"\n", "            f\"kgeo={self.k_geo_kind}@{self.k_geo_qblock},\"\n", "            f\"v={self.v_kind}@{self.v_qblock},\"\n", "            f\"resid={self.residual_len}\"\n", "        )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _is_quant(kind: \"KVCacheKind\") -> bool:\n", "    return kind not in (\"fp16\", \"fp32\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def estimate_seq_cache_bytes(*, batch_size: int, max_seq_len: int, dim: int, cfg: \"KVCacheTensorConfig\") -> int:\n", "    \"\"\"Rough-but-useful memory estimator for a SeqCacheTensor.\"\"\"\n", "    B = int(batch_size)\n", "    L = int(max_seq_len)\n", "    D = int(dim)\n", "    kind = str(cfg.kind)\n", "    if kind == \"fp16\":\n", "        return B * L * D * 2\n", "    if kind == \"fp32\":\n", "        return B * L * D * 4\n", "    spec = make_quantspec(cfg.kind, dim, cfg.qblock)\n\n", "    # Quantized buffers\n", "    if kind == \"q8_0\":\n", "        q_bytes = B * L * spec.pad_dim * 1\n", "        s_bytes = B * L * spec.n_blocks * 2\n", "    elif kind in (\"q4_0\", \"nf4\"):\n", "        q_bytes = B * L * (spec.pad_dim // 2) * 1\n", "        s_bytes = B * L * spec.n_blocks * 2\n", "    else:\n", "        raise ValueError(kind)\n\n", "    # fp16 residual tail (only allocated for quantized kinds)\n", "    rlen = int(max(0, cfg.residual_len))\n", "    r_eff = min(rlen, L)\n", "    r_bytes = B * r_eff * D * 2\n", "    return int(q_bytes + s_bytes + r_bytes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def estimate_decoupled_kvcache_bytes(\n", "    *,\n", "    n_layer: int,\n", "    batch_size: int,\n", "    max_seq_len: int,\n", "    sem_dim: int,\n", "    geo_dim: int,\n", "    v_dim: int,\n", "    policy: KVCachePolicy,\n", ") -> int:\n", "    k_sem_cfg, k_geo_cfg, v_cfg = policy.to_tensor_cfgs()\n", "    per_layer = (\n", "        estimate_seq_cache_bytes(batch_size=batch_size, max_seq_len=max_seq_len, dim=sem_dim, cfg=k_sem_cfg)\n", "        + estimate_seq_cache_bytes(batch_size=batch_size, max_seq_len=max_seq_len, dim=geo_dim, cfg=k_geo_cfg)\n", "        + estimate_seq_cache_bytes(batch_size=batch_size, max_seq_len=max_seq_len, dim=v_dim, cfg=v_cfg)\n", "    )\n", "    return int(n_layer) * int(per_layer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _as_mb(n_bytes: int) -> float:\n", "    return float(n_bytes) / (1024.0 * 1024.0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KVCachePolicySelfOptimizer:\n", "    \"\"\"Pick a cache policy that fits a strict memory budget and improves decode throughput.\n", "    This is used once at generation startup (because changing cache layouts mid-generation is expensive).\n", "    \"\"\"\n", "    def __init__(\n", "        self,\n", "        cfg: KVSelfOptConfig,\n", "        *,\n", "        device: torch.device,\n", "        attn: Any,\n", "        model_cfg: Any,\n", "        batch_size: int,\n", "        max_seq_len: int,\n", "        base_policy: KVCachePolicy,\n", "        base_decode_block: int,\n", "        base_fused: str,\n", "    ):\n", "        self.cfg = cfg\n", "        self.device = device\n", "        self.attn = attn\n", "        self.model_cfg = model_cfg\n", "        self.batch_size = int(batch_size)\n", "        self.max_seq_len = int(max_seq_len)\n", "        self.base_policy = base_policy\n", "        self.base_decode_block = int(base_decode_block)\n", "        self.base_fused = str(base_fused)\n\n", "        # Persistence piggy-backs on cfg.cache_path under \"cache_policies\" (optional).\n", "        self._cache_path = cfg.cache_path\n", "        self._policy_cache: Dict[str, Dict[str, Any]] = {}\n", "        if self._cache_path and os.path.exists(self._cache_path):\n", "            try:\n", "                with open(self._cache_path, \"r\") as f:\n", "                    root = json.load(f)\n", "                if isinstance(root, dict):\n", "                    self._policy_cache = dict(root.get(\"cache_policies\", {})) if isinstance(root.get(\"cache_policies\", {}), dict) else {}\n", "            except Exception:\n", "                self._policy_cache = {}\n", "    def _save_policy_cache(self) -> None:\n", "        if not self._cache_path:\n", "            return\n", "        try:\n", "            os.makedirs(os.path.dirname(self._cache_path) or \".\", exist_ok=True)\n", "            root: Dict[str, Any] = {\"version\": 26, \"cache_policies\": self._policy_cache}\n", "            # Preserve decode plans (and any other keys) if present.\n", "            if os.path.exists(self._cache_path):\n", "                try:\n", "                    with open(self._cache_path, \"r\") as f:\n", "                        prev = json.load(f)\n", "                    if isinstance(prev, dict):\n", "                        root = dict(prev)\n", "                        root[\"version\"] = 26\n", "                        root[\"cache_policies\"] = self._policy_cache\n", "                except Exception:\n", "                    pass\n", "            with open(self._cache_path, \"w\") as f:\n", "                json.dump(root, f, indent=2, sort_keys=True)\n", "        except Exception:\n", "            pass\n", "    def _policy_key(self) -> str:\n", "        # Bucket max_seq_len to avoid exploding cache keys.\n", "        max_bucket = _pow2_bucket(self.max_seq_len)\n", "        dims = f\"sem={self.model_cfg.sem_dim},geo={self.model_cfg.geo_dim},v={self.model_cfg.attn_dim},H={self.model_cfg.n_head}\"\n", "        return f\"{_device_sig(self.device)}|decoupled|max={max_bucket}|B={self.batch_size}|{dims}\"\n", "    def _budget_bytes(self) -> int:\n", "        if self.cfg.mem_budget_mb is not None:\n", "            return int(float(self.cfg.mem_budget_mb) * 1024.0 * 1024.0)\n", "        # Baseline = same kinds/qblocks as base_policy but with residual=0\n", "        base0 = KVCachePolicy(\n", "            k_sem_kind=self.base_policy.k_sem_kind,\n", "            k_geo_kind=self.base_policy.k_geo_kind,\n", "            v_kind=self.base_policy.v_kind,\n", "            k_sem_qblock=self.base_policy.k_sem_qblock,\n", "            k_geo_qblock=self.base_policy.k_geo_qblock,\n", "            v_qblock=self.base_policy.v_qblock,\n", "            residual_len=0,\n", "        )\n", "        base_bytes = estimate_decoupled_kvcache_bytes(\n", "            n_layer=self.model_cfg.n_layer,\n", "            batch_size=self.batch_size,\n", "            max_seq_len=self.max_seq_len,\n", "            sem_dim=self.model_cfg.sem_dim,\n", "            geo_dim=self.model_cfg.geo_dim,\n", "            v_dim=self.model_cfg.attn_dim,\n", "            policy=base0,\n", "        )\n", "        return int(base_bytes * (1.0 + float(self.cfg.mem_overhead_frac)))\n", "    def _supports_fused_q4q8q4(self, policy: KVCachePolicy) -> bool:\n", "        if not _triton_decoupled_q4q8q4_available():\n", "            return False\n", "        # Only the q4/q8/q4 + qblock=32 specialization is implemented in Triton in this file.\n", "        return (\n", "            str(policy.k_sem_kind) == \"q4_0\"\n", "            and str(policy.k_geo_kind) == \"q8_0\"\n", "            and str(policy.v_kind) == \"q4_0\"\n", "            and int(policy.k_sem_qblock) == 32\n", "            and int(policy.k_geo_qblock) == 32\n", "            and int(policy.v_qblock) == 32\n", "            and (not getattr(self.attn.cfg, \"null_attn\", False))\n", "            and (self.device.type == \"cuda\")\n", "        )\n", "    def _bench_policy_ms(self, policy: KVCachePolicy, *, L_prefix: int) -> float:\n", "        \"\"\"Benchmark 1 decode attention op for the first layer (proxy for full model).\"\"\"\n", "        B = self.batch_size\n", "        H = int(getattr(self.attn, \"H\", self.model_cfg.n_head))\n", "        sem_hd = int(getattr(self.attn, \"sem_head_dim\", self.model_cfg.sem_dim // H))\n", "        geo_hd = int(getattr(self.attn, \"geo_head_dim\", self.model_cfg.geo_dim // H))\n", "        v_hd = int(getattr(self.attn, \"v_head_dim\", self.model_cfg.attn_dim // H))\n\n", "        # Build dummy cache (one layer).\n", "        k_sem_cfg, k_geo_cfg, v_cfg = policy.to_tensor_cfgs()\n", "        cache = DecoupledLayerKVCache(\n", "            batch_size=B,\n", "            max_seq_len=L_prefix + 1,\n", "            k_sem_dim=self.model_cfg.sem_dim,\n", "            k_geo_dim=self.model_cfg.geo_dim,\n", "            v_dim=self.model_cfg.attn_dim,\n", "            k_sem_cfg=k_sem_cfg,\n", "            k_geo_cfg=k_geo_cfg,\n", "            v_cfg=v_cfg,\n", "            device=self.device,\n", "        )\n", "        cache.decode_block = self.base_decode_block\n", "        cache.fused = \"none\"\n\n", "        # Fill with random KV so the decode path actually reads cache memory.\n", "        with torch.no_grad():\n", "            k_sem = torch.randn((B, L_prefix, self.model_cfg.sem_dim), device=self.device, dtype=torch.float16)\n", "            k_geo = torch.randn((B, L_prefix, self.model_cfg.geo_dim), device=self.device, dtype=torch.float16)\n", "            v = torch.randn((B, L_prefix, self.model_cfg.attn_dim), device=self.device, dtype=torch.float16)\n", "            cache.append(k_sem, k_geo, v)\n", "        q_sem = torch.randn((B, H, 1, sem_hd), device=self.device, dtype=torch.float16)\n", "        q_geo = torch.randn((B, H, 1, geo_hd), device=self.device, dtype=torch.float16)\n", "        sem_scale = 1.0 / math.sqrt(float(sem_hd))\n", "        geo_scale = 1.0 / math.sqrt(float(geo_hd))\n\n", "        # Decide which decode kernel(s) to consider for this policy.\n", "        # We only do a tiny selection here; the full decode-tuner still runs later.\n", "        fused_menu: List[str]\n", "        if self.base_fused in (\"triton1pass\", \"triton2pass\"):\n", "            fused_menu = [self.base_fused]\n", "        elif self.base_fused == \"none\":\n", "            fused_menu = [\"none\"]\n", "        else:\n", "            # auto\n", "            fused_menu = [\"none\"]\n", "            if self._supports_fused_q4q8q4(policy):\n", "                fused_menu += [\"triton1pass\", \"triton2pass\"]\n\n", "        # Use decode_block candidates only when the user enabled decode tuning; else just base.\n", "        decode_blocks = (self.cfg.decode_blocks if self.cfg.scope in (\"decode\", \"all\") else (self.base_decode_block,))\n", "        decode_blocks = tuple(int(x) for x in decode_blocks if int(x) > 0)\n\n", "        # Time all candidates and take the best.\n", "        best = float(\"inf\")\n", "        # We can reuse the decode tuner timing helper.\n", "        tuner = KVDecodeSelfOptimizer(\n", "            KVSelfOptConfig(\n", "                mode=\"startup\",\n", "                scope=\"decode\",\n", "                decode_blocks=decode_blocks,\n", "                block_ns=self.cfg.block_ns,\n", "                warps=self.cfg.warps,\n", "                stages=self.cfg.stages,\n", "                warmup=max(0, int(self.cfg.policy_warmup)),\n", "                iters=max(1, int(self.cfg.policy_iters)),\n", "                interval=self.cfg.interval,\n", "                hysteresis=self.cfg.hysteresis,\n", "                cache_path=None,\n", "                verbose=False,\n", "                verify=False,\n", "                verify_tol=self.cfg.verify_tol,\n", "            ),\n", "            device=self.device,\n", "            base_fused=\"auto\",  # allow selection among fused_menu below via plan filtering\n", "            base_decode_block=self.base_decode_block,\n", "        )\n\n", "        # Hack: restrict fused modes by temporarily overriding base_fused.\n", "        tuner.base_fused = \"auto\"\n", "        for fused in fused_menu:\n", "            for db in decode_blocks:\n", "                plan = KVDecodePlan(fused=fused, decode_block=db)\n", "                try:\n", "                    # Apply plan knobs to the cache\n", "                    plan.apply_to_cache(cache)\n", "                    ms = tuner._bench_plan(\n", "                        attn=self.attn,\n", "                        cache=cache,\n", "                        q_sem=q_sem,\n", "                        q_geo=q_geo,\n", "                        plan=plan,\n", "                        sem_scale=sem_scale,\n", "                        geo_scale=geo_scale,\n", "                        baseline_out=None,\n", "                    )\n", "                except Exception:\n", "                    ms = float(\"inf\")\n", "                if ms < best:\n", "                    best = ms\n", "        return float(best)\n", "    def _neighbors(self, p: KVCachePolicy) -> List[KVCachePolicy]:\n", "        cfg = self.cfg\n\n", "        # Candidate lists (dedup + sorted for numeric fields).\n", "        resid_cands = sorted({int(x) for x in cfg.residuals if int(x) >= 0})\n", "        qb_cands = sorted({int(x) for x in cfg.qblocks if int(x) > 0})\n", "        def neigh_num(cur: int, cands: List[int]) -> List[int]:\n", "            if cur not in cands:\n", "                cands = sorted(set(cands + [cur]))\n", "            i = cands.index(cur)\n", "            out = []\n", "            if i - 1 >= 0:\n", "                out.append(cands[i - 1])\n", "            if i + 1 < len(cands):\n", "                out.append(cands[i + 1])\n", "            return out\n\n", "        # Kinds\n", "        def neigh_kind(cur: str, cands: Tuple[str, ...]) -> List[str]:\n", "            c = [str(x) for x in cands]\n", "            if cur not in c:\n", "                c = list(dict.fromkeys([cur] + c))\n", "            i = c.index(cur)\n", "            out = []\n", "            if i - 1 >= 0:\n", "                out.append(c[i - 1])\n", "            if i + 1 < len(c):\n", "                out.append(c[i + 1])\n", "            return out\n", "        out: List[KVCachePolicy] = []\n\n", "        # Residual\n", "        for r in neigh_num(int(p.residual_len), resid_cands):\n", "            out.append(KVCachePolicy(\n", "                k_sem_kind=p.k_sem_kind, k_geo_kind=p.k_geo_kind, v_kind=p.v_kind,\n", "                k_sem_qblock=p.k_sem_qblock, k_geo_qblock=p.k_geo_qblock, v_qblock=p.v_qblock,\n", "                residual_len=r,\n", "            ))\n\n", "        # qblock: keep them tied for now (simplifies fused compatibility)\n", "        for qb in neigh_num(int(p.k_sem_qblock), qb_cands):\n", "            out.append(KVCachePolicy(\n", "                k_sem_kind=p.k_sem_kind, k_geo_kind=p.k_geo_kind, v_kind=p.v_kind,\n", "                k_sem_qblock=qb, k_geo_qblock=qb, v_qblock=qb,\n", "                residual_len=p.residual_len,\n", "            ))\n\n", "        # kind tweaks (one tensor at a time)\n", "        for k in neigh_kind(str(p.k_sem_kind), cfg.k_sem_kinds):\n", "            out.append(KVCachePolicy(\n", "                k_sem_kind=k, k_geo_kind=p.k_geo_kind, v_kind=p.v_kind,\n", "                k_sem_qblock=p.k_sem_qblock, k_geo_qblock=p.k_geo_qblock, v_qblock=p.v_qblock,\n", "                residual_len=p.residual_len,\n", "            ))\n", "        for k in neigh_kind(str(p.k_geo_kind), cfg.k_geo_kinds):\n", "            out.append(KVCachePolicy(\n", "                k_sem_kind=p.k_sem_kind, k_geo_kind=k, v_kind=p.v_kind,\n", "                k_sem_qblock=p.k_sem_qblock, k_geo_qblock=p.k_geo_qblock, v_qblock=p.v_qblock,\n", "                residual_len=p.residual_len,\n", "            ))\n", "        for k in neigh_kind(str(p.v_kind), cfg.v_kinds):\n", "            out.append(KVCachePolicy(\n", "                k_sem_kind=p.k_sem_kind, k_geo_kind=p.k_geo_kind, v_kind=k,\n", "                k_sem_qblock=p.k_sem_qblock, k_geo_qblock=p.k_geo_qblock, v_qblock=p.v_qblock,\n", "                residual_len=p.residual_len,\n", "            ))\n\n", "        # Dedup\n", "        uniq = []\n", "        seen = set()\n", "        for cand in out:\n", "            key = cand.short()\n", "            if key not in seen:\n", "                seen.add(key)\n", "                uniq.append(cand)\n", "        return uniq\n", "    def choose_policy(self, *, prompt_len: int) -> KVCachePolicy:\n", "        \"\"\"Return the chosen policy (may be base_policy).\"\"\"\n", "        if self.cfg.mode == \"none\":\n", "            return self.base_policy\n\n", "        # Only meaningful for decoupled attention in this file.\n", "        if getattr(self.model_cfg, \"attn_mode\", \"standard\") != \"decoupled\":\n", "            return self.base_policy\n", "        key = self._policy_key()\n", "        if key in self._policy_cache:\n", "            try:\n", "                p = self._policy_cache[key]\n", "                policy = KVCachePolicy(**p)\n", "                if self.cfg.verbose:\n", "                    print(f\"[selfopt] cache-policy hit {key} -> {policy.short()}\")\n", "                return policy\n", "            except Exception:\n", "                pass\n\n", "        # Pick a representative prefix length for benchmarking.\n", "        if self.cfg.policy_prefix_len is not None:\n", "            L = int(self.cfg.policy_prefix_len)\n", "        else:\n", "            # Favor \"interesting\" long contexts without going beyond max_seq_len.\n", "            # If prompt is short, still benchmark at 1024 so we tune for the regime where KV dominates.\n", "            L = int(min(self.max_seq_len - 1, max(1024, _pow2_bucket(prompt_len))))\n", "        L = max(1, min(L, self.max_seq_len - 1))\n", "        budget = self._budget_bytes()\n", "        if self.cfg.verbose:\n", "            base_mem = estimate_decoupled_kvcache_bytes(\n", "                n_layer=self.model_cfg.n_layer, batch_size=self.batch_size, max_seq_len=self.max_seq_len,\n", "                sem_dim=self.model_cfg.sem_dim, geo_dim=self.model_cfg.geo_dim, v_dim=self.model_cfg.attn_dim,\n", "                policy=self.base_policy,\n", "            )\n", "            print(f\"[selfopt] cache-policy budget: { _as_mb(budget):.1f} MB \"\n", "                  f\"(base={_as_mb(base_mem):.1f} MB, max_seq={self.max_seq_len}, B={self.batch_size})\")\n", "        def mem_bytes(pol: KVCachePolicy) -> int:\n", "            return estimate_decoupled_kvcache_bytes(\n", "                n_layer=self.model_cfg.n_layer,\n", "                batch_size=self.batch_size,\n", "                max_seq_len=self.max_seq_len,\n", "                sem_dim=self.model_cfg.sem_dim,\n", "                geo_dim=self.model_cfg.geo_dim,\n", "                v_dim=self.model_cfg.attn_dim,\n", "                policy=pol,\n", "            )\n", "        def ok_mem(pol: KVCachePolicy) -> bool:\n", "            return mem_bytes(pol) <= budget\n\n", "        # Start from base_policy but clamp to candidate sets (if base is outside).\n", "        cur = self.base_policy\n", "        best = cur\n", "        best_ms = float(\"inf\")\n\n", "        # If base violates budget, forcibly drop residual first (never hurts memory objective).\n", "        if not ok_mem(cur):\n", "            cur = KVCachePolicy(\n", "                k_sem_kind=cur.k_sem_kind, k_geo_kind=cur.k_geo_kind, v_kind=cur.v_kind,\n", "                k_sem_qblock=cur.k_sem_qblock, k_geo_qblock=cur.k_geo_qblock, v_qblock=cur.v_qblock,\n", "                residual_len=0,\n", "            )\n\n", "        # Evaluate base.\n", "        try:\n", "            best_ms = self._bench_policy_ms(cur, L_prefix=L)\n", "            best = cur\n", "        except Exception:\n", "            best_ms = float(\"inf\")\n", "            best = cur\n", "        improved = True\n", "        while improved:\n", "            improved = False\n", "            candidates = [p for p in self._neighbors(best) if ok_mem(p)]\n", "            if not candidates:\n", "                break\n\n", "            # Evaluate all neighbors and pick the best improvement.\n", "            scored: List[Tuple[float, int, KVCachePolicy]] = []\n", "            for p in candidates:\n", "                try:\n", "                    ms = self._bench_policy_ms(p, L_prefix=L)\n", "                except Exception:\n", "                    ms = float(\"inf\")\n", "                scored.append((ms, mem_bytes(p), p))\n", "            scored.sort(key=lambda x: (x[0], x[1]))\n", "            for ms, mb, p in scored:\n", "                # Accept only real improvements (hysteresis).\n", "                if ms < best_ms * (1.0 - float(self.cfg.policy_hysteresis)):\n", "                    if self.cfg.verbose:\n", "                        print(f\"[selfopt] cache-policy step: {best.short()} -> {p.short()} \"\n", "                              f\"({best_ms:.3f}ms -> {ms:.3f}ms, mem={_as_mb(mb):.1f}MB)\")\n", "                    best = p\n", "                    best_ms = ms\n", "                    improved = True\n", "                    break\n\n", "        # Tie-break: if within prefer_lower_mem_within, choose lower-memory policy.\n", "        # This makes the tuner \"memory-first\" when speed differences are small.\n", "        if self.cfg.prefer_lower_mem_within > 0 and best_ms < float(\"inf\"):\n", "            cur_ms = best_ms\n", "            cur_mem = mem_bytes(best)\n", "            # Consider immediate neighbors only to keep it cheap.\n", "            for p in [p for p in self._neighbors(best) if ok_mem(p)]:\n", "                try:\n", "                    ms = self._bench_policy_ms(p, L_prefix=L)\n", "                except Exception:\n", "                    continue\n", "                if ms <= cur_ms * (1.0 + float(self.cfg.prefer_lower_mem_within)):\n", "                    m = mem_bytes(p)\n", "                    if m < cur_mem:\n", "                        if self.cfg.verbose:\n", "                            print(f\"[selfopt] cache-policy tie-break: {best.short()} -> {p.short()} \"\n", "                                  f\"(ms={ms:.3f} within {self.cfg.prefer_lower_mem_within*100:.1f}%, \"\n", "                                  f\"mem {_as_mb(cur_mem):.1f}MB -> {_as_mb(m):.1f}MB)\")\n", "                        best = p\n", "                        cur_mem = m\n\n", "        # Persist.\n", "        self._policy_cache[key] = asdict(best)\n", "        self._save_policy_cache()\n", "        if self.cfg.verbose:\n", "            print(f\"[selfopt] cache-policy chosen: {best.short()} @ L={L} (best_ms={best_ms:.3f}ms)\")\n", "        return best\n", "# -----------------------------\n", "# Tokenizer (fallback for raw text)\n", "# -----------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class WordTokenizer:\n", "    \"\"\"\n", "    Minimal word-level tokenizer from v20:\n", "      - splits on whitespace\n", "      - inserts <eos> at end of each non-empty line (preserves boundaries)\n", "      - uses <unk> for OOV\n", "    \"\"\"\n", "    def __init__(self, stoi: Dict[str, int], itos: List[str], unk: str = \"<unk>\", eos: str = \"<eos>\"):\n", "        self.stoi = stoi\n", "        self.itos = itos\n", "        self.unk = unk\n", "        self.eos = eos\n", "        self.unk_id = int(stoi[unk])\n", "        self.eos_id = int(stoi[eos])\n", "    @staticmethod\n", "    def _line_to_tokens(line: str) -> List[str]:\n", "        # WikiText-2 uses a lot of formatting; whitespace tokenization keeps it simple and reproducible.\n", "        toks = line.strip().split()\n", "        return toks\n", "    @classmethod\n", "    def build_from_train_text(cls, train_text: str, extra_specials: Optional[List[str]] = None) -> \"WordTokenizer\":\n", "        extra_specials = extra_specials or []\n", "        vocab = {}\n", "        def add(tok: str):\n", "            if tok not in vocab:\n", "                vocab[tok] = 1\n", "            else:\n", "                vocab[tok] += 1\n\n", "        # special tokens first\n", "        specials = [\"<unk>\", \"<eos>\"] + [t for t in extra_specials if t not in (\"<unk>\", \"<eos>\")]\n", "        for s in specials:\n", "            add(s)\n", "        for line in train_text.splitlines():\n", "            toks = cls._line_to_tokens(line)\n", "            if not toks:\n", "                continue\n", "            for t in toks:\n", "                add(t)\n", "            add(\"<eos>\")\n\n", "        # deterministic ordering: specials first, then alpha by token\n", "        vocab_tokens = [t for t in vocab.keys() if t not in specials]\n", "        vocab_tokens.sort()\n", "        itos = specials + vocab_tokens\n", "        stoi = {t: i for i, t in enumerate(itos)}\n", "        return cls(stoi=stoi, itos=itos)\n", "    def encode_text(self, text: str) -> List[int]:\n", "        ids: List[int] = []\n", "        for line in text.splitlines():\n", "            toks = self._line_to_tokens(line)\n", "            if not toks:\n", "                continue\n", "            for t in toks:\n", "                ids.append(self.stoi.get(t, self.unk_id))\n", "            ids.append(self.eos_id)\n", "        return ids\n", "    def decode_ids(self, ids: Iterable[int]) -> str:\n", "        out = []\n", "        for i in ids:\n", "            tok = self.itos[int(i)] if 0 <= int(i) < len(self.itos) else self.unk\n", "            if tok == self.eos:\n", "                out.append(\"\\n\")\n", "            else:\n", "                out.append(tok)\n", "        return \" \".join(out).replace(\" \\n \", \"\\n\")\n", "    def vocab_size(self) -> int:\n", "        return len(self.itos)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def read_tokens(path: str, tokenizer_mode: str = \"word\") -> Tuple[torch.Tensor, int]:\n", "    \"\"\"\n", "    Returns (tokens_tensor, vocab_size).\n", "    \"\"\"\n", "    if not os.path.exists(path):\n", "        raise FileNotFoundError(path)\n", "    \n", "    # 1) If user specifically asked for tiktoken\n", "    if tokenizer_mode == \"tiktoken\":\n", "        if tiktoken is None:\n", "            raise ImportError(\"Please `pip install tiktoken` to use --tokenizer tiktoken\")\n", "        print(f\"Loading {path} with tiktoken (gpt2)...\")\n", "        text = Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n", "        enc = tiktoken.get_encoding(\"gpt2\")\n", "        ids = enc.encode_ordinary(text) \n", "        return torch.tensor(ids, dtype=torch.long), enc.n_vocab\n\n", "    # 2) Try reading as space-separated integers (legacy/pre-processed format)\n", "    # We do this manually to avoid numpy.fromfile\n", "    try:\n", "        # Check if file starts with a number? \n", "        # Actually, let's just try to read it as text and split into ints if it looks like numbers\n", "        # Reading the whole file into memory as string might be heavy but consistent with v20\n", "        text = Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n", "        # heuristic: if the first few tokens are digits, assume integer format\n", "        first_tokens = text.split(maxsplit=5)\n", "        if first_tokens and all(t.isdigit() for t in first_tokens):\n", "             ids = [int(t) for t in text.split()]\n", "             if ids:\n", "                 return torch.tensor(ids, dtype=torch.long), max(ids) + 1\n", "    except ValueError:\n", "        pass\n", "        \n", "    # 3) Fallback: WordTokenizer\n", "    print(f\"File {path} could not be read as space-separated integers. Tokenizing as words...\")\n", "    text = Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n", "    tokenizer = WordTokenizer.build_from_train_text(text)\n", "    ids = tokenizer.encode_text(text)\n", "    print(f\"Tokenized {len(ids)} tokens. Vocab size: {tokenizer.vocab_size()}\")\n", "    return torch.tensor(ids, dtype=torch.long), tokenizer.vocab_size()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_batch(tokens_cpu: torch.Tensor, batch_size: int, block_size: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n", "    \"\"\"\n", "    tokens_cpu: 1D CPU tensor\n", "    Returns x,y on `device`.\n", "    \"\"\"\n", "    if tokens_cpu.device.type != \"cpu\":\n", "        tokens_cpu = tokens_cpu.cpu()\n", "    n = tokens_cpu.size(0)\n", "    if n <= block_size + 1:\n", "        raise ValueError(f\"Need > block_size+1 tokens, got {n} with block_size={block_size}\")\n", "    ix = torch.randint(0, n - block_size - 1, (batch_size,), device=\"cpu\")\n", "    x = torch.stack([tokens_cpu[i:i + block_size] for i in ix], dim=0).to(device)\n", "    y = torch.stack([tokens_cpu[i + 1:i + block_size + 1] for i in ix], dim=0).to(device)\n", "    return x, y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def neg_inf(dtype: torch.dtype) -> float:\n", "    # Safer than -inf on some backends.\n", "    return float(torch.finfo(dtype).min)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "RoPE<br>\n", "-----------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class RotaryEmbedding(nn.Module):\n", "    \"\"\"\n", "    RoPE with cached cos/sin tables.\n", "    NOTE:\n", "      The original v29 implementation cached (cos, sin) keyed by (device, dtype, seq_len).\n", "      During token-by-token decode that makes seq_len grow by 1 each step, which creates O(N)\n", "      separate cache entries and can blow up memory.\n", "      This version caches only per (device, dtype) and grows the table amortized (power-of-two)\n", "      so decode stays O(N) memory and ~O(N) total trig work.\n", "    \"\"\"\n", "    def __init__(self, rot_dim: int, base: float = 10000.0):\n", "        super().__init__()\n", "        if rot_dim % 2 != 0:\n", "            raise ValueError(f\"rot_dim must be even, got {rot_dim}\")\n", "        self.rot_dim = rot_dim\n", "        inv_freq = 1.0 / (base ** (torch.arange(0, rot_dim, 2).float() / rot_dim))\n", "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n\n", "        # Cache: (device, dtype) -> (cos, sin) with shape (L_cached, rot_dim/2)\n", "        self._cache: Dict[Tuple[str, str], Tuple[torch.Tensor, torch.Tensor]] = {}\n", "    @staticmethod\n", "    def _next_pow2(n: int) -> int:\n", "        n = int(n)\n", "        if n <= 0:\n", "            return 0\n", "        return 1 << (n - 1).bit_length()\n", "    def _cos_sin(self, seq_len: int, device: torch.device, dtype: torch.dtype) -> Tuple[torch.Tensor, torch.Tensor]:\n", "        seq_len = int(seq_len)\n", "        key = (str(device), str(dtype))\n", "        cached = self._cache.get(key, None)\n", "        if cached is None:\n", "            cached_len = 0\n", "            cos_cached = None\n", "            sin_cached = None\n", "        else:\n", "            cos_cached, sin_cached = cached\n", "            cached_len = int(cos_cached.size(0))\n", "        if cached is None or cached_len < seq_len:\n", "            # Grow to the next power-of-two to avoid O(N^2) behavior from tiny incremental extends.\n", "            target_len = self._next_pow2(seq_len)\n", "            if target_len < seq_len:\n", "                target_len = seq_len\n", "            start = cached_len\n", "            t = torch.arange(start, target_len, device=device, dtype=self.inv_freq.dtype)\n", "            freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq.to(device))\n", "            cos_new = torch.cos(freqs).to(dtype=dtype)\n", "            sin_new = torch.sin(freqs).to(dtype=dtype)\n", "            if cached is None:\n", "                cos_all = cos_new\n", "                sin_all = sin_new\n", "            else:\n", "                # Concatenate (amortized) to extend the cache.\n", "                cos_all = torch.cat([cos_cached, cos_new], dim=0)  # type: ignore[arg-type]\n", "                sin_all = torch.cat([sin_cached, sin_new], dim=0)  # type: ignore[arg-type]\n", "            self._cache[key] = (cos_all, sin_all)\n", "            cos_cached, sin_cached = cos_all, sin_all\n", "        return cos_cached[:seq_len], sin_cached[:seq_len]\n", "    def rotate(self, x: torch.Tensor, pos_offset: int) -> torch.Tensor:\n", "        \"\"\"\n", "        x: (B,H,T,D)\n", "        applies to first rot_dim of D\n", "        \"\"\"\n", "        B, H, T, D = x.shape\n", "        rot = self.rot_dim\n", "        if rot > D:\n", "            raise ValueError(f\"rot_dim {rot} > head_dim {D}\")\n", "        cos, sin = self._cos_sin(pos_offset + T, x.device, x.dtype)\n", "        cos = cos[pos_offset:pos_offset + T].unsqueeze(0).unsqueeze(0)  # (1,1,T,rot/2)\n", "        sin = sin[pos_offset:pos_offset + T].unsqueeze(0).unsqueeze(0)\n", "        x_rot = x[..., :rot]\n", "        x_pass = x[..., rot:]\n", "        x1 = x_rot[..., :rot // 2]\n", "        x2 = x_rot[..., rot // 2:rot]\n", "        y1 = x1 * cos - x2 * sin\n", "        y2 = x1 * sin + x2 * cos\n", "        return torch.cat([y1, y2, x_pass], dim=-1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "KV cache quantization<br>\n", "-----------------------------<br>\n", "-----------------------------<br>\n", "KV cache quantization<br>\n", "-----------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["NOTE: This research file keeps the quantization formats deliberately simple and kernel-friendly:<br>\n", "  - q8_0: per-block symmetric int8 with fp16 scale (absmax / 127)<br>\n", "  - q4_0: per-block symmetric int4 (packed into uint8) with fp16 scale (absmax / 7)<br>\n", "  - nf4 : per-block \"NormalFloat4\" codebook (packed into uint8) with fp16 scale (absmax)<br>\n", "<br>\n", "For production-scale inference, you'd normally use fused kernels to avoid dequantizing the whole cache.<br>\n", "This file adds a streaming (\"online softmax\") decode path that dequantizes in small sequence blocks."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["KVCacheKind = Literal[\"fp16\", \"fp32\", \"q8_0\", \"q4_0\", \"nf4\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@dataclass(frozen=True)\n", "class QuantSpec:\n", "    kind: KVCacheKind\n", "    dim: int\n", "    qblock: int\n", "    pad_dim: int\n", "    n_blocks: int"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@dataclass(frozen=True)\n", "class KVCacheTensorConfig:\n", "    kind: KVCacheKind = \"fp16\"\n", "    qblock: int = 32\n", "    residual_len: int = 0   # keep a small fp16 \"hot\" window for the newest tokens (ring-buffer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _qblock_eff(kind: KVCacheKind, dim: int, qblock: int) -> int:\n", "    qb = min(qblock if qblock > 0 else 32, dim)\n", "    if kind in (\"q4_0\", \"nf4\"):\n", "        if dim < 2:\n", "            raise ValueError(f\"{kind} cache requires dim >= 2\")\n", "        # ensure even qb <= dim (or <= dim-1 if dim is odd)\n", "        max_even = dim if (dim % 2 == 0) else (dim - 1)\n", "        qb = min(qb, max_even)\n", "        if qb < 2:\n", "            qb = 2\n", "        if qb % 2 != 0:\n", "            qb -= 1\n", "    return max(1, qb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def make_quantspec(kind: KVCacheKind, dim: int, qblock: int) -> QuantSpec:\n", "    qb = _qblock_eff(kind, dim, qblock)\n", "    pad_dim = int(math.ceil(dim / qb) * qb)\n", "    if kind in (\"q4_0\", \"nf4\") and (pad_dim % 2 != 0):\n", "        pad_dim += qb\n", "    n_blocks = pad_dim // qb\n", "    return QuantSpec(kind=kind, dim=dim, qblock=qb, pad_dim=pad_dim, n_blocks=n_blocks)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def quantize_q8_0(x: torch.Tensor, spec: QuantSpec) -> Tuple[torch.Tensor, torch.Tensor]:\n", "    \"\"\"\n", "    x: (..., dim) float\n", "    returns (q int8 (..., pad_dim), scale fp16 (..., n_blocks))\n", "    \"\"\"\n", "    if spec.kind != \"q8_0\":\n", "        raise ValueError(spec.kind)\n", "    dim, pad_dim, qb, nb = spec.dim, spec.pad_dim, spec.qblock, spec.n_blocks\n", "    if x.size(-1) != dim:\n", "        raise ValueError(f\"Expected dim {dim}, got {x.size(-1)}\")\n", "    if pad_dim != dim:\n", "        x = F.pad(x, (0, pad_dim - dim), value=0.0)\n", "    orig = x.shape[:-1]\n", "    x2 = x.reshape(-1, pad_dim).reshape(-1, nb, qb)\n", "    amax = x2.abs().amax(dim=-1)  # (N, nb)\n", "    scale = (amax / 127.0).clamp(min=1e-8)\n", "    q = torch.round(x2 / scale.unsqueeze(-1)).clamp(-127, 127).to(torch.int8)\n", "    q = q.reshape(*orig, pad_dim)\n", "    return q, scale.to(torch.float16).reshape(*orig, nb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dequantize_q8_0(q: torch.Tensor, scale: torch.Tensor, spec: QuantSpec) -> torch.Tensor:\n", "    if spec.kind != \"q8_0\":\n", "        raise ValueError(spec.kind)\n", "    dim, pad_dim, qb, nb = spec.dim, spec.pad_dim, spec.qblock, spec.n_blocks\n", "    if q.size(-1) != pad_dim:\n", "        raise ValueError(f\"Expected q pad_dim {pad_dim}, got {q.size(-1)}\")\n", "    if scale.size(-1) != nb:\n", "        raise ValueError(f\"Expected scale n_blocks {nb}, got {scale.size(-1)}\")\n", "    orig = q.shape[:-1]\n", "    q2 = q.reshape(-1, pad_dim).reshape(-1, nb, qb).to(torch.float32)\n", "    s2 = scale.reshape(-1, nb).to(torch.float32).unsqueeze(-1)\n", "    x2 = q2 * s2\n", "    x = x2.reshape(*orig, pad_dim)[..., :dim]\n", "    return x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def quantize_q4_0(x: torch.Tensor, spec: QuantSpec) -> Tuple[torch.Tensor, torch.Tensor]:\n", "    \"\"\"\n", "    Q4_0-like: int4 packed into uint8, with fp16 scale per block.\n", "    returns (packed uint8 (..., pad_dim//2), scale fp16 (..., n_blocks))\n", "    \"\"\"\n", "    if spec.kind != \"q4_0\":\n", "        raise ValueError(spec.kind)\n", "    dim, pad_dim, qb, nb = spec.dim, spec.pad_dim, spec.qblock, spec.n_blocks\n", "    if x.size(-1) != dim:\n", "        raise ValueError(f\"Expected dim {dim}, got {x.size(-1)}\")\n", "    if pad_dim != dim:\n", "        x = F.pad(x, (0, pad_dim - dim), value=0.0)\n", "    orig = x.shape[:-1]\n", "    x2 = x.reshape(-1, pad_dim).reshape(-1, nb, qb)\n", "    amax = x2.abs().amax(dim=-1)\n", "    scale = (amax / 7.0).clamp(min=1e-8)\n", "    q = torch.round(x2 / scale.unsqueeze(-1)).clamp(-8, 7).to(torch.int16)  # int16 for packing\n", "    u = (q + 8).clamp(0, 15).to(torch.uint8)  # 0..15\n\n", "    # pack two nibbles per byte via arithmetic (works on MPS too)\n", "    u_even = u[..., 0::2]\n", "    u_odd = u[..., 1::2]\n", "    packed = (u_even * 16) + u_odd  # uint8\n", "    packed = packed.reshape(*orig, pad_dim // 2)\n", "    return packed, scale.to(torch.float16).reshape(*orig, nb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dequantize_q4_0(packed: torch.Tensor, scale: torch.Tensor, spec: QuantSpec) -> torch.Tensor:\n", "    if spec.kind != \"q4_0\":\n", "        raise ValueError(spec.kind)\n", "    dim, pad_dim, qb, nb = spec.dim, spec.pad_dim, spec.qblock, spec.n_blocks\n", "    if packed.size(-1) != pad_dim // 2:\n", "        raise ValueError(f\"Expected packed last dim {pad_dim//2}, got {packed.size(-1)}\")\n", "    if scale.size(-1) != nb:\n", "        raise ValueError(f\"Expected scale n_blocks {nb}, got {scale.size(-1)}\")\n", "    orig = packed.shape[:-1]\n", "    p2 = packed.reshape(-1, pad_dim // 2).to(torch.int16)\n", "    hi = p2 // 16\n", "    lo = p2 % 16\n", "    u = torch.stack([hi, lo], dim=-1).reshape(-1, pad_dim)  # 0..15\n", "    q = (u - 8).clamp(-8, 7).to(torch.float32)\n", "    q = q.reshape(-1, nb, qb)\n", "    s = scale.reshape(-1, nb).to(torch.float32).unsqueeze(-1)\n", "    x2 = q * s\n", "    x = x2.reshape(*orig, pad_dim)[..., :dim]\n", "    return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["NF4 codebook from QLoRA Appendix E / bitsandbytes (normalized to [-1, 1]).<br>\n", "(We keep it explicit here so the file stays self-contained.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["NF4_LEVELS = torch.tensor([\n", "    -1.0,\n", "    -0.6961928009986877,\n", "    -0.5250730514526367,\n", "    -0.39491748809814453,\n", "    -0.28444138169288635,\n", "    -0.18477343022823334,\n", "    -0.09105003625154495,\n", "    0.0,\n", "    0.07958029955625534,\n", "    0.16093020141124725,\n", "    0.24611230194568634,\n", "    0.33791524171829224,\n", "    0.44070982933044434,\n", "    0.5626170039176941,\n", "    0.7229568362236023,\n", "    1.0,\n", "], dtype=torch.float32)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def quantize_nf4(x: torch.Tensor, spec: QuantSpec) -> Tuple[torch.Tensor, torch.Tensor]:\n", "    \"\"\"\n", "    NF4: non-uniform 4-bit codebook quantization.\n", "    x: (..., dim) float\n", "    returns (packed uint8 (..., pad_dim//2), scale fp16 (..., n_blocks))\n", "    NOTE: This is implemented in pure PyTorch for research (not fast vs kernel implementations).\n", "    \"\"\"\n", "    if spec.kind != \"nf4\":\n", "        raise ValueError(spec.kind)\n", "    dim, pad_dim, qb, nb = spec.dim, spec.pad_dim, spec.qblock, spec.n_blocks\n", "    if x.size(-1) != dim:\n", "        raise ValueError(f\"Expected dim {dim}, got {x.size(-1)}\")\n", "    if pad_dim != dim:\n", "        x = F.pad(x, (0, pad_dim - dim), value=0.0)\n", "    orig = x.shape[:-1]\n", "    x2 = x.reshape(-1, pad_dim).reshape(-1, nb, qb)  # (N, nb, qb)\n", "    amax = x2.abs().amax(dim=-1)  # (N, nb)\n", "    scale = amax.clamp(min=1e-8)  # map into [-1, 1] via absmax\n", "    y = (x2 / scale.unsqueeze(-1)).clamp(-1.0, 1.0)  # (N, nb, qb)\n", "    levels = NF4_LEVELS.to(device=y.device, dtype=torch.float32)\n\n", "    # nearest-neighbor assignment into 16-level LUT\n", "    # (N, nb, qb, 1) - (16,) -> (N, nb, qb, 16)\n", "    diff = (y.to(torch.float32).unsqueeze(-1) - levels).abs()\n", "    idx = diff.argmin(dim=-1).to(torch.uint8)  # 0..15\n\n", "    # pack two 4-bit indices per byte (same packing layout as q4_0)\n", "    idx_even = idx[..., 0::2]\n", "    idx_odd = idx[..., 1::2]\n", "    packed = (idx_even * 16) + idx_odd  # uint8\n", "    packed = packed.reshape(*orig, pad_dim // 2)\n", "    return packed, scale.to(torch.float16).reshape(*orig, nb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def dequantize_nf4(packed: torch.Tensor, scale: torch.Tensor, spec: QuantSpec) -> torch.Tensor:\n", "    if spec.kind != \"nf4\":\n", "        raise ValueError(spec.kind)\n", "    dim, pad_dim, qb, nb = spec.dim, spec.pad_dim, spec.qblock, spec.n_blocks\n", "    if packed.size(-1) != pad_dim // 2:\n", "        raise ValueError(f\"Expected packed last dim {pad_dim//2}, got {packed.size(-1)}\")\n", "    if scale.size(-1) != nb:\n", "        raise ValueError(f\"Expected scale n_blocks {nb}, got {scale.size(-1)}\")\n", "    orig = packed.shape[:-1]\n", "    p2 = packed.reshape(-1, pad_dim // 2).to(torch.int16)\n", "    hi = p2 // 16\n", "    lo = p2 % 16\n", "    idx = torch.stack([hi, lo], dim=-1).reshape(-1, pad_dim).to(torch.long)  # 0..15\n", "    levels = NF4_LEVELS.to(device=packed.device, dtype=torch.float32)\n", "    q = levels[idx]  # (N, pad_dim)\n", "    q = q.reshape(-1, nb, qb)\n", "    s = scale.reshape(-1, nb).to(torch.float32).unsqueeze(-1)\n", "    x2 = q * s\n", "    x = x2.reshape(*orig, pad_dim)[..., :dim]\n", "    return x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "Optional Triton fused kernels (decode only)<br>\n", "-----------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if TRITON_AVAILABLE:\n", "    @triton.jit\n", "    def _kv_decode_update_decoupled_q4q8q4(\n", "        q_sem_ptr, q_geo_ptr,\n", "        k_sem_q_ptr, k_sem_s_ptr,\n", "        k_geo_q_ptr, k_geo_s_ptr,\n", "        v_q_ptr, v_s_ptr,\n", "        m_ptr, d_ptr, o_ptr,\n", "        start: tl.int32,\n", "        # runtime lengths\n", "        L_prefix: tl.int32,\n", "        # meta\n", "        H: tl.constexpr,\n", "        HD_SEM: tl.constexpr,\n", "        HD_GEO: tl.constexpr,\n", "        HD_V: tl.constexpr,\n", "        QBLOCK_SEM: tl.constexpr,\n", "        QBLOCK_GEO: tl.constexpr,\n", "        QBLOCK_V: tl.constexpr,\n", "        SEM_SCALE: tl.constexpr,\n", "        GEO_SCALE: tl.constexpr,\n", "        BLOCK_N: tl.constexpr,\n", "        NUM_SUBBLOCKS: tl.constexpr,\n", "        # strides\n", "        stride_qsem_b: tl.constexpr, stride_qsem_h: tl.constexpr,\n", "        stride_qgeo_b: tl.constexpr, stride_qgeo_h: tl.constexpr,\n", "        stride_ksq_b: tl.constexpr, stride_ksq_t: tl.constexpr,\n", "        stride_kss_b: tl.constexpr, stride_kss_t: tl.constexpr, stride_kss_c: tl.constexpr,\n", "        stride_kgq_b: tl.constexpr, stride_kgq_t: tl.constexpr,\n", "        stride_kgs_b: tl.constexpr, stride_kgs_t: tl.constexpr, stride_kgs_c: tl.constexpr,\n", "        stride_vq_b: tl.constexpr, stride_vq_t: tl.constexpr,\n", "        stride_vs_b: tl.constexpr, stride_vs_t: tl.constexpr, stride_vs_c: tl.constexpr,\n", "        stride_o: tl.constexpr,\n", "    ):\n", "        \"\"\"One streaming-update kernel: updates (m,d,o) for a block-range of tokens.\n", "        This is intended for **decode (T==1)**, where we run online softmax.\n", "        We fuse:\n", "          - dequant (K_sem q4_0, K_geo q8_0, V q4_0)\n", "          - logits computation\n", "          - exp / sums\n", "          - weighted value accumulation\n", "        \"\"\"\n", "        pid = tl.program_id(0)  # 0 .. B*H-1\n", "        b = pid // H\n", "        h = pid - b * H\n\n", "        # Load running state.\n", "        m = tl.load(m_ptr + pid).to(tl.float32)\n", "        d = tl.load(d_ptr + pid).to(tl.float32)\n", "        dv = tl.arange(0, HD_V)\n", "        o = tl.load(o_ptr + pid * stride_o + dv, mask=dv < HD_V, other=0.0).to(tl.float32)\n\n", "        # Load query vectors.\n", "        ds = tl.arange(0, HD_SEM)\n", "        dg = tl.arange(0, HD_GEO)\n", "        q_sem = tl.load(q_sem_ptr + b * stride_qsem_b + h * stride_qsem_h + ds, mask=ds < HD_SEM, other=0.0).to(tl.float32)\n", "        q_geo = tl.load(q_geo_ptr + b * stride_qgeo_b + h * stride_qgeo_h + dg, mask=dg < HD_GEO, other=0.0).to(tl.float32)\n\n", "        # Static loop: process NUM_SUBBLOCKS contiguous blocks of BLOCK_N tokens.\n", "        for sb in tl.static_range(NUM_SUBBLOCKS):\n", "            t = start + sb * BLOCK_N + tl.arange(0, BLOCK_N)\n", "            tm = t < L_prefix\n\n", "            # ---- semantic keys: q4_0 ----\n", "            ksd = h * HD_SEM + ds  # global dim indices in [0, sem_dim)\n", "            ks_byte = ksd // 2\n", "            ks_nib = ksd % 2\n", "            ks_ptr = k_sem_q_ptr + b * stride_ksq_b + t[:, None] * stride_ksq_t + ks_byte[None, :]\n", "            ks_p = tl.load(ks_ptr, mask=tm[:, None] & (ds[None, :] < HD_SEM), other=0).to(tl.int32)\n", "            ks_hi = ks_p >> 4\n", "            ks_lo = ks_p & 0xF\n", "            ks_u = tl.where(ks_nib[None, :] == 0, ks_hi, ks_lo)\n", "            ks_q = ks_u.to(tl.int32) - 8\n", "            ks_sb = ksd // QBLOCK_SEM\n", "            ks_s_ptr = k_sem_s_ptr + b * stride_kss_b + t[:, None] * stride_kss_t + ks_sb[None, :] * stride_kss_c\n", "            ks_s = tl.load(ks_s_ptr, mask=tm[:, None] & (ds[None, :] < HD_SEM), other=0.0).to(tl.float32)\n", "            k_sem = ks_q.to(tl.float32) * ks_s\n", "            logit_sem = tl.sum(k_sem * q_sem[None, :], axis=1)\n\n", "            # ---- geometric keys: q8_0 ----\n", "            kgd = h * HD_GEO + dg  # global dim indices in [0, geo_dim)\n", "            kg_ptr = k_geo_q_ptr + b * stride_kgq_b + t[:, None] * stride_kgq_t + kgd[None, :]\n", "            kg_q = tl.load(kg_ptr, mask=tm[:, None] & (dg[None, :] < HD_GEO), other=0).to(tl.int32)\n", "            kg_sb = kgd // QBLOCK_GEO\n", "            kg_s_ptr = k_geo_s_ptr + b * stride_kgs_b + t[:, None] * stride_kgs_t + kg_sb[None, :] * stride_kgs_c\n", "            kg_s = tl.load(kg_s_ptr, mask=tm[:, None] & (dg[None, :] < HD_GEO), other=0.0).to(tl.float32)\n", "            k_geo = kg_q.to(tl.float32) * kg_s\n", "            logit_geo = tl.sum(k_geo * q_geo[None, :], axis=1)\n", "            logits = logit_sem * SEM_SCALE + logit_geo * GEO_SCALE\n", "            logits = tl.where(tm, logits, -float(\"inf\"))\n", "            block_max = tl.max(logits, axis=0)\n", "            m_new = tl.maximum(m, block_max)\n", "            exp_m = tl.exp(m - m_new)\n", "            exp_logits = tl.exp(logits - m_new)\n\n", "            # ---- values: q4_0 ----\n", "            vd = h * HD_V + dv\n", "            v_byte = vd // 2\n", "            v_nib = vd % 2\n", "            v_ptr = v_q_ptr + b * stride_vq_b + t[:, None] * stride_vq_t + v_byte[None, :]\n", "            v_p = tl.load(v_ptr, mask=tm[:, None] & (dv[None, :] < HD_V), other=0).to(tl.int32)\n", "            v_hi = v_p >> 4\n", "            v_lo = v_p & 0xF\n", "            v_u = tl.where(v_nib[None, :] == 0, v_hi, v_lo)\n", "            v_q = v_u.to(tl.int32) - 8\n", "            v_sb = vd // QBLOCK_V\n", "            vs_ptr = v_s_ptr + b * stride_vs_b + t[:, None] * stride_vs_t + v_sb[None, :] * stride_vs_c\n", "            v_s = tl.load(vs_ptr, mask=tm[:, None] & (dv[None, :] < HD_V), other=0.0).to(tl.float32)\n", "            v_val = v_q.to(tl.float32) * v_s\n", "            d = d * exp_m + tl.sum(exp_logits, axis=0)\n", "            # weighted sum over tokens -> (HD_V,)\n", "            wv = tl.sum(exp_logits[:, None] * v_val, axis=0)\n", "            o = o * exp_m + wv\n", "            m = m_new\n", "        tl.store(m_ptr + pid, m)\n", "        tl.store(d_ptr + pid, d)\n", "        tl.store(o_ptr + pid * stride_o + dv, o, mask=dv < HD_V)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # -----------------------------\n", "    # v24: 2-pass \"FlashAttention-style\" split-K decode kernels\n", "    # -----------------------------\n", "    #\n", "    # Motivation:\n", "    # - v23's fused kernel is \"one program per (batch, head)\" and loops over the sequence.\n", "    #   Great for moderate context, but it can't parallelize over sequence length when T==1.\n", "    # - This split-K design parallelizes across the KV sequence dimension by slicing it into partitions.\n", "    #   Each partition computes local (m, d, o) using online-softmax, then we reduce partitions.\n", "    #\n", "    # This is decode-only (T==1), forward-only, and currently specialized for:\n", "    #   K_sem: q4_0, K_geo: q8_0, V: q4_0  with qblock=32.\n", "    @triton.jit\n", "    def _kv_decode_partition_stats_decoupled_q4q8q4(\n", "        q_sem_ptr, q_geo_ptr,\n", "        k_sem_q_ptr, k_sem_s_ptr,\n", "        k_geo_q_ptr, k_geo_s_ptr,\n", "        v_q_ptr, v_s_ptr,\n", "        m_part_ptr, d_part_ptr, o_part_ptr,\n", "        L_prefix: tl.int32,\n", "        P: tl.int32,\n", "        PARTITION_SIZE: tl.constexpr,\n", "        H: tl.constexpr,\n", "        HD_SEM: tl.constexpr,\n", "        HD_GEO: tl.constexpr,\n", "        HD_V: tl.constexpr,\n", "        QBLOCK_SEM: tl.constexpr,\n", "        QBLOCK_GEO: tl.constexpr,\n", "        QBLOCK_V: tl.constexpr,\n", "        SEM_SCALE: tl.constexpr,\n", "        GEO_SCALE: tl.constexpr,\n", "        BLOCK_N: tl.constexpr,\n", "        NUM_SUBBLOCKS: tl.constexpr,\n", "        stride_qsem_b: tl.constexpr,\n", "        stride_qsem_h: tl.constexpr,\n", "        stride_qgeo_b: tl.constexpr,\n", "        stride_qgeo_h: tl.constexpr,\n", "        stride_ksq_b: tl.constexpr,\n", "        stride_ksq_t: tl.constexpr,\n", "        stride_kss_b: tl.constexpr,\n", "        stride_kss_t: tl.constexpr,\n", "        stride_kss_c: tl.constexpr,\n", "        stride_kgq_b: tl.constexpr,\n", "        stride_kgq_t: tl.constexpr,\n", "        stride_kgs_b: tl.constexpr,\n", "        stride_kgs_t: tl.constexpr,\n", "        stride_kgs_c: tl.constexpr,\n", "        stride_vq_b: tl.constexpr,\n", "        stride_vq_t: tl.constexpr,\n", "        stride_vs_b: tl.constexpr,\n", "        stride_vs_t: tl.constexpr,\n", "        stride_vs_c: tl.constexpr,\n", "        stride_mp_row: tl.constexpr,\n", "        stride_mp_part: tl.constexpr,\n", "        stride_dp_row: tl.constexpr,\n", "        stride_dp_part: tl.constexpr,\n", "        stride_op_row: tl.constexpr,\n", "        stride_op_part: tl.constexpr,\n", "    ):\n", "        pid_row = tl.program_id(0)  # 0 .. BH-1\n", "        pid_part = tl.program_id(1) # 0 .. P-1 (grid)\n", "        b = pid_row // H\n", "        h = pid_row - b * H\n\n", "        # Load query vectors (fp16) -> fp32.\n", "        ds = tl.arange(0, HD_SEM)\n", "        dg = tl.arange(0, HD_GEO)\n", "        dv = tl.arange(0, HD_V)\n", "        qsem = tl.load(q_sem_ptr + b * stride_qsem_b + h * stride_qsem_h + ds, mask=ds < HD_SEM, other=0.0).to(tl.float32)\n", "        qgeo = tl.load(q_geo_ptr + b * stride_qgeo_b + h * stride_qgeo_h + dg, mask=dg < HD_GEO, other=0.0).to(tl.float32)\n\n", "        # Local online-softmax state for this partition.\n", "        m = -float(\"inf\")\n", "        d = 0.0\n", "        o = tl.zeros([HD_V], dtype=tl.float32)\n", "        start = pid_part * PARTITION_SIZE\n", "        # Process PARTITION_SIZE tokens in NUM_SUBBLOCKS * BLOCK_N tiles.\n", "        for sb in tl.static_range(0, NUM_SUBBLOCKS):\n", "            t = start + sb * BLOCK_N + tl.arange(0, BLOCK_N)\n", "            tm = t < L_prefix\n\n", "            # --- Semantic K (q4_0) dot ---\n", "            # Global dim index within merged (H*HD_SEM)\n", "            ksd = h * HD_SEM + ds                       # (HD_SEM,)\n", "            ks_byte = ksd // 2\n", "            ks_nib = ksd % 2\n", "            ks_ptr = k_sem_q_ptr + b * stride_ksq_b + t[:, None] * stride_ksq_t + ks_byte[None, :]\n", "            ks_p = tl.load(ks_ptr, mask=tm[:, None] & (ds[None, :] < HD_SEM), other=0).to(tl.uint8)\n", "            ks_hi = ks_p >> 4\n", "            ks_lo = ks_p & 0xF\n", "            ks_u = tl.where(ks_nib[None, :] == 0, ks_hi, ks_lo)\n", "            ks_q = ks_u.to(tl.int32) - 8\n", "            ks_sb = ksd // QBLOCK_SEM\n", "            ks_s_ptr = k_sem_s_ptr + b * stride_kss_b + t[:, None] * stride_kss_t + ks_sb[None, :] * stride_kss_c\n", "            ks_s = tl.load(ks_s_ptr, mask=tm[:, None] & (ds[None, :] < HD_SEM), other=0.0).to(tl.float32)\n", "            ksem = ks_q.to(tl.float32) * ks_s\n", "            sem = tl.sum(ksem * qsem[None, :], axis=1)\n\n", "            # --- Geometric K (q8_0) dot ---\n", "            kgd = h * HD_GEO + dg\n", "            kg_ptr = k_geo_q_ptr + b * stride_kgq_b + t[:, None] * stride_kgq_t + kgd[None, :]\n", "            kg_q = tl.load(kg_ptr, mask=tm[:, None] & (dg[None, :] < HD_GEO), other=0).to(tl.int8).to(tl.float32)\n", "            kg_sb = kgd // QBLOCK_GEO\n", "            kg_s_ptr = k_geo_s_ptr + b * stride_kgs_b + t[:, None] * stride_kgs_t + kg_sb[None, :] * stride_kgs_c\n", "            kg_s = tl.load(kg_s_ptr, mask=tm[:, None] & (dg[None, :] < HD_GEO), other=0.0).to(tl.float32)\n", "            kgeo = kg_q * kg_s\n", "            geo = tl.sum(kgeo * qgeo[None, :], axis=1)\n", "            logits = sem * SEM_SCALE + geo * GEO_SCALE\n", "            logits = tl.where(tm, logits, -float(\"inf\"))\n", "            block_max = tl.max(logits, axis=0)\n", "            m_new = tl.maximum(m, block_max)\n", "            exp_m = tl.exp(m - m_new)\n", "            exp_logits = tl.exp(logits - m_new)\n\n", "            # --- V (q4_0) weighted sum ---\n", "            vd = h * HD_V + dv\n", "            v_byte = vd // 2\n", "            v_nib = vd % 2\n", "            v_ptr = v_q_ptr + b * stride_vq_b + t[:, None] * stride_vq_t + v_byte[None, :]\n", "            v_p = tl.load(v_ptr, mask=tm[:, None] & (dv[None, :] < HD_V), other=0).to(tl.uint8)\n", "            v_hi = v_p >> 4\n", "            v_lo = v_p & 0xF\n", "            v_u = tl.where(v_nib[None, :] == 0, v_hi, v_lo)\n", "            v_q = v_u.to(tl.int32) - 8\n", "            v_sb = vd // QBLOCK_V\n", "            vs_ptr = v_s_ptr + b * stride_vs_b + t[:, None] * stride_vs_t + v_sb[None, :] * stride_vs_c\n", "            v_s = tl.load(vs_ptr, mask=tm[:, None] & (dv[None, :] < HD_V), other=0.0).to(tl.float32)\n", "            v_val = v_q.to(tl.float32) * v_s\n", "            d = d * exp_m + tl.sum(exp_logits, axis=0)\n", "            wv = tl.sum(exp_logits[:, None] * v_val, axis=0)\n", "            o = o * exp_m + wv\n", "            m = m_new\n\n", "        # Write partition stats\n", "        tl.store(m_part_ptr + pid_row * stride_mp_row + pid_part * stride_mp_part, m)\n", "        tl.store(d_part_ptr + pid_row * stride_dp_row + pid_part * stride_dp_part, d)\n", "        tl.store(o_part_ptr + pid_row * stride_op_row + pid_part * stride_op_part + dv, o, mask=dv < HD_V)\n", "    @triton.jit\n", "    def _kv_decode_reduce_partitions(\n", "        m_part_ptr, d_part_ptr, o_part_ptr,\n", "        m_ptr, d_ptr, o_ptr,\n", "        P: tl.int32,\n", "        NUM_PARTS: tl.constexpr,\n", "        HD_V: tl.constexpr,\n", "        stride_mp_row: tl.constexpr,\n", "        stride_mp_part: tl.constexpr,\n", "        stride_dp_row: tl.constexpr,\n", "        stride_dp_part: tl.constexpr,\n", "        stride_op_row: tl.constexpr,\n", "        stride_op_part: tl.constexpr,\n", "        stride_o: tl.constexpr,\n", "    ):\n", "        pid_row = tl.program_id(0)  # 0..BH-1\n", "        dv = tl.arange(0, HD_V)\n\n", "        # First pass: global max over partitions.\n", "        m = -float(\"inf\")\n", "        for p in tl.static_range(0, NUM_PARTS):\n", "            p_i = tl.full([], p, tl.int32)\n", "            pm = p_i < P\n", "            mp = tl.load(m_part_ptr + pid_row * stride_mp_row + p_i * stride_mp_part, mask=pm, other=-float(\"inf\"))\n", "            m = tl.maximum(m, mp)\n\n", "        # Second pass: combine denominators and outputs.\n", "        d = 0.0\n", "        o = tl.zeros([HD_V], dtype=tl.float32)\n", "        for p in tl.static_range(0, NUM_PARTS):\n", "            p_i = tl.full([], p, tl.int32)\n", "            pm = p_i < P\n", "            mp = tl.load(m_part_ptr + pid_row * stride_mp_row + p_i * stride_mp_part, mask=pm, other=-float(\"inf\"))\n", "            dp = tl.load(d_part_ptr + pid_row * stride_dp_row + p_i * stride_dp_part, mask=pm, other=0.0)\n", "            op = tl.load(o_part_ptr + pid_row * stride_op_row + p_i * stride_op_part + dv, mask=pm & (dv < HD_V), other=0.0).to(tl.float32)\n", "            scale = tl.where(pm, tl.exp(mp - m), 0.0)\n", "            d += dp * scale\n", "            o += op * scale\n", "        tl.store(m_ptr + pid_row, m)\n", "        tl.store(d_ptr + pid_row, d)\n", "        tl.store(o_ptr + pid_row * stride_o + dv, o, mask=dv < HD_V)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _triton_decoupled_q4q8q4_available() -> bool:\n", "    return bool(TRITON_AVAILABLE)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class SeqCacheTensor:\n", "    \"\"\"\n", "    A [B, max_seq_len, dim] sequence tensor stored in fp16/fp32/q8_0/q4_0/nf4.\n", "    New in v22:\n", "      - get_slice(start, end): dequantize only a slice (critical for long-context decode)\n", "      - residual fp16 \"hot\" ring-buffer for the newest tokens (optional)\n", "    \"\"\"\n", "    def __init__(\n", "        self,\n", "        *,\n", "        batch_size: int,\n", "        max_seq_len: int,\n", "        dim: int,\n", "        cfg: KVCacheTensorConfig,\n", "        device: torch.device,\n", "    ):\n", "        self.kind: KVCacheKind = cfg.kind\n", "        self.device = device\n", "        self.spec = make_quantspec(cfg.kind, dim, cfg.qblock)\n", "        self.pos = 0\n", "        self.max_seq_len = max_seq_len\n", "        self.residual_len = int(max(0, cfg.residual_len))\n", "        self._residual: Optional[torch.Tensor]\n", "        self._residual_len_eff = min(self.residual_len, max_seq_len) if self.residual_len > 0 else 0\n", "        if self.kind in (\"fp16\", \"fp32\"):\n", "            dtype = torch.float16 if self.kind == \"fp16\" else torch.float32\n", "            self.buf = torch.empty((batch_size, max_seq_len, dim), device=device, dtype=dtype)\n", "            self.q = None\n", "            self.s = None\n", "            self._residual = None\n", "        elif self.kind == \"q8_0\":\n", "            self.buf = None\n", "            self.q = torch.empty((batch_size, max_seq_len, self.spec.pad_dim), device=device, dtype=torch.int8)\n", "            self.s = torch.empty((batch_size, max_seq_len, self.spec.n_blocks), device=device, dtype=torch.float16)\n", "            self._residual = (\n", "                torch.empty((batch_size, self._residual_len_eff, dim), device=device, dtype=torch.float16)\n", "                if self._residual_len_eff > 0 else None\n", "            )\n", "        elif self.kind in (\"q4_0\", \"nf4\"):\n", "            self.buf = None\n", "            self.q = torch.empty((batch_size, max_seq_len, self.spec.pad_dim // 2), device=device, dtype=torch.uint8)\n", "            self.s = torch.empty((batch_size, max_seq_len, self.spec.n_blocks), device=device, dtype=torch.float16)\n", "            self._residual = (\n", "                torch.empty((batch_size, self._residual_len_eff, dim), device=device, dtype=torch.float16)\n", "                if self._residual_len_eff > 0 else None\n", "            )\n", "        else:\n", "            raise ValueError(self.kind)\n", "    @property\n", "    def is_quantized(self) -> bool:\n", "        return self.kind not in (\"fp16\", \"fp32\")\n", "    def _residual_start(self) -> int:\n", "        if self._residual is None:\n", "            return self.pos  # empty range\n", "        return max(0, self.pos - self._residual_len_eff)\n", "    def _residual_gather(self, start: int, end: int) -> torch.Tensor:\n", "        \"\"\"\n", "        Gather [start, end) from the fp16 residual ring buffer.\n", "        Assumes the range is fully inside the residual window.\n", "        \"\"\"\n", "        if self._residual is None:\n", "            raise RuntimeError(\"No residual buffer allocated\")\n", "        if not (0 <= start <= end <= self.pos):\n", "            raise ValueError(f\"Invalid residual slice {start}:{end} for pos={self.pos}\")\n", "        rlen = self._residual_len_eff\n", "        if rlen <= 0:\n", "            raise RuntimeError(\"Residual length is 0\")\n", "        idx = (torch.arange(start, end, device=self.device, dtype=torch.long) % rlen)\n", "        # (B, end-start, dim)\n", "        return self._residual.index_select(1, idx)\n", "    def append(self, x_new: torch.Tensor) -> int:\n", "        \"\"\"\n", "        x_new: (B, T_new, dim) float\n", "        returns old_pos (start index)\n", "        \"\"\"\n", "        B, Tn, D = x_new.shape\n", "        if D != self.spec.dim:\n", "            raise ValueError(f\"dim mismatch: expected {self.spec.dim}, got {D}\")\n", "        if self.pos + Tn > self.max_seq_len:\n", "            raise ValueError(f\"Cache overflow: pos {self.pos} + {Tn} > max {self.max_seq_len}\")\n", "        old = self.pos\n", "        if self.kind in (\"fp16\", \"fp32\"):\n", "            self.buf[:, old:old + Tn] = x_new.to(self.buf.dtype)\n", "        elif self.kind == \"q8_0\":\n", "            q, s = quantize_q8_0(x_new, self.spec)\n", "            self.q[:, old:old + Tn] = q\n", "            self.s[:, old:old + Tn] = s\n", "        elif self.kind == \"q4_0\":\n", "            q, s = quantize_q4_0(x_new, self.spec)\n", "            self.q[:, old:old + Tn] = q\n", "            self.s[:, old:old + Tn] = s\n", "        elif self.kind == \"nf4\":\n", "            q, s = quantize_nf4(x_new, self.spec)\n", "            self.q[:, old:old + Tn] = q\n", "            self.s[:, old:old + Tn] = s\n", "        else:\n", "            raise ValueError(self.kind)\n\n", "        # maintain residual fp16 ring for hot tokens (helps decode; negligible memory).\n", "        if self._residual is not None:\n", "            rlen = self._residual_len_eff\n", "            if rlen > 0:\n", "                if Tn >= rlen:\n", "                    # Only the newest rlen tokens matter for the ring.\n", "                    x_tail = x_new[:, -rlen:].to(torch.float16)\n", "                    idx = (torch.arange(old + Tn - rlen, old + Tn, device=self.device, dtype=torch.long) % rlen)\n", "                    self._residual[:, idx] = x_tail\n", "                else:\n", "                    x_fp16 = x_new.to(torch.float16)\n", "                    idx = (torch.arange(old, old + Tn, device=self.device, dtype=torch.long) % rlen)\n", "                    self._residual[:, idx] = x_fp16\n", "        self.pos += Tn\n", "        return old\n", "    def get_slice(self, start: int, end: int, *, dtype: torch.dtype = torch.float32) -> torch.Tensor:\n", "        \"\"\"\n", "        returns (B, end-start, dim) in `dtype`, dequantizing only the requested slice.\n", "        \"\"\"\n", "        start = int(start); end = int(end)\n", "        if start < 0 or end < start:\n", "            raise ValueError(f\"Invalid slice {start}:{end}\")\n", "        if end > self.pos:\n", "            raise ValueError(f\"Requested end {end} > cached length {self.pos}\")\n", "        if start == end:\n", "            # preserve shape semantics\n", "            B = (self.buf.size(0) if self.buf is not None else self.q.size(0))  # type: ignore[union-attr]\n", "            return torch.empty((B, 0, self.spec.dim), device=self.device, dtype=dtype)\n", "        if self.kind in (\"fp16\", \"fp32\"):\n", "            return self.buf[:, start:end].to(dtype)  # type: ignore[index]\n\n", "        # residual fast-path (newest tokens)\n", "        r_start = self._residual_start()\n", "        if self._residual is not None and start >= r_start:\n", "            return self._residual_gather(start, end).to(dtype)\n\n", "        # mixed slice: older part dequant + tail from residual\n", "        if self._residual is not None and end > r_start and start < r_start:\n", "            a = self.get_slice(start, r_start, dtype=dtype)\n", "            b = self._residual_gather(r_start, end).to(dtype)\n", "            return torch.cat([a, b], dim=1)\n\n", "        # fully in the quantized region\n", "        if self.kind == \"q8_0\":\n", "            x = dequantize_q8_0(self.q[:, start:end], self.s[:, start:end], self.spec)\n", "            return x.to(dtype)\n", "        if self.kind == \"q4_0\":\n", "            x = dequantize_q4_0(self.q[:, start:end], self.s[:, start:end], self.spec)\n", "            return x.to(dtype)\n", "        if self.kind == \"nf4\":\n", "            x = dequantize_nf4(self.q[:, start:end], self.s[:, start:end], self.spec)\n", "            return x.to(dtype)\n", "        raise ValueError(self.kind)\n", "    def get(self, length: Optional[int] = None, *, dtype: torch.dtype = torch.float32) -> torch.Tensor:\n", "        \"\"\"\n", "        returns (B, length, dim) in `dtype` (compatibility helper).\n", "        \"\"\"\n", "        L = self.pos if length is None else int(length)\n", "        return self.get_slice(0, L, dtype=dtype)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LayerKVCache:\n", "    def __init__(\n", "        self,\n", "        *,\n", "        batch_size: int,\n", "        max_seq_len: int,\n", "        k_dim: int,\n", "        v_dim: int,\n", "        k_cfg: KVCacheTensorConfig,\n", "        v_cfg: KVCacheTensorConfig,\n", "        device: torch.device,\n", "    ):\n", "        self.k = SeqCacheTensor(batch_size=batch_size, max_seq_len=max_seq_len, dim=k_dim, cfg=k_cfg, device=device)\n", "        self.v = SeqCacheTensor(batch_size=batch_size, max_seq_len=max_seq_len, dim=v_dim, cfg=v_cfg, device=device)\n", "    @property\n", "    def pos(self) -> int:\n", "        return self.k.pos\n", "    def append(self, k_new: torch.Tensor, v_new: torch.Tensor) -> int:\n", "        old = self.k.append(k_new)\n", "        old2 = self.v.append(v_new)\n", "        if old != old2:\n", "            raise RuntimeError(\"K/V cache desync\")\n", "        return old\n", "    def get(self, *, dtype: torch.dtype = torch.float32) -> Tuple[torch.Tensor, torch.Tensor]:\n", "        return self.k.get(dtype=dtype), self.v.get(dtype=dtype)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DecoupledLayerKVCache:\n", "    def __init__(\n", "        self,\n", "        *,\n", "        batch_size: int,\n", "        max_seq_len: int,\n", "        k_sem_dim: int,\n", "        k_geo_dim: int,\n", "        v_dim: int,\n", "        k_sem_cfg: KVCacheTensorConfig,\n", "        k_geo_cfg: KVCacheTensorConfig,\n", "        v_cfg: KVCacheTensorConfig,\n", "        device: torch.device,\n", "    ):\n", "        self.k_sem = SeqCacheTensor(batch_size=batch_size, max_seq_len=max_seq_len, dim=k_sem_dim, cfg=k_sem_cfg, device=device)\n", "        self.k_geo = SeqCacheTensor(batch_size=batch_size, max_seq_len=max_seq_len, dim=k_geo_dim, cfg=k_geo_cfg, device=device)\n", "        self.v = SeqCacheTensor(batch_size=batch_size, max_seq_len=max_seq_len, dim=v_dim, cfg=v_cfg, device=device)\n", "    @property\n", "    def pos(self) -> int:\n", "        return self.k_sem.pos\n", "    def append(self, k_sem_new: torch.Tensor, k_geo_new: torch.Tensor, v_new: torch.Tensor) -> int:\n", "        old = self.k_sem.append(k_sem_new)\n", "        old2 = self.k_geo.append(k_geo_new)\n", "        old3 = self.v.append(v_new)\n", "        if not (old == old2 == old3):\n", "            raise RuntimeError(\"Decoupled cache desync\")\n", "        return old\n", "    def get(self, *, dtype: torch.dtype = torch.float32) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n", "        return self.k_sem.get(dtype=dtype), self.k_geo.get(dtype=dtype), self.v.get(dtype=dtype)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "Model<br>\n", "-----------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@dataclass\n", "class ModelConfig:\n", "    vocab_size: int\n", "    block_size: int\n", "    n_layer: int = 6\n", "    n_head: int = 8\n", "    kv_head: Optional[int] = None  # for GQA: number of KV heads (defaults to n_head)\n", "    d_model: int = 512\n", "    d_ff: int = 2048\n", "    embed_dim: int = 512  # lexical bottleneck if < d_model\n", "    attn_mode: Literal[\"standard\", \"bottleneck\", \"decoupled\", \"gqa\"] = \"bottleneck\"\n", "    attn_dim: int = 512    # total V dim (and Q/K dim for bottleneck)\n", "    sem_dim: int = 32      # total semantic Q/K dim across heads (decoupled)\n", "    geo_dim: int = 64      # total geometric Q/K dim across heads (decoupled)\n\n", "    # (Decoupled) Learn per-head sem/geo mixing weights (implemented as a sigmoid gate).\n", "    # Neutral init reproduces the old behavior exactly.\n", "    decoupled_gate: bool = True\n", "    rope: bool = True\n", "    rope_base: float = 10000.0\n", "    tie_qk: bool = False\n", "    null_attn: bool = False\n", "    learned_temp: bool = True\n", "    mlp: Literal[\"swiglu\", \"gelu\"] = \"swiglu\"\n", "    dropout: float = 0.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FeedForward(nn.Module):\n", "    def __init__(self, cfg: ModelConfig):\n", "        super().__init__()\n", "        self.cfg = cfg\n", "        self.drop = nn.Dropout(cfg.dropout)\n", "        if cfg.mlp == \"swiglu\":\n", "            self.w1 = nn.Linear(cfg.d_model, cfg.d_ff, bias=False)\n", "            self.w2 = nn.Linear(cfg.d_model, cfg.d_ff, bias=False)\n", "            self.w3 = nn.Linear(cfg.d_ff, cfg.d_model, bias=False)\n", "        elif cfg.mlp == \"gelu\":\n", "            self.w1 = nn.Linear(cfg.d_model, cfg.d_ff, bias=False)\n", "            self.w2 = nn.Linear(cfg.d_ff, cfg.d_model, bias=False)\n", "        else:\n", "            raise ValueError(cfg.mlp)\n", "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n", "        if self.cfg.mlp == \"swiglu\":\n", "            x = self.w3(F.silu(self.w1(x)) * self.w2(x))\n", "        else:\n", "            x = self.w2(F.gelu(self.w1(x)))\n", "        return self.drop(x)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DecoupledBottleneckAttention(nn.Module):\n", "    def __init__(self, cfg: ModelConfig):\n", "        super().__init__()\n", "        self.cfg = cfg\n", "        H = cfg.n_head\n", "        self.H = H\n", "        self.H_kv = H\n", "        self.group_size = 1\n", "        self.drop = nn.Dropout(cfg.dropout)\n\n", "        # (Decoupled) Optional per-head sem/geo mixing gate (created only in decoupled mode).\n", "        self.decoupled_gate_logit: Optional[torch.Tensor] = None\n", "        def must_div(name: str, total: int, denom: int) -> int:\n", "            if total % denom != 0:\n", "                raise ValueError(f\"{name} ({total}) must be divisible by {denom}\")\n", "            return total // denom\n", "        if cfg.attn_mode == \"standard\":\n", "            qk_dim = cfg.d_model\n", "            v_dim = cfg.d_model\n", "            self.qk_head_dim = must_div(\"d_model\", qk_dim, H)\n", "            self.v_head_dim = must_div(\"d_model\", v_dim, H)\n", "            self.q_proj = nn.Linear(cfg.d_model, qk_dim, bias=False)\n", "            self.k_proj = self.q_proj if cfg.tie_qk else nn.Linear(cfg.d_model, qk_dim, bias=False)\n", "            self.v_proj = nn.Linear(cfg.d_model, v_dim, bias=False)\n", "            self.out_proj = nn.Linear(v_dim, cfg.d_model, bias=False)\n", "            self.q_sem = self.k_sem = self.q_geo = self.k_geo = None\n", "            self.sem_head_dim = self.geo_head_dim = None\n", "            self.rotary = RotaryEmbedding(self.qk_head_dim, base=cfg.rope_base) if cfg.rope else None\n", "            self.k_null = nn.Parameter(torch.zeros(1, 1, qk_dim)) if cfg.null_attn else None\n", "            self.v_null = nn.Parameter(torch.zeros(1, 1, v_dim)) if cfg.null_attn else None\n", "            self.k_sem_null = self.k_geo_null = None\n", "        elif cfg.attn_mode == \"bottleneck\":\n", "            qk_dim = cfg.attn_dim\n", "            v_dim = cfg.attn_dim\n", "            self.qk_head_dim = must_div(\"attn_dim\", qk_dim, H)\n", "            self.v_head_dim = must_div(\"attn_dim\", v_dim, H)\n", "            if cfg.rope and (self.qk_head_dim % 2 != 0):\n", "                raise ValueError(\"RoPE needs even head dim; pick attn_dim divisible by 2*n_head\")\n", "            self.q_proj = nn.Linear(cfg.d_model, qk_dim, bias=False)\n", "            self.k_proj = self.q_proj if cfg.tie_qk else nn.Linear(cfg.d_model, qk_dim, bias=False)\n", "            self.v_proj = nn.Linear(cfg.d_model, v_dim, bias=False)\n", "            self.out_proj = nn.Linear(v_dim, cfg.d_model, bias=False)\n", "            self.q_sem = self.k_sem = self.q_geo = self.k_geo = None\n", "            self.sem_head_dim = self.geo_head_dim = None\n", "            self.rotary = RotaryEmbedding(self.qk_head_dim, base=cfg.rope_base) if cfg.rope else None\n", "            self.k_null = nn.Parameter(torch.zeros(1, 1, qk_dim)) if cfg.null_attn else None\n", "            self.v_null = nn.Parameter(torch.zeros(1, 1, v_dim)) if cfg.null_attn else None\n", "            self.k_sem_null = self.k_geo_null = None\n", "        elif cfg.attn_mode == \"gqa\":\n", "            # Grouped-Query Attention (GQA): Q has H heads, K/V has H_kv heads shared across groups.\n", "            kv_head = cfg.kv_head if cfg.kv_head is not None else H\n", "            if kv_head <= 0:\n", "                raise ValueError(\"kv_head must be > 0\")\n", "            if H % kv_head != 0:\n", "                raise ValueError(f\"gqa requires n_head % kv_head == 0 (got n_head={H}, kv_head={kv_head})\")\n", "            self.H_kv = kv_head\n", "            self.group_size = H // kv_head\n", "            self.qk_head_dim = must_div(\"attn_dim\", cfg.attn_dim, H)\n", "            self.v_head_dim = self.qk_head_dim\n", "            kv_dim = kv_head * self.qk_head_dim\n", "            if cfg.rope and (self.qk_head_dim % 2 != 0):\n", "                raise ValueError(\"RoPE requires an even head dim. Choose attn_dim divisible by 2*n_head.\")\n", "            if cfg.tie_qk:\n", "                raise ValueError(\"tie_qk is not supported for gqa unless kv_head == n_head (use --attn-mode standard).\")\n", "            self.q_proj = nn.Linear(cfg.d_model, cfg.attn_dim, bias=False)\n", "            self.k_proj = nn.Linear(cfg.d_model, kv_dim, bias=False)\n", "            self.v_proj = nn.Linear(cfg.d_model, kv_dim, bias=False)\n", "            self.out_proj = nn.Linear(cfg.attn_dim, cfg.d_model, bias=False)\n", "            self.q_sem = self.k_sem = self.q_geo = self.k_geo = None\n", "            self.sem_head_dim = self.geo_head_dim = None\n", "            self.rotary = RotaryEmbedding(self.qk_head_dim, base=cfg.rope_base) if cfg.rope else None\n", "            self.k_null = nn.Parameter(torch.zeros(1, 1, kv_dim)) if cfg.null_attn else None\n", "            self.v_null = nn.Parameter(torch.zeros(1, 1, kv_dim)) if cfg.null_attn else None\n", "            self.k_sem_null = self.k_geo_null = None\n", "        elif cfg.attn_mode == \"decoupled\":\n", "            self.sem_head_dim = must_div(\"sem_dim\", cfg.sem_dim, H)\n", "            self.geo_head_dim = must_div(\"geo_dim\", cfg.geo_dim, H)\n", "            self.v_head_dim = must_div(\"attn_dim\", cfg.attn_dim, H)\n", "            if cfg.rope and (self.geo_head_dim % 2 != 0):\n", "                raise ValueError(\"RoPE needs even geo_head_dim; pick geo_dim divisible by 2*n_head\")\n", "            self.q_sem = nn.Linear(cfg.d_model, cfg.sem_dim, bias=False)\n", "            self.k_sem = self.q_sem if cfg.tie_qk else nn.Linear(cfg.d_model, cfg.sem_dim, bias=False)\n", "            self.q_geo = nn.Linear(cfg.d_model, cfg.geo_dim, bias=False)\n", "            self.k_geo = self.q_geo if cfg.tie_qk else nn.Linear(cfg.d_model, cfg.geo_dim, bias=False)\n", "            self.v_proj = nn.Linear(cfg.d_model, cfg.attn_dim, bias=False)\n", "            self.out_proj = nn.Linear(cfg.attn_dim, cfg.d_model, bias=False)\n", "            self.q_proj = self.k_proj = None\n", "            self.qk_head_dim = None\n", "            self.rotary = RotaryEmbedding(self.geo_head_dim, base=cfg.rope_base) if cfg.rope else None\n", "            self.k_sem_null = nn.Parameter(torch.zeros(1, 1, cfg.sem_dim)) if cfg.null_attn else None\n", "            self.k_geo_null = nn.Parameter(torch.zeros(1, 1, cfg.geo_dim)) if cfg.null_attn else None\n", "            self.v_null = nn.Parameter(torch.zeros(1, 1, cfg.attn_dim)) if cfg.null_attn else None\n", "            self.k_null = None\n", "            if cfg.decoupled_gate:\n", "                # Per-head gate (sigmoid) controlling semantic vs geometric score contribution.\n", "                # Initialized to 0 => sigmoid=0.5, and we scale both branches so this is neutral (matches baseline).\n", "                self.decoupled_gate_logit = nn.Parameter(torch.zeros(H))\n", "        else:\n", "            raise ValueError(cfg.attn_mode)\n\n", "        # learned per-head temperature (applied as a multiplicative scale on logits)\n", "        self.logit_scale = nn.Parameter(torch.zeros(H)) if cfg.learned_temp else None\n", "        # Scratch buffers for Triton 2-pass (split-K) decode. Allocated lazily on CUDA.\n", "        self._flash2_scratch = None  # type: Optional[Tuple[torch.Tensor, torch.Tensor, torch.Tensor]]\n", "        self._flash2_scratch_cap = (0, 0, 0)  # (BH, parts_cap, hd_v)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def _shape(self, x: torch.Tensor, head_dim: int, H: Optional[int] = None) -> torch.Tensor:\n", "        # (B,T,H*hd)->(B,H,T,hd)\n", "        B, T, D = x.shape\n", "        H = self.H if H is None else H\n", "        return x.view(B, T, H, head_dim).transpose(1, 2).contiguous()\n", "    def _merge(self, x: torch.Tensor) -> torch.Tensor:\n", "        # (B,H,T,hd)->(B,T,H*hd)\n", "        B, H, T, hd = x.shape\n", "        return x.transpose(1, 2).contiguous().view(B, T, H * hd)\n", "    def _apply_logit_scale_to_q(self, q: torch.Tensor) -> torch.Tensor:\n", "        # scores = (q @ k^T) * exp(logit_scale)\n", "        if self.logit_scale is None:\n", "            return q\n", "        return q * torch.exp(self.logit_scale.view(1, -1, 1, 1))\n", "    def _sdp(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, attn_mask: Optional[torch.Tensor]) -> torch.Tensor:\n", "        # Use PyTorch's fused SDPA when available (Flash / mem-efficient attention).\n", "        # - If attn_mask is None, we can use is_causal=True and let the kernel handle causality.\n", "        # - If attn_mask is provided (e.g., chunked prefill with KV-cache), we pass it explicitly.\n", "        dropout_p = self.cfg.dropout if self.training else 0.0\n", "        if attn_mask is None:\n", "            return F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=dropout_p, is_causal=True)\n", "        return F.scaled_dot_product_attention(q, k, v, attn_mask=attn_mask, dropout_p=dropout_p, is_causal=False)\n", "    def _streaming_decode_attn(\n", "        self,\n", "        *,\n", "        q: torch.Tensor,          # (B,H,1,hd_qk)\n", "        k_cache: SeqCacheTensor,  # stores (B,L,H*hd_qk) merged\n", "        v_cache: SeqCacheTensor,  # stores (B,L,H*hd_v)  merged\n", "        head_dim: int,\n", "        decode_block: int,\n", "        scale: float,\n", "        v_head_dim: Optional[int] = None,\n", "        k_null: Optional[torch.Tensor] = None,   # (B,H,1,hd_qk) or None\n", "        v_null: Optional[torch.Tensor] = None,   # (B,H,1,hd_v)  or None\n", "    ) -> torch.Tensor:\n", "        \"\"\"\n", "        Streaming attention for decode (T==1): computes softmax(qK^T)V without materializing the full score vector.\n", "        Returns: (B,H,1,hd_v)\n", "        \"\"\"\n", "        B, H, Tq, hd = q.shape\n", "        assert Tq == 1\n", "        if v_head_dim is None:\n", "            v_head_dim = head_dim\n", "        L = k_cache.pos\n", "        if L != v_cache.pos:\n", "            raise RuntimeError(\"K/V cache desync in streaming decode\")\n\n", "        # We'll compute in fp32 for the running softmax state, but use fp16/bf16 matmuls where possible.\n", "        compute_dtype = q.dtype\n", "        m = torch.full((B, H, 1), -float(\"inf\"), device=q.device, dtype=torch.float32)\n", "        d = torch.zeros((B, H, 1), device=q.device, dtype=torch.float32)\n", "        o = torch.zeros((B, H, 1, v_head_dim), device=q.device, dtype=torch.float32)\n", "        qh = q.to(compute_dtype)\n", "        def update(scores_f32: torch.Tensor, v_block_f16: torch.Tensor) -> None:\n", "            nonlocal m, d, o\n", "            # scores_f32: (B,H,1,Bl)\n", "            block_max = scores_f32.amax(dim=-1)  # (B,H,1)\n", "            m_new = torch.maximum(m, block_max)\n", "            exp_m = torch.exp(m - m_new)  # (B,H,1)\n", "            exp_scores = torch.exp(scores_f32 - m_new.unsqueeze(-1))  # (B,H,1,Bl)\n", "            exp_scores_f16 = exp_scores.to(compute_dtype)\n", "            d = d * exp_m + exp_scores_f16.sum(dim=-1).to(torch.float32)  # (B,H,1)\n\n", "            # (B,H,1,Bl) @ (B,H,Bl,hd) -> (B,H,1,hd)\n", "            o = o * exp_m.unsqueeze(-1) + torch.matmul(exp_scores_f16, v_block_f16).to(torch.float32)\n", "            m = m_new\n\n", "        # Optional null token (one extra key/value)\n", "        if k_null is not None and v_null is not None:\n", "            # scores: (B,H,1,1)\n", "            s = (qh * k_null.to(compute_dtype)).sum(dim=-1, keepdim=True).to(torch.float32) * scale\n", "            update(s, v_null.to(compute_dtype))\n\n", "        # Stream over cached sequence in blocks.\n", "        blk = int(max(1, decode_block))\n", "        for start in range(0, L, blk):\n", "            end = min(L, start + blk)\n", "            k_blk = k_cache.get_slice(start, end, dtype=compute_dtype)  # (B,Bl,H*hd)\n", "            v_blk = v_cache.get_slice(start, end, dtype=compute_dtype)  # (B,Bl,H*hdv)\n", "            kbh = self._shape(k_blk, head_dim)                          # (B,H,Bl,hd)\n", "            vbh = self._shape(v_blk, v_head_dim)                        # (B,H,Bl,hdv)\n\n", "            # (B,H,1,hd) @ (B,H,hd,Bl) -> (B,H,1,Bl)\n", "            scores = torch.matmul(qh, kbh.transpose(-2, -1)) * scale\n", "            update(scores.to(torch.float32), vbh)\n", "        out = o / d.clamp(min=1e-9).unsqueeze(-1)\n", "        return out.to(q.dtype)\n", "    def _streaming_decode_attn_decoupled(\n", "        self,\n", "        *,\n", "        q_sem: torch.Tensor,          # (B,H,1,hd_sem)\n", "        q_geo: torch.Tensor,          # (B,H,1,hd_geo)\n", "        k_sem_cache: SeqCacheTensor,  # stores (B,L,H*hd_sem) merged\n", "        k_geo_cache: SeqCacheTensor,  # stores (B,L,H*hd_geo) merged\n", "        v_cache: SeqCacheTensor,      # stores (B,L,H*hd_v) merged\n", "        sem_head_dim: int,\n", "        geo_head_dim: int,\n", "        v_head_dim: int,\n", "        decode_block: int,\n", "        sem_scale: float,\n", "        geo_scale: float,\n", "        k_sem_null: Optional[torch.Tensor] = None,  # (B,H,1,hd_sem)\n", "        k_geo_null: Optional[torch.Tensor] = None,  # (B,H,1,hd_geo)\n", "        v_null: Optional[torch.Tensor] = None,      # (B,H,1,hd_v)\n", "    ) -> torch.Tensor:\n", "        B, H, Tq, _ = q_sem.shape\n", "        assert Tq == 1\n", "        L = k_sem_cache.pos\n", "        if not (L == k_geo_cache.pos == v_cache.pos):\n", "            raise RuntimeError(\"Decoupled cache desync in streaming decode\")\n", "        compute_dtype = q_sem.dtype\n", "        m = torch.full((B, H, 1), -float(\"inf\"), device=q_sem.device, dtype=torch.float32)\n", "        d = torch.zeros((B, H, 1), device=q_sem.device, dtype=torch.float32)\n", "        o = torch.zeros((B, H, 1, v_head_dim), device=q_sem.device, dtype=torch.float32)\n", "        qsh = q_sem.to(compute_dtype)\n", "        qgh = q_geo.to(compute_dtype)\n", "        def update(scores_f32: torch.Tensor, v_block_f16: torch.Tensor) -> None:\n", "            nonlocal m, d, o\n", "            block_max = scores_f32.amax(dim=-1)\n", "            m_new = torch.maximum(m, block_max)\n", "            exp_m = torch.exp(m - m_new)\n", "            exp_scores = torch.exp(scores_f32 - m_new.unsqueeze(-1))\n", "            exp_scores_f16 = exp_scores.to(compute_dtype)\n", "            d = d * exp_m + exp_scores_f16.sum(dim=-1).to(torch.float32)\n", "            o = o * exp_m.unsqueeze(-1) + torch.matmul(exp_scores_f16, v_block_f16).to(torch.float32)\n", "            m = m_new\n\n", "        # Optional null token.\n", "        if k_sem_null is not None and k_geo_null is not None and v_null is not None:\n", "            s = (\n", "                (qsh * k_sem_null.to(compute_dtype)).sum(dim=-1, keepdim=True).to(torch.float32) * sem_scale\n", "                + (qgh * k_geo_null.to(compute_dtype)).sum(dim=-1, keepdim=True).to(torch.float32) * geo_scale\n", "            )\n", "            update(s, v_null.to(compute_dtype))\n", "        blk = int(max(1, decode_block))\n", "        for start in range(0, L, blk):\n", "            end = min(L, start + blk)\n", "            k_sem_blk = k_sem_cache.get_slice(start, end, dtype=compute_dtype)  # (B,Bl,H*hd_sem)\n", "            k_geo_blk = k_geo_cache.get_slice(start, end, dtype=compute_dtype)  # (B,Bl,H*hd_geo)\n", "            v_blk = v_cache.get_slice(start, end, dtype=compute_dtype)          # (B,Bl,H*hd_v)\n", "            ksh = self._shape(k_sem_blk, sem_head_dim)  # (B,H,Bl,hd_sem)\n", "            kgh = self._shape(k_geo_blk, geo_head_dim)  # (B,H,Bl,hd_geo)\n", "            vbh = self._shape(v_blk, v_head_dim)        # (B,H,Bl,hd_v)\n", "            s = (\n", "                torch.matmul(qsh, ksh.transpose(-2, -1)).to(torch.float32) * sem_scale\n", "                + torch.matmul(qgh, kgh.transpose(-2, -1)).to(torch.float32) * geo_scale\n", "            )\n", "            update(s, vbh)\n", "        out = o / d.clamp(min=1e-9).unsqueeze(-1)\n", "        return out.to(q_sem.dtype)\n", "    def _fused_decode_attn_decoupled_q4q8q4(\n", "        self,\n", "        *,\n", "        q_sem: torch.Tensor,          # (B,H,1,hd_sem)\n", "        q_geo: torch.Tensor,          # (B,H,1,hd_geo)\n", "        cache: \"DecoupledLayerKVCache\",\n", "        sem_head_dim: int,\n", "        geo_head_dim: int,\n", "        v_head_dim: int,\n", "        decode_block: int,\n", "        sem_scale: float,\n", "        geo_scale: float,\n", "    ) -> torch.Tensor:\n", "        \"\"\"Decode-only fused path (T==1) for the common decoupled quant policy:\n", "          K_sem: q4_0  (merged dim = sem_dim)\n", "          K_geo: q8_0  (merged dim = geo_dim)\n", "          V:     q4_0  (merged dim = attn_dim)\n", "        Uses a Triton kernel (if installed) to fuse dequant + online-softmax update per block.\n", "        Falls back to Python streaming if Triton is unavailable.\n", "        \"\"\"\n", "        if not TRITON_AVAILABLE:\n", "            raise RuntimeError(\"Triton not available\")\n", "        if q_sem.device.type != \"cuda\":\n", "            raise RuntimeError(\"Fused decode requires CUDA\")\n", "        if self.cfg.null_attn:\n", "            raise RuntimeError(\"Fused decode currently assumes null_attn=False\")\n\n", "        # Enforce the expected cache layout.\n", "        if not (cache.k_sem.kind == \"q4_0\" and cache.k_geo.kind == \"q8_0\" and cache.v.kind == \"q4_0\"):\n", "            raise RuntimeError(\"Fused decode q4q8q4 requires k_sem=q4_0, k_geo=q8_0, v=q4_0\")\n", "        if not (cache.k_sem.spec.qblock == cache.k_geo.spec.qblock == cache.v.spec.qblock == 32):\n", "            raise RuntimeError(\"Fused decode currently assumes qblock=32\")\n", "        B, H, Tq, _ = q_sem.shape\n", "        assert Tq == 1\n", "        L = cache.pos\n\n", "        # Split into a big quantized prefix and an fp16 residual tail (processed in PyTorch).\n", "        rlen = cache.k_sem._residual_len_eff if cache.k_sem._residual is not None else 0\n", "        r_start = max(0, L - rlen) if rlen > 0 else L\n", "        L_prefix = int(r_start)\n\n", "        # Triton expects contiguous (B,H,hd) query tensors.\n", "        q_sem2 = q_sem[:, :, 0, :].contiguous().to(torch.float16)\n", "        q_geo2 = q_geo[:, :, 0, :].contiguous().to(torch.float16)\n\n", "        # Running state in fp32.\n", "        BH = B * H\n", "        m = torch.full((BH,), -float(\"inf\"), device=q_sem.device, dtype=torch.float32)\n", "        d = torch.zeros((BH,), device=q_sem.device, dtype=torch.float32)\n", "        o = torch.zeros((BH, v_head_dim), device=q_sem.device, dtype=torch.float32)\n", "        if L_prefix > 0:\n", "            # Kernel tiling + launch params. v25 lets these be tuned at runtime via cache attributes.\n", "            block_n = int(getattr(cache, \"block_n\", 128))\n", "            if block_n <= 0:\n", "                block_n = 128\n", "            num_sub = max(1, int(decode_block // block_n))\n", "            step = block_n * num_sub\n", "            num_warps = int(getattr(cache, \"num_warps_1pass\", 4))\n", "            num_stages = int(getattr(cache, \"num_stages_1pass\", 2))\n\n", "            # Shorthand tensors.\n", "            ksq = cache.k_sem.q\n", "            kss = cache.k_sem.s\n", "            kgq = cache.k_geo.q\n", "            kgs = cache.k_geo.s\n", "            vq = cache.v.q\n", "            vs = cache.v.s\n", "            assert ksq is not None and kss is not None and kgq is not None and kgs is not None and vq is not None and vs is not None\n", "            grid = (BH,)\n", "            for start in range(0, L_prefix, step):\n", "                _kv_decode_update_decoupled_q4q8q4[grid](\n", "                    q_sem2,\n", "                    q_geo2,\n", "                    ksq,\n", "                    kss,\n", "                    kgq,\n", "                    kgs,\n", "                    vq,\n", "                    vs,\n", "                    m,\n", "                    d,\n", "                    o,\n", "                    start,\n", "                    L_prefix,\n", "                    H=H,\n", "                    HD_SEM=sem_head_dim,\n", "                    HD_GEO=geo_head_dim,\n", "                    HD_V=v_head_dim,\n", "                    QBLOCK_SEM=32,\n", "                    QBLOCK_GEO=32,\n", "                    QBLOCK_V=32,\n", "                    SEM_SCALE=sem_scale,\n", "                    GEO_SCALE=geo_scale,\n", "                    BLOCK_N=block_n,\n", "                    NUM_SUBBLOCKS=num_sub,\n", "                    stride_qsem_b=q_sem2.stride(0),\n", "                    stride_qsem_h=q_sem2.stride(1),\n", "                    stride_qgeo_b=q_geo2.stride(0),\n", "                    stride_qgeo_h=q_geo2.stride(1),\n", "                    stride_ksq_b=ksq.stride(0),\n", "                    stride_ksq_t=ksq.stride(1),\n", "                    stride_kss_b=kss.stride(0),\n", "                    stride_kss_t=kss.stride(1),\n", "                    stride_kss_c=kss.stride(2),\n", "                    stride_kgq_b=kgq.stride(0),\n", "                    stride_kgq_t=kgq.stride(1),\n", "                    stride_kgs_b=kgs.stride(0),\n", "                    stride_kgs_t=kgs.stride(1),\n", "                    stride_kgs_c=kgs.stride(2),\n", "                    stride_vq_b=vq.stride(0),\n", "                    stride_vq_t=vq.stride(1),\n", "                    stride_vs_b=vs.stride(0),\n", "                    stride_vs_t=vs.stride(1),\n", "                    stride_vs_c=vs.stride(2),\n", "                    stride_o=o.stride(0),\n", "                    num_warps=num_warps,\n", "                    num_stages=num_stages,\n", "                )\n\n", "        # Process residual tail in PyTorch (small; uses fp16 residual ring via get_slice).\n", "        if L_prefix < L:\n", "            qsh = q_sem.to(torch.float16)\n", "            qgh = q_geo.to(torch.float16)\n\n", "            # reshape state to (B,H,1) / (B,H,1,hd)\n", "            m_t = m.view(B, H, 1)\n", "            d_t = d.view(B, H, 1)\n", "            o_t = o.view(B, H, 1, v_head_dim)\n", "            def update(scores_f32: torch.Tensor, v_block_f16: torch.Tensor) -> None:\n", "                nonlocal m_t, d_t, o_t\n", "                block_max = scores_f32.amax(dim=-1)\n", "                m_new = torch.maximum(m_t, block_max)\n", "                exp_m = torch.exp(m_t - m_new)\n", "                exp_scores = torch.exp(scores_f32 - m_new.unsqueeze(-1)).to(torch.float16)\n", "                d_t = d_t * exp_m + exp_scores.sum(dim=-1).to(torch.float32)\n", "                o_t = o_t * exp_m.unsqueeze(-1) + torch.matmul(exp_scores, v_block_f16).to(torch.float32)\n", "                m_t = m_new\n\n", "            # one or a few blocks only\n", "            k_sem_blk = cache.k_sem.get_slice(L_prefix, L, dtype=torch.float16)\n", "            k_geo_blk = cache.k_geo.get_slice(L_prefix, L, dtype=torch.float16)\n", "            v_blk = cache.v.get_slice(L_prefix, L, dtype=torch.float16)\n", "            ksh = self._shape(k_sem_blk, sem_head_dim)\n", "            kgh = self._shape(k_geo_blk, geo_head_dim)\n", "            vbh = self._shape(v_blk, v_head_dim)\n", "            s = (\n", "                torch.matmul(qsh, ksh.transpose(-2, -1)).to(torch.float32) * sem_scale\n", "                + torch.matmul(qgh, kgh.transpose(-2, -1)).to(torch.float32) * geo_scale\n", "            )\n", "            update(s, vbh)\n\n", "            # flatten back\n", "            m = m_t.view(BH)\n", "            d = d_t.view(BH)\n", "            o = o_t.view(BH, v_head_dim)\n", "        out = (o / d.clamp(min=1e-9).unsqueeze(-1)).view(B, H, 1, v_head_dim)\n", "        return out.to(q_sem.dtype)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def _fused_decode_attn_decoupled_q4q8q4_2pass(\n", "        self,\n", "        *,\n", "        q_sem: torch.Tensor,          # (B,H,1,hd_sem)\n", "        q_geo: torch.Tensor,          # (B,H,1,hd_geo)\n", "        cache: \"DecoupledLayerKVCache\",\n", "        sem_head_dim: int,\n", "        geo_head_dim: int,\n", "        v_head_dim: int,\n", "        decode_block: int,\n", "        sem_scale: float,\n", "        geo_scale: float,\n", "    ) -> torch.Tensor:\n", "        \"\"\"Decode-only fused path (T==1) using a 2-pass split-K (\"FlashAttention-style\") kernel.\n", "        Pass 1 computes local (m, d, o) for each partition of the KV sequence in parallel.\n", "        Pass 2 reduces partitions into a single (m, d, o) for the row.\n", "        A tiny fp16 residual tail (hot window) is then folded in via the Python streaming updater.\n", "        Specializes to the common decoupled heterogeneous quant policy:\n", "          K_sem: q4_0  (merged dim = sem_dim)\n", "          K_geo: q8_0  (merged dim = geo_dim)\n", "          V:     q4_0  (merged dim = attn_dim)\n", "        \"\"\"\n", "        if not TRITON_AVAILABLE:\n", "            raise RuntimeError(\"Triton not available\")\n", "        if q_sem.device.type != \"cuda\":\n", "            raise RuntimeError(\"Fused decode requires CUDA\")\n", "        if self.cfg.null_attn:\n", "            raise RuntimeError(\"Fused decode currently assumes null_attn=False\")\n\n", "        # Enforce the expected cache layout.\n", "        if not (cache.k_sem.kind == \"q4_0\" and cache.k_geo.kind == \"q8_0\" and cache.v.kind == \"q4_0\"):\n", "            raise RuntimeError(\"Fused decode q4q8q4 requires k_sem=q4_0, k_geo=q8_0, v=q4_0\")\n", "        if not (cache.k_sem.spec.qblock == cache.k_geo.spec.qblock == cache.v.spec.qblock == 32):\n", "            raise RuntimeError(\"Fused decode currently assumes qblock=32\")\n", "        B, H, Tq, _ = q_sem.shape\n", "        assert Tq == 1\n", "        L = cache.pos\n\n", "        # Split into a big quantized prefix and an fp16 residual tail (processed in PyTorch).\n", "        rlen = cache.k_sem._residual_len_eff if cache.k_sem._residual is not None else 0\n", "        r_start = max(0, L - rlen) if rlen > 0 else L\n", "        L_prefix = int(r_start)\n\n", "        # Queries: contiguous (B,H,hd)\n", "        q_sem2 = q_sem[:, :, 0, :].contiguous().to(torch.float16)\n", "        q_geo2 = q_geo[:, :, 0, :].contiguous().to(torch.float16)\n", "        BH = B * H\n\n", "        # Running state in fp32 (flattened).\n", "        m = torch.full((BH,), -float(\"inf\"), device=q_sem.device, dtype=torch.float32)\n", "        d = torch.zeros((BH,), device=q_sem.device, dtype=torch.float32)\n", "        o = torch.zeros((BH, v_head_dim), device=q_sem.device, dtype=torch.float32)\n", "        if L_prefix > 0:\n", "            # Partition sizing:\n", "            # - decode_block is the user-facing knob. We round it up to a multiple of BLOCK_N.\n", "            # - v25 lets BLOCK_N + launch params be tuned at runtime via cache attributes.\n", "            block_n = int(getattr(cache, \"block_n\", 128))\n", "            if block_n <= 0:\n", "                block_n = 128\n", "            num_warps_part = int(getattr(cache, \"num_warps_part\", 4))\n", "            num_stages_part = int(getattr(cache, \"num_stages_part\", 2))\n", "            num_warps_reduce = int(getattr(cache, \"num_warps_reduce\", 1))\n", "            num_stages_reduce = int(getattr(cache, \"num_stages_reduce\", 1))\n", "            part_size = int(max(block_n, decode_block))\n", "            if part_size % block_n != 0:\n", "                part_size = ((part_size + block_n - 1) // block_n) * block_n\n", "            num_sub = part_size // block_n\n", "            P = int((L_prefix + part_size - 1) // part_size)\n\n", "            # Allocate/reuse scratch buffers (BH, P_cap).\n", "            # We grow capacity to the next power-of-two to reduce realloc+recompile churn.\n", "            P_cap = 1 << (int(P - 1).bit_length())\n", "            cap_BH, cap_P, cap_V = self._flash2_scratch_cap\n", "            if (self._flash2_scratch is None) or (cap_BH < BH) or (cap_P < P_cap) or (cap_V != v_head_dim):\n", "                m_part = torch.empty((BH, P_cap), device=q_sem.device, dtype=torch.float32)\n", "                d_part = torch.empty((BH, P_cap), device=q_sem.device, dtype=torch.float32)\n", "                o_part = torch.empty((BH, P_cap, v_head_dim), device=q_sem.device, dtype=torch.float32)\n", "                self._flash2_scratch = (m_part, d_part, o_part)\n", "                self._flash2_scratch_cap = (BH, P_cap, v_head_dim)\n", "            else:\n", "                m_part, d_part, o_part = self._flash2_scratch\n\n", "            # Shorthand quant tensors.\n", "            ksq = cache.k_sem.q\n", "            kss = cache.k_sem.s\n", "            kgq = cache.k_geo.q\n", "            kgs = cache.k_geo.s\n", "            vq = cache.v.q\n", "            vs = cache.v.s\n", "            assert ksq is not None and kss is not None and kgq is not None and kgs is not None and vq is not None and vs is not None\n\n", "            # Pass 1: partition stats\n", "            grid1 = (BH, P)\n", "            _kv_decode_partition_stats_decoupled_q4q8q4[grid1](\n", "                q_sem2,\n", "                q_geo2,\n", "                ksq,\n", "                kss,\n", "                kgq,\n", "                kgs,\n", "                vq,\n", "                vs,\n", "                m_part,\n", "                d_part,\n", "                o_part,\n", "                L_prefix,\n", "                P,\n", "                PARTITION_SIZE=part_size,\n", "                H=H,\n", "                HD_SEM=sem_head_dim,\n", "                HD_GEO=geo_head_dim,\n", "                HD_V=v_head_dim,\n", "                QBLOCK_SEM=32,\n", "                QBLOCK_GEO=32,\n", "                QBLOCK_V=32,\n", "                SEM_SCALE=sem_scale,\n", "                GEO_SCALE=geo_scale,\n", "                BLOCK_N=block_n,\n", "                NUM_SUBBLOCKS=num_sub,\n", "                stride_qsem_b=q_sem2.stride(0),\n", "                stride_qsem_h=q_sem2.stride(1),\n", "                stride_qgeo_b=q_geo2.stride(0),\n", "                stride_qgeo_h=q_geo2.stride(1),\n", "                stride_ksq_b=ksq.stride(0),\n", "                stride_ksq_t=ksq.stride(1),\n", "                stride_kss_b=kss.stride(0),\n", "                stride_kss_t=kss.stride(1),\n", "                stride_kss_c=kss.stride(2),\n", "                stride_kgq_b=kgq.stride(0),\n", "                stride_kgq_t=kgq.stride(1),\n", "                stride_kgs_b=kgs.stride(0),\n", "                stride_kgs_t=kgs.stride(1),\n", "                stride_kgs_c=kgs.stride(2),\n", "                stride_vq_b=vq.stride(0),\n", "                stride_vq_t=vq.stride(1),\n", "                stride_vs_b=vs.stride(0),\n", "                stride_vs_t=vs.stride(1),\n", "                stride_vs_c=vs.stride(2),\n", "                stride_mp_row=m_part.stride(0),\n", "                stride_mp_part=m_part.stride(1),\n", "                stride_dp_row=d_part.stride(0),\n", "                stride_dp_part=d_part.stride(1),\n", "                stride_op_row=o_part.stride(0),\n", "                stride_op_part=o_part.stride(1),\n", "                num_warps=num_warps_part,\n", "                num_stages=num_stages_part,\n", "            )\n\n", "            # Pass 2: reduce partitions -> (m, d, o) for the prefix.\n", "            grid2 = (BH,)\n", "            _kv_decode_reduce_partitions[grid2](\n", "                m_part,\n", "                d_part,\n", "                o_part,\n", "                m,\n", "                d,\n", "                o,\n", "                P,\n", "                NUM_PARTS=P_cap,\n", "                HD_V=v_head_dim,\n", "                stride_mp_row=m_part.stride(0),\n", "                stride_mp_part=m_part.stride(1),\n", "                stride_dp_row=d_part.stride(0),\n", "                stride_dp_part=d_part.stride(1),\n", "                stride_op_row=o_part.stride(0),\n", "                stride_op_part=o_part.stride(1),\n", "                stride_o=o.stride(0),\n", "                num_warps=num_warps_reduce,\n", "                num_stages=num_stages_reduce,\n", "            )\n\n", "        # Process residual tail in PyTorch (small; uses fp16 residual ring via get_slice).\n", "        if L_prefix < L:\n", "            qsh = q_sem.to(torch.float16)\n", "            qgh = q_geo.to(torch.float16)\n\n", "            # reshape state to (B,H,1) / (B,H,1,hd)\n", "            m_t = m.view(B, H, 1)\n", "            d_t = d.view(B, H, 1)\n", "            o_t = o.view(B, H, 1, v_head_dim)\n", "            def update(scores_f32: torch.Tensor, v_block_f16: torch.Tensor) -> None:\n", "                nonlocal m_t, d_t, o_t\n", "                block_max = scores_f32.amax(dim=-1)\n", "                m_new = torch.maximum(m_t, block_max)\n", "                exp_m = torch.exp(m_t - m_new)\n", "                exp_scores = torch.exp(scores_f32 - m_new.unsqueeze(-1)).to(torch.float16)\n", "                d_t = d_t * exp_m + exp_scores.sum(dim=-1).to(torch.float32)\n", "                o_t = o_t * exp_m.unsqueeze(-1) + torch.matmul(exp_scores, v_block_f16).to(torch.float32)\n", "                m_t = m_new\n", "            k_sem_blk = cache.k_sem.get_slice(L_prefix, L, dtype=torch.float16)\n", "            k_geo_blk = cache.k_geo.get_slice(L_prefix, L, dtype=torch.float16)\n", "            v_blk = cache.v.get_slice(L_prefix, L, dtype=torch.float16)\n", "            ksh = self._shape(k_sem_blk, sem_head_dim)\n", "            kgh = self._shape(k_geo_blk, geo_head_dim)\n", "            vbh = self._shape(v_blk, v_head_dim)\n", "            s = (\n", "                torch.matmul(qsh, ksh.transpose(-2, -1)).to(torch.float32) * sem_scale\n", "                + torch.matmul(qgh, kgh.transpose(-2, -1)).to(torch.float32) * geo_scale\n", "            )\n", "            update(s, vbh)\n", "            m = m_t.view(BH)\n", "            d = d_t.view(BH)\n", "            o = o_t.view(BH, v_head_dim)\n", "        out = (o / d.clamp(min=1e-9).unsqueeze(-1)).view(B, H, 1, v_head_dim)\n", "        return out.to(q_sem.dtype)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def _streaming_decode_attn_gqa(\n", "        self,\n", "        *,\n", "        q: torch.Tensor,          # (B,H,1,hd)\n", "        k_cache: SeqCacheTensor,  # stores (B,L,H_kv*hd)\n", "        v_cache: SeqCacheTensor,  # stores (B,L,H_kv*hd)\n", "        head_dim: int,\n", "        decode_block: int,\n", "        scale: float,\n", "        k_null: Optional[torch.Tensor] = None,  # (B,H_kv,1,hd) or None\n", "        v_null: Optional[torch.Tensor] = None,  # (B,H_kv,1,hd) or None\n", "    ) -> torch.Tensor:\n", "        \"\"\"\n", "        Streaming decode for GQA without expanding KV heads to Q heads.\n", "        Returns: (B,H,1,hd)\n", "        \"\"\"\n", "        B, H, Tq, hd = q.shape\n", "        assert Tq == 1\n", "        H_kv = self.H_kv\n", "        g = self.group_size\n", "        if H != H_kv * g:\n", "            raise RuntimeError(\"Invalid GQA head geometry\")\n", "        L = k_cache.pos\n", "        if L != v_cache.pos:\n", "            raise RuntimeError(\"K/V cache desync in streaming decode (gqa)\")\n", "        compute_dtype = q.dtype\n", "        m = torch.full((B, H, 1), -float(\"inf\"), device=q.device, dtype=torch.float32)\n", "        d = torch.zeros((B, H, 1), device=q.device, dtype=torch.float32)\n", "        o = torch.zeros((B, H, 1, hd), device=q.device, dtype=torch.float32)\n", "        qh = q.to(compute_dtype)\n", "        # reshape Q into KV groups: (B,H_kv,g,1,hd)\n", "        qg = qh.view(B, H_kv, g, 1, hd)\n", "        def update(scores_f32: torch.Tensor, v_block_f16: torch.Tensor) -> None:\n", "            nonlocal m, d, o\n", "            # scores_f32: (B,H,1,Bl)\n", "            block_max = scores_f32.amax(dim=-1)\n", "            m_new = torch.maximum(m, block_max)\n", "            exp_m = torch.exp(m - m_new)\n", "            exp_scores = torch.exp(scores_f32 - m_new.unsqueeze(-1))\n", "            exp_scores_f16 = exp_scores.to(compute_dtype)\n", "            d = d * exp_m + exp_scores_f16.sum(dim=-1).to(torch.float32)\n\n", "            # matmul in groups:\n", "            # exp_scores: (B,H,1,Bl) -> (B,H_kv,g,1,Bl)\n", "            es = exp_scores_f16.view(B, H_kv, g, 1, -1)\n", "            # v_block_f16: (B,H_kv,Bl,hd) -> (B,H_kv,1,Bl,hd)\n", "            vb = v_block_f16.unsqueeze(2)  # (B,H_kv,1,Bl,hd)\n", "            # (B,H_kv,g,1,Bl) @ (B,H_kv,1,Bl,hd) -> (B,H_kv,g,1,hd)\n", "            out_blk = torch.matmul(es, vb).to(torch.float32)\n", "            o = o * exp_m.unsqueeze(-1) + out_blk.view(B, H, 1, hd)\n", "            m = m_new\n\n", "        # Optional null token (KV-head count).\n", "        if k_null is not None and v_null is not None:\n", "            # Expand to query heads logically by grouping.\n", "            # scores: (B,H_kv,g,1,1) -> view (B,H,1,1)\n", "            s = (qg * k_null.to(compute_dtype).unsqueeze(2)).sum(dim=-1, keepdim=True).to(torch.float32) * scale\n", "            update(s.view(B, H, 1, 1), v_null.to(compute_dtype).unsqueeze(2).view(B, H, 1, hd))\n", "        blk = int(max(1, decode_block))\n", "        for start in range(0, L, blk):\n", "            end = min(L, start + blk)\n", "            k_blk = k_cache.get_slice(start, end, dtype=compute_dtype)  # (B,Bl,H_kv*hd)\n", "            v_blk = v_cache.get_slice(start, end, dtype=compute_dtype)  # (B,Bl,H_kv*hd)\n", "            kbh = self._shape(k_blk, head_dim, H=H_kv)                   # (B,H_kv,Bl,hd)\n", "            vbh = self._shape(v_blk, head_dim, H=H_kv)                   # (B,H_kv,Bl,hd)\n\n", "            # scores per kv head/group: (B,H_kv,g,1,Bl)\n", "            s = torch.matmul(qg, kbh.unsqueeze(2).transpose(-2, -1)) * scale\n", "            update(s.view(B, H, 1, -1).to(torch.float32), vbh)\n", "        out = o / d.clamp(min=1e-9).unsqueeze(-1)\n", "        return out.to(q.dtype)\n", "    def forward(\n", "        self,\n", "        x: torch.Tensor,\n", "        *,\n", "        attn_mask: Optional[torch.Tensor],\n", "        cache: Optional[Any],\n", "        pos_offset: int,\n", "    ) -> Tuple[torch.Tensor, Optional[Any]]:\n", "        \"\"\"\n", "        x: (B,T,d_model)\n", "        attn_mask:\n", "          - training: causal mask (B,1,T,T) bool, or None when using SDPA causal.\n", "          - cached prefill: mask (B,1,T,L) bool to enforce causality inside the new chunk.\n", "        cache:\n", "          - None (training)\n", "          - LayerKVCache (standard/bottleneck/gqa)\n", "          - DecoupledLayerKVCache (decoupled)\n", "        pos_offset: absolute position for RoPE for x[:,0]\n", "        \"\"\"\n", "        cfg = self.cfg\n", "        B, T, _ = x.shape\n", "        ninfty = neg_inf(x.dtype)\n\n", "        # -----------------------------\n", "        # standard / bottleneck\n", "        # -----------------------------\n", "        if cfg.attn_mode in (\"standard\", \"bottleneck\"):\n", "            q = self.q_proj(x)\n", "            k = self.k_proj(x)\n", "            v = self.v_proj(x)\n", "            qh = self._shape(q, self.qk_head_dim)\n", "            kh = self._shape(k, self.qk_head_dim)\n", "            vh = self._shape(v, self.v_head_dim)\n", "            if self.rotary is not None:\n", "                qh = self.rotary.rotate(qh, pos_offset)\n", "                kh = self.rotary.rotate(kh, pos_offset)\n", "            qh = self._apply_logit_scale_to_q(qh)\n\n", "            # ---- training / full-attn ----\n", "            if cache is None:\n", "                if not cfg.null_attn:\n", "                    # Prefer SDPA/Flash when possible.\n", "                    out = self._sdp(qh, kh, vh, attn_mask=None if attn_mask is None else attn_mask)\n", "                    y = self.out_proj(self._merge(out))\n", "                    return y, None\n", "                # Null-attn path (manual).\n", "                scores = torch.matmul(qh, kh.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                if attn_mask is not None:\n", "                    scores = scores.masked_fill(~attn_mask, ninfty)\n", "                k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim)\n", "                v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "                s_null = torch.matmul(qh, k_null.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                if attn_mask is not None:\n", "                    extra = torch.ones((1, 1, T, 1), device=attn_mask.device, dtype=attn_mask.dtype)\n", "                    keep = torch.cat([extra, attn_mask], dim=-1)\n", "                    scores = scores.masked_fill(~keep, ninfty)\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                vals = torch.cat([v_null, vh], dim=-2)\n", "                out = torch.matmul(attn, vals)\n", "                y = self.out_proj(self._merge(out))\n", "                return y, None\n\n", "            # ---- KV-cache path ----\n", "            old_len = cache.pos\n\n", "            # Fast prefill when the cache is empty: compute attention from local K/V, then append.\n", "            if old_len == 0 and T > 1:\n", "                if not cfg.null_attn:\n", "                    out = self._sdp(qh, kh, vh, attn_mask=None if attn_mask is None else attn_mask)\n", "                    y = self.out_proj(self._merge(out))\n", "                    cache.append(self._merge(kh), self._merge(vh))\n", "                    return y, cache\n", "                # Null-attn prefill (manual).\n", "                scores = torch.matmul(qh, kh.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                if attn_mask is not None:\n", "                    scores = scores.masked_fill(~attn_mask, ninfty)\n", "                k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim)\n", "                v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "                s_null = torch.matmul(qh, k_null.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                if attn_mask is not None:\n", "                    extra = torch.ones((1, 1, T, 1), device=attn_mask.device, dtype=attn_mask.dtype)\n", "                    keep = torch.cat([extra, attn_mask], dim=-1)\n", "                    scores = scores.masked_fill(~keep, ninfty)\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                vals = torch.cat([v_null, vh], dim=-2)\n", "                out = torch.matmul(attn, vals)\n", "                y = self.out_proj(self._merge(out))\n", "                cache.append(self._merge(kh), self._merge(vh))\n", "                return y, cache\n\n", "            # General cached path: append, then attend over the full cache.\n", "            cache.append(self._merge(kh), self._merge(vh))\n", "            L = cache.pos\n\n", "            # Decode streaming for T==1 (critical for long context).\n", "            if T == 1:\n", "                decode_block = getattr(cache, \"decode_block\", 1024)\n", "                if cfg.null_attn:\n", "                    k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim)\n", "                    v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "                else:\n", "                    k_null = v_null = None\n", "                if cache.k.is_quantized or cache.v.is_quantized or cfg.null_attn:\n", "                    out = self._streaming_decode_attn(\n", "                        q=qh,\n", "                        k_cache=cache.k,\n", "                        v_cache=cache.v,\n", "                        head_dim=self.qk_head_dim,\n", "                        v_head_dim=self.v_head_dim,\n", "                        decode_block=decode_block,\n", "                        scale=(1.0 / math.sqrt(self.qk_head_dim)),\n", "                        k_null=k_null,\n", "                        v_null=v_null,\n", "                    )\n", "                else:\n", "                    # fp16 cache on GPU -> SDPA is usually faster than Python streaming\n", "                    k_all = self._shape(cache.k.get(dtype=qh.dtype), self.qk_head_dim)\n", "                    v_all = self._shape(cache.v.get(dtype=qh.dtype), self.v_head_dim)\n", "                    out = F.scaled_dot_product_attention(qh, k_all, v_all, attn_mask=None, dropout_p=0.0, is_causal=False)\n", "                y = self.out_proj(self._merge(out))\n", "                return y, cache\n\n", "            # Prefill/chunked attention (T>1): fallback (materializes K/V). This is still O(T*L).\n", "            k_all, v_all = cache.get(dtype=x.dtype)\n", "            kh_all = self._shape(k_all, self.qk_head_dim)\n", "            vh_all = self._shape(v_all, self.v_head_dim)\n", "            scores = torch.matmul(qh, kh_all.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)  # (B,H,T,L)\n", "            if attn_mask is not None:\n", "                scores = scores.masked_fill(~attn_mask, ninfty)\n", "            elif T > 1:\n", "                key_pos = torch.arange(L, device=x.device).view(1, 1, 1, L)\n", "                q_pos = (old_len + torch.arange(T, device=x.device)).view(1, 1, T, 1)\n", "                keep = key_pos <= q_pos\n", "                scores = scores.masked_fill(~keep, ninfty)\n", "            if cfg.null_attn:\n", "                k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim)\n", "                v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "                s_null = torch.matmul(qh, k_null.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                vals = torch.cat([v_null, vh_all], dim=-2)\n", "                out = torch.matmul(attn, vals)\n", "            else:\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                out = torch.matmul(attn, vh_all)\n", "            y = self.out_proj(self._merge(out))\n", "            return y, cache\n\n", "        # -----------------------------\n", "        # gqa\n", "        # -----------------------------\n", "        if cfg.attn_mode == \"gqa\":\n", "            q = self.q_proj(x)\n", "            k = self.k_proj(x)\n", "            v = self.v_proj(x)\n", "            qh = self._shape(q, self.qk_head_dim, H=self.H)               # (B,H,T,hd)\n", "            kh = self._shape(k, self.qk_head_dim, H=self.H_kv)            # (B,H_kv,T,hd)\n", "            vh = self._shape(v, self.v_head_dim, H=self.H_kv)             # (B,H_kv,T,hd)\n", "            if self.rotary is not None:\n", "                qh = self.rotary.rotate(qh, pos_offset)\n", "                kh = self.rotary.rotate(kh, pos_offset)\n", "            qh = self._apply_logit_scale_to_q(qh)\n", "            if cache is None:\n", "                # For simplicity (and because this is a research file), we do a straightforward broadcast.\n", "                kh_rep = kh.repeat_interleave(self.group_size, dim=1)  # (B,H,T,hd)\n", "                vh_rep = vh.repeat_interleave(self.group_size, dim=1)  # (B,H,T,hd)\n", "                if not cfg.null_attn:\n", "                    out = self._sdp(qh, kh_rep, vh_rep, attn_mask=None if attn_mask is None else attn_mask)\n", "                    y = self.out_proj(self._merge(out))\n", "                    return y, None\n", "                scores = torch.matmul(qh, kh_rep.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                if attn_mask is not None:\n", "                    scores = scores.masked_fill(~attn_mask, ninfty)\n", "                k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim, H=self.H_kv)\n", "                v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim, H=self.H_kv)\n", "                k_null_rep = k_null.repeat_interleave(self.group_size, dim=1)\n", "                v_null_rep = v_null.repeat_interleave(self.group_size, dim=1)\n", "                s_null = torch.matmul(qh, k_null_rep.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                if attn_mask is not None:\n", "                    extra = torch.ones((1, 1, T, 1), device=attn_mask.device, dtype=attn_mask.dtype)\n", "                    keep = torch.cat([extra, attn_mask], dim=-1)\n", "                    scores = scores.masked_fill(~keep, ninfty)\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                vals = torch.cat([v_null_rep, vh_rep], dim=-2)\n", "                out = torch.matmul(attn, vals)\n", "                y = self.out_proj(self._merge(out))\n", "                return y, None\n", "            old_len = cache.pos\n", "            if old_len == 0 and T > 1:\n", "                # prefill without cache readback\n", "                kh_rep = kh.repeat_interleave(self.group_size, dim=1)\n", "                vh_rep = vh.repeat_interleave(self.group_size, dim=1)\n", "                if not cfg.null_attn:\n", "                    out = self._sdp(qh, kh_rep, vh_rep, attn_mask=None if attn_mask is None else attn_mask)\n", "                    y = self.out_proj(self._merge(out))\n", "                    cache.append(self._merge(kh), self._merge(vh))\n", "                    return y, cache\n", "                # null-attn prefill (manual)\n", "                scores = torch.matmul(qh, kh_rep.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                if attn_mask is not None:\n", "                    scores = scores.masked_fill(~attn_mask, ninfty)\n", "                k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim, H=self.H_kv)\n", "                v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim, H=self.H_kv)\n", "                k_null_rep = k_null.repeat_interleave(self.group_size, dim=1)\n", "                v_null_rep = v_null.repeat_interleave(self.group_size, dim=1)\n", "                s_null = torch.matmul(qh, k_null_rep.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                if attn_mask is not None:\n", "                    extra = torch.ones((1, 1, T, 1), device=attn_mask.device, dtype=attn_mask.dtype)\n", "                    keep = torch.cat([extra, attn_mask], dim=-1)\n", "                    scores = scores.masked_fill(~keep, ninfty)\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                vals = torch.cat([v_null_rep, vh_rep], dim=-2)\n", "                out = torch.matmul(attn, vals)\n", "                y = self.out_proj(self._merge(out))\n", "                cache.append(self._merge(kh), self._merge(vh))\n", "                return y, cache\n", "            cache.append(self._merge(kh), self._merge(vh))\n", "            L = cache.pos\n", "            if T == 1:\n", "                decode_block = getattr(cache, \"decode_block\", 1024)\n", "                if cfg.null_attn:\n", "                    k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim, H=self.H_kv)\n", "                    v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim, H=self.H_kv)\n", "                else:\n", "                    k_null = v_null = None\n", "                out = self._streaming_decode_attn_gqa(\n", "                    q=qh,\n", "                    k_cache=cache.k,\n", "                    v_cache=cache.v,\n", "                    head_dim=self.qk_head_dim,\n", "                    decode_block=decode_block,\n", "                    scale=(1.0 / math.sqrt(self.qk_head_dim)),\n", "                    k_null=k_null,\n", "                    v_null=v_null,\n", "                )\n", "                y = self.out_proj(self._merge(out))\n", "                return y, cache\n\n", "            # T>1 fallback\n", "            k_all, v_all = cache.get(dtype=x.dtype)\n", "            kh_all = self._shape(k_all, self.qk_head_dim, H=self.H_kv).repeat_interleave(self.group_size, dim=1)\n", "            vh_all = self._shape(v_all, self.v_head_dim, H=self.H_kv).repeat_interleave(self.group_size, dim=1)\n", "            scores = torch.matmul(qh, kh_all.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "            if attn_mask is not None:\n", "                scores = scores.masked_fill(~attn_mask, ninfty)\n", "            elif T > 1:\n", "                key_pos = torch.arange(L, device=x.device).view(1, 1, 1, L)\n", "                q_pos = (old_len + torch.arange(T, device=x.device)).view(1, 1, T, 1)\n", "                keep = key_pos <= q_pos\n", "                scores = scores.masked_fill(~keep, ninfty)\n", "            if cfg.null_attn:\n", "                k_null = self._shape(self.k_null.expand(B, 1, -1), self.qk_head_dim, H=self.H_kv).repeat_interleave(self.group_size, dim=1)\n", "                v_null = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim, H=self.H_kv).repeat_interleave(self.group_size, dim=1)\n", "                s_null = torch.matmul(qh, k_null.transpose(-2, -1)) / math.sqrt(self.qk_head_dim)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                vals = torch.cat([v_null, vh_all], dim=-2)\n", "                out = torch.matmul(attn, vals)\n", "            else:\n", "                attn = F.softmax(scores, dim=-1)\n", "                attn = self.drop(attn)\n", "                out = torch.matmul(attn, vh_all)\n", "            y = self.out_proj(self._merge(out))\n", "            return y, cache\n\n", "        # -----------------------------\n", "        # decoupled\n", "        # -----------------------------\n", "        q_sem = self.q_sem(x)\n", "        k_sem = self.k_sem(x)\n", "        q_geo = self.q_geo(x)\n", "        k_geo = self.k_geo(x)\n", "        v = self.v_proj(x)\n", "        qsh = self._shape(q_sem, self.sem_head_dim)\n", "        ksh = self._shape(k_sem, self.sem_head_dim)\n", "        qgh = self._shape(q_geo, self.geo_head_dim)\n", "        kgh = self._shape(k_geo, self.geo_head_dim)\n", "        vh = self._shape(v, self.v_head_dim)\n", "        if self.rotary is not None:\n", "            qgh = self.rotary.rotate(qgh, pos_offset)\n", "            kgh = self.rotary.rotate(kgh, pos_offset)\n\n", "        # Apply per-head temperature to both paths by scaling Q.\n", "        qsh = self._apply_logit_scale_to_q(qsh)\n", "        qgh = self._apply_logit_scale_to_q(qgh)\n\n", "        # (Decoupled) Optional per-head mixing gate between semantic vs geometric scores.\n", "        # We scale both branches so that gate=0.5 reproduces the original behavior (weight 1.0 on each path).\n", "        if self.decoupled_gate_logit is not None:\n", "            g = torch.sigmoid(self.decoupled_gate_logit).view(1, -1, 1, 1).to(dtype=qsh.dtype, device=qsh.device)\n", "            sem_w = 2.0 * g\n", "            geo_w = 2.0 * (1.0 - g)\n", "            qsh = qsh * sem_w\n", "            qgh = qgh * geo_w\n", "        sem_scale = 1.0 / math.sqrt(self.sem_head_dim)\n", "        geo_scale = 1.0 / math.sqrt(self.geo_head_dim)\n", "        if cache is None:\n", "            if not cfg.null_attn:\n", "                # Combine into a single SDPA call by concatenating along head_dim.\n", "                q_cat = torch.cat([qsh * sem_scale, qgh * geo_scale], dim=-1)\n", "                k_cat = torch.cat([ksh, kgh], dim=-1)\n", "                out = self._sdp(q_cat, k_cat, vh, attn_mask=None if attn_mask is None else attn_mask)\n", "                y = self.out_proj(self._merge(out))\n", "                return y, None\n\n", "            # Null-attn manual path\n", "            sem = torch.matmul(qsh, ksh.transpose(-2, -1)) * sem_scale\n", "            geo = torch.matmul(qgh, kgh.transpose(-2, -1)) * geo_scale\n", "            scores = sem + geo\n", "            if attn_mask is not None:\n", "                scores = scores.masked_fill(~attn_mask, ninfty)\n", "            ksn = self._shape(self.k_sem_null.expand(B, 1, -1), self.sem_head_dim)\n", "            kgn = self._shape(self.k_geo_null.expand(B, 1, -1), self.geo_head_dim)\n", "            vn = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "            s_null = (torch.matmul(qsh, ksn.transpose(-2, -1)) * sem_scale + torch.matmul(qgh, kgn.transpose(-2, -1)) * geo_scale)\n", "            scores = torch.cat([s_null, scores], dim=-1)\n", "            if attn_mask is not None:\n", "                extra = torch.ones((1, 1, T, 1), device=attn_mask.device, dtype=attn_mask.dtype)\n", "                keep = torch.cat([extra, attn_mask], dim=-1)\n", "                scores = scores.masked_fill(~keep, ninfty)\n", "            attn = F.softmax(scores, dim=-1)\n", "            attn = self.drop(attn)\n", "            vals = torch.cat([vn, vh], dim=-2)\n", "            out = torch.matmul(attn, vals)\n", "            y = self.out_proj(self._merge(out))\n", "            return y, None\n", "        old_len = cache.pos\n\n", "        # Empty-cache prefill: compute locally, then append (no dequant).\n", "        if old_len == 0 and T > 1:\n", "            if not cfg.null_attn:\n", "                q_cat = torch.cat([qsh * sem_scale, qgh * geo_scale], dim=-1)\n", "                k_cat = torch.cat([ksh, kgh], dim=-1)\n", "                out = self._sdp(q_cat, k_cat, vh, attn_mask=None if attn_mask is None else attn_mask)\n", "                y = self.out_proj(self._merge(out))\n", "                cache.append(self._merge(ksh), self._merge(kgh), self._merge(vh))\n", "                return y, cache\n\n", "            # Null-attn prefill manual\n", "            sem = torch.matmul(qsh, ksh.transpose(-2, -1)) * sem_scale\n", "            geo = torch.matmul(qgh, kgh.transpose(-2, -1)) * geo_scale\n", "            scores = sem + geo\n", "            if attn_mask is not None:\n", "                scores = scores.masked_fill(~attn_mask, ninfty)\n", "            ksn = self._shape(self.k_sem_null.expand(B, 1, -1), self.sem_head_dim)\n", "            kgn = self._shape(self.k_geo_null.expand(B, 1, -1), self.geo_head_dim)\n", "            vn = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "            s_null = (torch.matmul(qsh, ksn.transpose(-2, -1)) * sem_scale + torch.matmul(qgh, kgn.transpose(-2, -1)) * geo_scale)\n", "            scores = torch.cat([s_null, scores], dim=-1)\n", "            if attn_mask is not None:\n", "                extra = torch.ones((1, 1, T, 1), device=attn_mask.device, dtype=attn_mask.dtype)\n", "                keep = torch.cat([extra, attn_mask], dim=-1)\n", "                scores = scores.masked_fill(~keep, ninfty)\n", "            attn = F.softmax(scores, dim=-1)\n", "            attn = self.drop(attn)\n", "            vals = torch.cat([vn, vh], dim=-2)\n", "            out = torch.matmul(attn, vals)\n", "            y = self.out_proj(self._merge(out))\n", "            cache.append(self._merge(ksh), self._merge(kgh), self._merge(vh))\n", "            return y, cache\n\n", "        # General cached path.\n", "        cache.append(self._merge(ksh), self._merge(kgh), self._merge(vh))\n", "        L = cache.pos\n\n", "        # Streaming decode for T==1.\n", "        if T == 1:\n", "            decode_block = getattr(cache, \"decode_block\", 1024)\n", "            if cfg.null_attn:\n", "                ksn = self._shape(self.k_sem_null.expand(B, 1, -1), self.sem_head_dim)\n", "                kgn = self._shape(self.k_geo_null.expand(B, 1, -1), self.geo_head_dim)\n", "                vn = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "            else:\n", "                ksn = kgn = vn = None\n", "            if cache.k_sem.is_quantized or cache.k_geo.is_quantized or cache.v.is_quantized or cfg.null_attn:\n", "                # Prefer fused kernels when available/allowed.\n", "                use_fused = getattr(cache, \"fused\", \"none\")\n", "                fused_ok = (\n", "                    (not cfg.null_attn)\n", "                    and use_fused in (\"auto\", \"triton1pass\", \"triton2pass\")\n", "                    and _triton_decoupled_q4q8q4_available()\n", "                    and cache.k_sem.kind == \"q4_0\"\n", "                    and cache.k_geo.kind == \"q8_0\"\n", "                    and cache.v.kind == \"q4_0\"\n", "                )\n", "                if fused_ok:\n", "                    try:\n", "                        if use_fused == \"triton1pass\":\n", "                            out = self._fused_decode_attn_decoupled_q4q8q4(\n", "                                q_sem=qsh,\n", "                                q_geo=qgh,\n", "                                cache=cache,\n", "                                sem_head_dim=self.sem_head_dim,\n", "                                geo_head_dim=self.geo_head_dim,\n", "                                v_head_dim=self.v_head_dim,\n", "                                decode_block=decode_block,\n", "                                sem_scale=sem_scale,\n", "                                geo_scale=geo_scale,\n", "                            )\n", "                        elif use_fused == \"triton2pass\":\n", "                            out = self._fused_decode_attn_decoupled_q4q8q4_2pass(\n", "                                q_sem=qsh,\n", "                                q_geo=qgh,\n", "                                cache=cache,\n", "                                sem_head_dim=self.sem_head_dim,\n", "                                geo_head_dim=self.geo_head_dim,\n", "                                v_head_dim=self.v_head_dim,\n", "                                decode_block=decode_block,\n", "                                sem_scale=sem_scale,\n", "                                geo_scale=geo_scale,\n", "                            )\n", "                        else:\n", "                            # auto: 2-pass when the sequence is \"long enough\" that split-K parallelism helps.\n", "                            if cache.pos >= 4 * int(decode_block):\n", "                                out = self._fused_decode_attn_decoupled_q4q8q4_2pass(\n", "                                    q_sem=qsh,\n", "                                    q_geo=qgh,\n", "                                    cache=cache,\n", "                                    sem_head_dim=self.sem_head_dim,\n", "                                    geo_head_dim=self.geo_head_dim,\n", "                                    v_head_dim=self.v_head_dim,\n", "                                    decode_block=decode_block,\n", "                                    sem_scale=sem_scale,\n", "                                    geo_scale=geo_scale,\n", "                                )\n", "                            else:\n", "                                out = self._fused_decode_attn_decoupled_q4q8q4(\n", "                                    q_sem=qsh,\n", "                                    q_geo=qgh,\n", "                                    cache=cache,\n", "                                    sem_head_dim=self.sem_head_dim,\n", "                                    geo_head_dim=self.geo_head_dim,\n", "                                    v_head_dim=self.v_head_dim,\n", "                                    decode_block=decode_block,\n", "                                    sem_scale=sem_scale,\n", "                                    geo_scale=geo_scale,\n", "                                )\n", "                    except Exception:\n", "                        out = self._streaming_decode_attn_decoupled(\n", "                            q_sem=qsh,\n", "                            q_geo=qgh,\n", "                            k_sem_cache=cache.k_sem,\n", "                            k_geo_cache=cache.k_geo,\n", "                            v_cache=cache.v,\n", "                            sem_head_dim=self.sem_head_dim,\n", "                            geo_head_dim=self.geo_head_dim,\n", "                            v_head_dim=self.v_head_dim,\n", "                            decode_block=decode_block,\n", "                            sem_scale=sem_scale,\n", "                            geo_scale=geo_scale,\n", "                            k_sem_null=ksn,\n", "                            k_geo_null=kgn,\n", "                            v_null=vn,\n", "                        )\n", "                else:\n", "                    out = self._streaming_decode_attn_decoupled(\n", "                        q_sem=qsh,\n", "                        q_geo=qgh,\n", "                        k_sem_cache=cache.k_sem,\n", "                        k_geo_cache=cache.k_geo,\n", "                        v_cache=cache.v,\n", "                        sem_head_dim=self.sem_head_dim,\n", "                        geo_head_dim=self.geo_head_dim,\n", "                        v_head_dim=self.v_head_dim,\n", "                        decode_block=decode_block,\n", "                        sem_scale=sem_scale,\n", "                        geo_scale=geo_scale,\n", "                        k_sem_null=ksn,\n", "                        k_geo_null=kgn,\n", "                        v_null=vn,\n", "                    )\n", "            else:\n", "                # fp16 cache -> materialize and use SDPA\n", "                k_sem_all = self._shape(cache.k_sem.get(dtype=qsh.dtype), self.sem_head_dim)\n", "                k_geo_all = self._shape(cache.k_geo.get(dtype=qsh.dtype), self.geo_head_dim)\n", "                v_all = self._shape(cache.v.get(dtype=qsh.dtype), self.v_head_dim)\n", "                q_cat = torch.cat([qsh * sem_scale, qgh * geo_scale], dim=-1)\n", "                k_cat = torch.cat([k_sem_all, k_geo_all], dim=-1)\n", "                out = F.scaled_dot_product_attention(q_cat, k_cat, v_all, attn_mask=None, dropout_p=0.0, is_causal=False)\n", "            y = self.out_proj(self._merge(out))\n", "            return y, cache\n\n", "        # T>1 fallback (materialize).\n", "        k_sem_all, k_geo_all, v_all = cache.get(dtype=x.dtype)\n", "        ksh_all = self._shape(k_sem_all, self.sem_head_dim)\n", "        kgh_all = self._shape(k_geo_all, self.geo_head_dim)\n", "        vh_all = self._shape(v_all, self.v_head_dim)\n", "        sem = torch.matmul(qsh, ksh_all.transpose(-2, -1)) * sem_scale\n", "        geo = torch.matmul(qgh, kgh_all.transpose(-2, -1)) * geo_scale\n", "        scores = sem + geo\n", "        if attn_mask is not None:\n", "            scores = scores.masked_fill(~attn_mask, ninfty)\n", "        elif T > 1:\n", "            key_pos = torch.arange(L, device=x.device).view(1, 1, 1, L)\n", "            q_pos = (old_len + torch.arange(T, device=x.device)).view(1, 1, T, 1)\n", "            keep = key_pos <= q_pos\n", "            scores = scores.masked_fill(~keep, ninfty)\n", "        if cfg.null_attn:\n", "            ksn = self._shape(self.k_sem_null.expand(B, 1, -1), self.sem_head_dim)\n", "            kgn = self._shape(self.k_geo_null.expand(B, 1, -1), self.geo_head_dim)\n", "            vn = self._shape(self.v_null.expand(B, 1, -1), self.v_head_dim)\n", "            s_null = (torch.matmul(qsh, ksn.transpose(-2, -1)) * sem_scale + torch.matmul(qgh, kgn.transpose(-2, -1)) * geo_scale)\n", "            scores = torch.cat([s_null, scores], dim=-1)\n", "            attn = F.softmax(scores, dim=-1)\n", "            attn = self.drop(attn)\n", "            vals = torch.cat([vn, vh_all], dim=-2)\n", "            out = torch.matmul(attn, vals)\n", "        else:\n", "            attn = F.softmax(scores, dim=-1)\n", "            attn = self.drop(attn)\n", "            out = torch.matmul(attn, vh_all)\n", "        y = self.out_proj(self._merge(out))\n", "        return y, cache"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Block(nn.Module):\n", "    def __init__(self, cfg: ModelConfig):\n", "        super().__init__()\n", "        self.ln1 = nn.LayerNorm(cfg.d_model)\n", "        self.attn = DecoupledBottleneckAttention(cfg)\n", "        self.ln2 = nn.LayerNorm(cfg.d_model)\n", "        self.ff = FeedForward(cfg)\n", "    def forward(self, x: torch.Tensor, *, attn_mask: Optional[torch.Tensor], cache: Optional[Any], pos_offset: int) -> Tuple[torch.Tensor, Optional[Any]]:\n", "        a, cache = self.attn(self.ln1(x), attn_mask=attn_mask, cache=cache, pos_offset=pos_offset)\n", "        x = x + a\n", "        x = x + self.ff(self.ln2(x))\n", "        return x, cache"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class GPT(nn.Module):\n", "    def __init__(self, cfg: ModelConfig):\n", "        super().__init__()\n", "        self.cfg = cfg\n\n", "        # lexical bottleneck\n", "        self.tok_emb = nn.Embedding(cfg.vocab_size, cfg.embed_dim)\n", "        self.emb_in = nn.Linear(cfg.embed_dim, cfg.d_model, bias=False) if cfg.embed_dim != cfg.d_model else None\n", "        self.emb_out = nn.Linear(cfg.d_model, cfg.embed_dim, bias=False) if cfg.embed_dim != cfg.d_model else None\n", "        self.drop = nn.Dropout(cfg.dropout)\n", "        self.blocks = nn.ModuleList([Block(cfg) for _ in range(cfg.n_layer)])\n", "        self.ln_f = nn.LayerNorm(cfg.d_model)\n", "        self.register_buffer(\n", "            \"causal_mask\",\n", "            torch.tril(torch.ones(cfg.block_size, cfg.block_size, dtype=torch.bool)).view(1, 1, cfg.block_size, cfg.block_size),\n", "            persistent=False,\n", "        )\n", "        self.apply(self._init_weights)\n\n", "        # Training-only toggles (not part of ModelConfig)\n", "        self.grad_checkpointing = False\n", "    def _init_weights(self, m: nn.Module) -> None:\n", "        if isinstance(m, (nn.Linear, nn.Embedding)):\n", "            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n", "    def forward(\n", "        self,\n", "        idx: torch.Tensor,\n", "        *,\n", "        caches: Optional[List[Any]] = None,\n", "        pos_offset: int = 0,\n", "    ) -> Tuple[torch.Tensor, Optional[List[Any]]]:\n", "        B, T = idx.shape\n", "        if caches is None and T > self.cfg.block_size:\n", "            raise ValueError(f\"Sequence length {T} > block_size {self.cfg.block_size}. Increase --block.\")\n", "        x = self.tok_emb(idx)\n", "        if self.emb_in is not None:\n", "            x = self.emb_in(x)\n", "        x = self.drop(x)\n\n", "        # Attention mask strategy:\n", "        # - Training (no cache):\n", "        #     * if null_attn is disabled, we pass attn_mask=None and let SDPA run with is_causal=True.\n", "        #     * if null_attn is enabled (manual attention path), we provide a causal boolean mask.\n", "        # - Cached prefill (T>1):\n", "        #     * build a (1,1,T,L) boolean mask so the new chunk can attend to the prefix + causal within itself.\n", "        #     * if cache is empty and null_attn is disabled, we again pass attn_mask=None so SDPA can use is_causal=True.\n", "        # - Decode (T==1): no mask needed.\n", "        attn_mask: Optional[torch.Tensor] = None\n", "        if caches is None:\n", "            if self.cfg.null_attn:\n", "                attn_mask = self.causal_mask[:, :, :T, :T]\n", "            else:\n", "                attn_mask = None\n", "        else:\n", "            if T > 1:\n", "                prev_len = caches[0].pos\n", "                if prev_len == 0 and (not self.cfg.null_attn):\n", "                    attn_mask = None\n", "                else:\n", "                    L = prev_len + T\n", "                    key_pos = torch.arange(L, device=idx.device).view(1, 1, 1, L)\n", "                    q_pos = (prev_len + torch.arange(T, device=idx.device)).view(1, 1, T, 1)\n", "                    attn_mask = key_pos <= q_pos\n", "            else:\n", "                attn_mask = None\n", "        new_caches: Optional[List[Any]] = [] if caches is not None else None\n\n", "        # Training memory saver: gradient checkpointing (only when not using KV cache).\n", "        if caches is None and self.training and getattr(self, \"grad_checkpointing\", False):\n", "            try:\n", "                from torch.utils.checkpoint import checkpoint  # type: ignore\n", "                for blk in self.blocks:\n", "                    def _blk_fwd(x_in: torch.Tensor, blk=blk) -> torch.Tensor:\n", "                        y, _ = blk(x_in, attn_mask=attn_mask, cache=None, pos_offset=pos_offset)\n", "                        return y\n", "                    x = checkpoint(_blk_fwd, x, use_reentrant=False)\n", "            except Exception:\n", "                # Fallback: run without checkpointing\n", "                for blk in self.blocks:\n", "                    x, _ = blk(x, attn_mask=attn_mask, cache=None, pos_offset=pos_offset)\n", "        elif caches is None:\n", "            for blk in self.blocks:\n", "                x, _ = blk(x, attn_mask=attn_mask, cache=None, pos_offset=pos_offset)\n", "        else:\n", "            for i, blk in enumerate(self.blocks):\n", "                layer_cache = caches[i]\n", "                x, layer_cache = blk(x, attn_mask=attn_mask, cache=layer_cache, pos_offset=pos_offset)\n", "                new_caches.append(layer_cache)\n", "        x = self.ln_f(x)\n", "        if self.emb_out is not None:\n", "            x_small = self.emb_out(x)\n", "        else:\n", "            x_small = x\n", "        logits = x_small @ self.tok_emb.weight.t()\n", "        return logits, new_caches\n", "    @torch.no_grad()\n", "    def generate(\n", "        self,\n", "        prompt: torch.Tensor,\n", "        *,\n", "        max_new_tokens: int,\n", "        temperature: float = 1.0,\n", "        top_k: Optional[int] = None,\n", "        # KV-cache controls (these matter *a lot* at long context)\n", "        kv_cache: KVCacheKind = \"fp16\",\n", "        kv_qblock: int = 32,\n", "        kv_residual: int = 128,\n", "        kv_decode_block: int = 1024,\n", "        kv_fused: str = \"auto\",  # {none, auto, triton1pass, triton2pass}\n", "        # v25 self-optimizer (optional): picks decode knobs that are fastest on this GPU.\n", "        self_opt: Optional[\"KVSelfOptConfig\"] = None,\n", "        # Optional heterogeneous overrides\n", "        kv_cache_k: Optional[KVCacheKind] = None,\n", "        kv_cache_v: Optional[KVCacheKind] = None,\n", "        kv_cache_k_sem: Optional[KVCacheKind] = None,\n", "        kv_cache_k_geo: Optional[KVCacheKind] = None,\n", "        kv_qblock_k: Optional[int] = None,\n", "        kv_qblock_v: Optional[int] = None,\n", "        kv_qblock_k_sem: Optional[int] = None,\n", "        kv_qblock_k_geo: Optional[int] = None,\n", "        log_callback: Optional[Any] = None,\n", "    ) -> torch.Tensor:\n", "        \"\"\"Autoregressive generation with optional heterogeneous KV-cache quantization.\n", "        The cache API supports fp16/fp32/q8_0/q4_0/nf4, plus an fp16 residual window for the newest tokens.\n", "        \"\"\"\n", "        was_training = self.training\n", "        self.eval()\n", "        device = prompt.device\n", "        B, T0 = prompt.shape\n", "        max_seq = T0 + max_new_tokens\n", "        if kv_fused not in (\"none\", \"auto\", \"triton1pass\", \"triton2pass\"):\n", "            raise ValueError(\"kv_fused must be one of: none, auto, triton1pass, triton2pass\")\n\n", "        # Heterogeneous default for decoupled mode:\n", "        # - Per the draft paper: keep the RoPE/geometric key path higher precision, compress the semantic path harder.\n", "        #   (You can override this with --kv-cache-k-sem / --kv-cache-k-geo.)\n", "        if self.cfg.attn_mode == \"decoupled\" and kv_cache == \"q4_0\":\n", "            if kv_cache_k_geo is None:\n", "                kv_cache_k_geo = \"q8_0\"\n", "            if kv_cache_k_sem is None:\n", "                kv_cache_k_sem = \"q4_0\"\n", "            if kv_cache_v is None:\n", "                kv_cache_v = \"q4_0\"\n", "        def make_cfg(kind_override: Optional[KVCacheKind], qblock_override: Optional[int]) -> KVCacheTensorConfig:\n", "            kind = kind_override if kind_override is not None else kv_cache\n", "            qblock = qblock_override if qblock_override is not None else kv_qblock\n", "            residual_len = kv_residual if kind not in (\"fp16\", \"fp32\") else 0\n", "            return KVCacheTensorConfig(kind=kind, qblock=qblock, residual_len=residual_len)\n\n", "        # default K/V configs (standard/bottleneck/gqa)\n", "        k_cfg = make_cfg(kv_cache_k, kv_qblock_k)\n", "        v_cfg = make_cfg(kv_cache_v, kv_qblock_v)\n\n", "        # decoupled configs\n", "        k_sem_cfg = make_cfg(kv_cache_k_sem, kv_qblock_k_sem)\n", "        k_geo_cfg = make_cfg(kv_cache_k_geo, kv_qblock_k_geo)\n", "        v_dec_cfg = make_cfg(kv_cache_v, kv_qblock_v)\n\n", "        # v26: cache-policy self-opt (startup only).\n", "        # This chooses: kv_residual hot-window length, quant kinds, qblocks (within a strict memory budget).\n", "        if (\n", "            self_opt is not None\n", "            and getattr(self_opt, \"mode\", \"none\") != \"none\"\n", "            and getattr(self_opt, \"scope\", \"all\") in (\"cache\", \"all\")\n", "            and self.cfg.attn_mode == \"decoupled\"\n", "        ):\n", "            try:\n", "                base_policy = KVCachePolicy(\n", "                    k_sem_kind=k_sem_cfg.kind,\n", "                    k_geo_kind=k_geo_cfg.kind,\n", "                    v_kind=v_dec_cfg.kind,\n", "                    k_sem_qblock=k_sem_cfg.qblock,\n", "                    k_geo_qblock=k_geo_cfg.qblock,\n", "                    v_qblock=v_dec_cfg.qblock,\n", "                    residual_len=int(kv_residual),\n", "                )\n", "                pol_tuner = KVCachePolicySelfOptimizer(\n", "                    self_opt,\n", "                    device=device,\n", "                    attn=self.blocks[0].attn,\n", "                    model_cfg=self.cfg,\n", "                    batch_size=B,\n", "                    max_seq_len=max_seq,\n", "                    base_policy=base_policy,\n", "                    base_decode_block=kv_decode_block,\n", "                    base_fused=kv_fused,\n", "                )\n", "                chosen = pol_tuner.choose_policy(prompt_len=T0)\n", "                # Optional policy quality guard: teacher-forced logits vs an fp16-cache baseline.\n", "                # This is intentionally tiny (few steps) so it stays usable in practice.\n", "                if getattr(self_opt, \"policy_quality\", False):\n", "                    try:\n", "                        calib_spec = getattr(self_opt, \"calib_tokens\", None)\n", "                        if calib_spec:\n", "                            calib_ids = load_token_ids_spec(str(calib_spec))\n", "                            calib = torch.tensor([calib_ids], device=device, dtype=torch.long)\n", "                        else:\n", "                            calib = prompt.detach()\n", "                        compute_kl = bool(\n", "                            getattr(self_opt, \"quality_compute_kl\", False)\n", "                            or (getattr(self_opt, \"quality_kl_tol\", None) is not None)\n", "                        )\n", "                        qm = self._policy_quality_metrics_decoupled(\n", "                            calib,\n", "                            policy=chosen,\n", "                            prefill=int(getattr(self_opt, \"calib_prefill\", 64)),\n", "                            decode_steps=int(getattr(self_opt, \"calib_decode_steps\", 8)),\n", "                            kv_decode_block=int(kv_decode_block),\n", "                            compute_kl=compute_kl,\n", "                        )\n", "                        maxerr = float(qm.get(\"max_abs_logit\", float(\"inf\")))\n", "                        tol = float(getattr(self_opt, \"quality_tol\", 0.5))\n", "                        delta_nll_tol = getattr(self_opt, \"quality_delta_nll_tol\", None)\n", "                        ppl_ratio_tol = getattr(self_opt, \"quality_ppl_ratio_tol\", None)\n", "                        kl_tol = getattr(self_opt, \"quality_kl_tol\", None)\n", "                        reject_reasons: List[str] = []\n", "                        if maxerr > tol:\n", "                            reject_reasons.append(f\"max|\u0394logit|={maxerr:.4g} > {tol:.4g}\")\n", "                        try:\n", "                            dnll = float(qm.get(\"delta_nll\", float(\"nan\")))\n", "                        except Exception:\n", "                            dnll = float(\"nan\")\n", "                        if delta_nll_tol is not None and not math.isnan(dnll):\n", "                            if dnll > float(delta_nll_tol):\n", "                                reject_reasons.append(f\"\u0394NLL={dnll:.4g} > {float(delta_nll_tol):.4g} nats/tok\")\n", "                        try:\n", "                            pr = float(qm.get(\"ppl_ratio\", float(\"nan\")))\n", "                        except Exception:\n", "                            pr = float(\"nan\")\n", "                        if ppl_ratio_tol is not None and not math.isnan(pr):\n", "                            if pr > float(ppl_ratio_tol):\n", "                                reject_reasons.append(f\"ppl_ratio={pr:.4g} > {float(ppl_ratio_tol):.4g}\")\n", "                        try:\n", "                            klv = float(qm.get(\"kl_base_cand\", float(\"nan\")))\n", "                        except Exception:\n", "                            klv = float(\"nan\")\n", "                        if kl_tol is not None and not math.isnan(klv):\n", "                            if klv > float(kl_tol):\n", "                                reject_reasons.append(f\"KL(base||cand)={klv:.4g} > {float(kl_tol):.4g} nats/tok\")\n", "                        if reject_reasons:\n", "                            if getattr(self_opt, \"verbose\", False):\n", "                                msg = \", \".join(reject_reasons)\n", "                                print(f\"[selfopt] cache-policy rejected by quality guard: {msg} (falling back)\")\n", "                            chosen = base_policy\n", "                        elif getattr(self_opt, \"verbose\", False):\n", "                            # Log a compact summary (metrics may be NaN if calibration too short).\n", "                            print(\n", "                                f\"[selfopt] cache-policy quality ok: \"\n", "                                f\"max|\u0394logit|={maxerr:.4g} \"\n", "                                f\"\u0394NLL={dnll:.4g} ppl_ratio={pr:.4g} KL={klv:.4g}\"\n", "                            )\n", "                    except Exception as e:\n", "                        if getattr(self_opt, \"verbose\", False):\n", "                            print(f\"[selfopt] cache-policy quality check skipped (error): {e}\")\n", "                k_sem_cfg, k_geo_cfg, v_dec_cfg = chosen.to_tensor_cfgs()\n", "                if getattr(self_opt, \"verbose\", False):\n", "                    print(f\"[selfopt] cache-policy active: {chosen.short()}\")\n", "            except Exception as e:\n", "                if getattr(self_opt, \"verbose\", False):\n", "                    print(f\"[selfopt] cache-policy tuning failed, falling back: {e}\")\n", "        caches: List[Any] = []\n", "        for _ in range(self.cfg.n_layer):\n", "            if self.cfg.attn_mode == \"decoupled\":\n", "                c = DecoupledLayerKVCache(\n", "                    batch_size=B,\n", "                    max_seq_len=max_seq,\n", "                    k_sem_dim=self.cfg.sem_dim,\n", "                    k_geo_dim=self.cfg.geo_dim,\n", "                    v_dim=self.cfg.attn_dim,\n", "                    k_sem_cfg=k_sem_cfg,\n", "                    k_geo_cfg=k_geo_cfg,\n", "                    v_cfg=v_dec_cfg,\n", "                    device=device,\n", "                )\n", "                c.decode_block = kv_decode_block\n", "                c.fused = kv_fused\n", "                caches.append(c)\n", "            else:\n", "                if self.cfg.attn_mode == \"standard\":\n", "                    k_dim = v_dim = self.cfg.d_model\n", "                elif self.cfg.attn_mode == \"bottleneck\":\n", "                    k_dim = v_dim = self.cfg.attn_dim\n", "                elif self.cfg.attn_mode == \"gqa\":\n", "                    head_dim = self.cfg.attn_dim // self.cfg.n_head\n", "                    kv_head = self.cfg.kv_head if self.cfg.kv_head is not None else self.cfg.n_head\n", "                    k_dim = v_dim = kv_head * head_dim\n", "                else:\n", "                    raise ValueError(f\"Unknown attn_mode for KV cache: {self.cfg.attn_mode}\")\n", "                c = LayerKVCache(\n", "                    batch_size=B,\n", "                    max_seq_len=max_seq,\n", "                    k_dim=k_dim,\n", "                    v_dim=v_dim,\n", "                    k_cfg=k_cfg,\n", "                    v_cfg=v_cfg,\n", "                    device=device,\n", "                )\n", "                c.decode_block = kv_decode_block\n", "                c.fused = kv_fused\n", "                caches.append(c)\n\n", "        # Prefill (fills caches). Thanks to the attention module, the \"empty-cache prefill\" path avoids cache readback.\n", "        logits, caches = self(prompt, caches=caches, pos_offset=0)\n\n", "        # v25: runtime self-optimizer for decode performance (optional).\n", "        tuner: Optional[KVDecodeSelfOptimizer] = None\n", "        if self_opt is not None and getattr(self_opt, \"mode\", \"none\") != \"none\":\n", "            tuner = KVDecodeSelfOptimizer(\n", "                self_opt,\n", "                device=device,\n", "                base_fused=kv_fused,\n", "                base_decode_block=kv_decode_block,\n", "                log_callback=log_callback,\n", "            )\n", "        out = prompt\n", "        for _ in range(max_new_tokens):\n", "            next_logits = logits[:, -1, :] / max(temperature, 1e-8)\n", "            if top_k is not None:\n", "                v, _ = torch.topk(next_logits, min(top_k, next_logits.size(-1)))\n", "                next_logits = next_logits.masked_fill(next_logits < v[:, [-1]], neg_inf(next_logits.dtype))\n", "            probs = F.softmax(next_logits, dim=-1)\n", "            next_id = torch.multinomial(probs, num_samples=1)\n", "            out = torch.cat([out, next_id], dim=1)\n\n", "            # v25 self-opt: set per-layer decode knobs (decode_block, fused mode, kernel launch params).\n", "            if tuner is not None and caches:\n", "                try:\n", "                    L_prefix = int(getattr(caches[0], \"pos\", out.size(1) - 1))\n", "                    plan = tuner.maybe_get_plan(attn=self.blocks[0].attn, cache=caches[0], L_prefix=L_prefix)\n", "                    if plan is not None:\n", "                        for c in caches:\n", "                            plan.apply_to_cache(c)\n", "                except Exception:\n", "                    pass\n\n", "            # decode one token\n", "            logits, caches = self(next_id, caches=caches, pos_offset=out.size(1) - 1)\n", "        if was_training:\n", "            self.train()\n", "        return out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    @torch.no_grad()\n", "    def _policy_logit_maxerr_decoupled(\n", "        self,\n", "        tokens: torch.Tensor,\n", "        *,\n", "        policy: KVCachePolicy,\n", "        prefill: int,\n", "        decode_steps: int,\n", "        kv_decode_block: int,\n", "    ) -> float:\n", "        \"\"\"Quality guard for cache-policy tuning.\n", "        Returns max(abs(logits_candidate - logits_fp16_baseline)) over a short teacher-forced decode window.\n", "        This is NOT a substitute for proper eval (perplexity), but it catches \"oops, this quant combo is broken\".\n", "        \"\"\"\n", "        m = self._policy_quality_metrics_decoupled(\n", "            tokens,\n", "            policy=policy,\n", "            prefill=prefill,\n", "            decode_steps=decode_steps,\n", "            kv_decode_block=kv_decode_block,\n", "            compute_kl=False,\n", "        )\n", "        return float(m.get(\"max_abs_logit\", 0.0))\n", "    @torch.no_grad()\n", "    def _policy_quality_metrics_decoupled(\n", "        self,\n", "        tokens: torch.Tensor,\n", "        *,\n", "        policy: KVCachePolicy,\n", "        prefill: int,\n", "        decode_steps: int,\n", "        kv_decode_block: int,\n", "        compute_kl: bool = False,\n", "    ) -> Dict[str, float]:\n", "        \"\"\"Importance-aware quality metrics for cache-policy tuning.\n", "        Computes over a short teacher-forced decode window:\n", "          - max_abs_logit: max(|\u0394logit|) vs fp16-cache baseline (safety fuse)\n", "          - delta_nll: \u0394NLL (nats/token) vs baseline on next-token targets\n", "          - ppl_ratio: exp(delta_nll)\n", "          - kl_base_cand: KL(p_base || p_cand) averaged over tokens (optional; costs a softmax)\n", "        \"\"\"\n", "        if tokens.numel() == 0:\n", "            return {\"max_abs_logit\": 0.0, \"delta_nll\": float(\"nan\"), \"ppl_ratio\": float(\"nan\"), \"kl_base_cand\": float(\"nan\")}\n\n", "        # Keep it cheap: single batch item only.\n", "        if tokens.dim() == 1:\n", "            tokens = tokens.unsqueeze(0)\n", "        tokens = tokens[:1].contiguous()\n", "        device = tokens.device\n", "        B, L = tokens.shape\n", "        if L < 2:\n", "            return {\"max_abs_logit\": 0.0, \"delta_nll\": float(\"nan\"), \"ppl_ratio\": float(\"nan\"), \"kl_base_cand\": float(\"nan\")}\n", "        prefill = int(max(1, min(int(prefill), L - 1)))\n", "        decode_steps = int(max(1, min(int(decode_steps), L - prefill)))\n\n", "        # We'll run up to (prefill + decode_steps) tokens total.\n", "        max_seq = prefill + decode_steps\n\n", "        # Force eval for determinism (dropout off).\n", "        was_training = self.training\n", "        self.eval()\n", "        try:\n", "            # Baseline: fp16 caches everywhere.\n", "            fp16_cfg = KVCacheTensorConfig(kind=\"fp16\", qblock=32, residual_len=0)\n", "            caches_base: List[Any] = []\n", "            for _ in range(self.cfg.n_layer):\n", "                c = DecoupledLayerKVCache(\n", "                    batch_size=B,\n", "                    max_seq_len=max_seq,\n", "                    k_sem_dim=self.cfg.sem_dim,\n", "                    k_geo_dim=self.cfg.geo_dim,\n", "                    v_dim=self.cfg.attn_dim,\n", "                    k_sem_cfg=fp16_cfg,\n", "                    k_geo_cfg=fp16_cfg,\n", "                    v_cfg=fp16_cfg,\n", "                    device=device,\n", "                )\n", "                c.decode_block = int(kv_decode_block)\n", "                c.fused = \"none\"\n", "                caches_base.append(c)\n\n", "            # Candidate caches: chosen policy (quantized).\n", "            k_sem_cfg, k_geo_cfg, v_cfg = policy.to_tensor_cfgs()\n", "            caches_cand: List[Any] = []\n", "            for _ in range(self.cfg.n_layer):\n", "                c = DecoupledLayerKVCache(\n", "                    batch_size=B,\n", "                    max_seq_len=max_seq,\n", "                    k_sem_dim=self.cfg.sem_dim,\n", "                    k_geo_dim=self.cfg.geo_dim,\n", "                    v_dim=self.cfg.attn_dim,\n", "                    k_sem_cfg=k_sem_cfg,\n", "                    k_geo_cfg=k_geo_cfg,\n", "                    v_cfg=v_cfg,\n", "                    device=device,\n", "                )\n", "                c.decode_block = int(kv_decode_block)\n", "                c.fused = \"none\"  # ensure we don't mix kernel numeric differences into the quant check\n", "                caches_cand.append(c)\n\n", "            # Prefill\n", "            prompt = tokens[:, :prefill]\n", "            logits_base, caches_base = self(prompt, caches=caches_base, pos_offset=0)\n", "            logits_cand, caches_cand = self(prompt, caches=caches_cand, pos_offset=0)\n\n", "            # Teacher-forced decode window\n", "            max_err = 0.0\n", "            nll_sum_base = 0.0\n", "            nll_sum_cand = 0.0\n", "            nll_count = 0\n", "            kl_sum = 0.0\n", "            kl_count = 0\n", "            for i in range(prefill, prefill + decode_steps):\n", "                x = tokens[:, i : i + 1]\n", "                logits_base, caches_base = self(x, caches=caches_base, pos_offset=i)\n", "                logits_cand, caches_cand = self(x, caches=caches_cand, pos_offset=i)\n", "                lb = logits_base[:, -1, :].float()\n", "                lc = logits_cand[:, -1, :].float()\n", "                # Fuse metric: max |\u0394logit|\n", "                err = (lc - lb).abs().max().item()\n", "                if err > max_err:\n", "                    max_err = float(err)\n", "                # Importance-aware metrics require next-token targets.\n", "                if (i + 1) < L:\n", "                    tgt = tokens[:, i + 1].reshape(-1)\n", "                    nll_sum_base += float(F.cross_entropy(lb.reshape(-1, lb.size(-1)), tgt, reduction=\"sum\").item())\n", "                    nll_sum_cand += float(F.cross_entropy(lc.reshape(-1, lc.size(-1)), tgt, reduction=\"sum\").item())\n", "                    nll_count += int(tgt.numel())\n", "                    if compute_kl:\n", "                        logp_b = F.log_softmax(lb, dim=-1)\n", "                        p_b = logp_b.exp()\n", "                        logp_c = F.log_softmax(lc, dim=-1)\n", "                        kl_tok = (p_b * (logp_b - logp_c)).sum(-1)  # [B]\n", "                        kl_sum += float(kl_tok.sum().item())\n", "                        kl_count += int(kl_tok.numel())\n", "            if nll_count > 0:\n", "                ce_base = nll_sum_base / float(nll_count)\n", "                ce_cand = nll_sum_cand / float(nll_count)\n", "                delta_nll = float(ce_cand - ce_base)\n", "                ppl_ratio = float(math.exp(delta_nll))\n", "            else:\n", "                delta_nll = float(\"nan\")\n", "                ppl_ratio = float(\"nan\")\n", "            if compute_kl and kl_count > 0:\n", "                kl_avg = float(kl_sum / float(kl_count))\n", "            else:\n", "                kl_avg = float(\"nan\")\n", "            return {\n", "                \"max_abs_logit\": float(max_err),\n", "                \"delta_nll\": float(delta_nll),\n", "                \"ppl_ratio\": float(ppl_ratio),\n", "                \"kl_base_cand\": float(kl_avg),\n", "            }\n", "        finally:\n", "            if was_training:\n", "                self.train()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@torch.no_grad()\n", "def estimate_loss(\n", "    model: GPT,\n", "    train_tokens: torch.Tensor,\n", "    val_tokens: torch.Tensor,\n", "    *,\n", "    eval_iters: int,\n", "    batch_size: int,\n", "    block_size: int,\n", "    device: torch.device,\n", ") -> Tuple[float, float]:\n", "    model.eval()\n", "    out: Dict[str, float] = {}\n", "    for split, tok in [(\"train\", train_tokens), (\"val\", val_tokens)]:\n", "        losses: List[float] = []\n", "        for _ in range(eval_iters):\n", "            x, y = get_batch(tok, batch_size, block_size, device)\n", "            logits, _ = model(x)\n", "            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), y.reshape(-1))\n", "            losses.append(loss.item())\n", "        out[split] = sum(losses) / len(losses)\n", "    model.train()\n", "    return out[\"train\"], out[\"val\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_ckpt(out_dir: str, name: str, model: GPT, cfg: ModelConfig, step: int, best_val: float) -> str:\n", "    os.makedirs(out_dir, exist_ok=True)\n", "    path = os.path.join(out_dir, name)\n", "    torch.save(\n", "        {\n", "            \"config\": asdict(cfg),\n", "            \"model\": model.state_dict(),\n", "            \"step\": step,\n", "            \"best_val\": best_val,\n", "        },\n", "        path,\n", "    )\n", "    return path"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "Experiment presets + instrumentation (v27)<br>\n", "-----------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["These presets are designed to match the \"Experiment Suite Summary\" you shared.<br>\n", "They only apply when you pass --size and/or --exp. Explicit CLI flags still win."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SIZE_PRESETS: Dict[str, Dict[str, Any]] = {\n", "    # params, d_model, layers, heads, d_ff, context, batch, steps\n", "    \"tiny\":   dict(d_model=512,  layers=6,  n_head=8,  d_ff=2048, block=1024, batch_size=16, steps=6000),\n", "    \"small\":  dict(d_model=768,  layers=12, n_head=12, d_ff=3072, block=1024, batch_size=8,  steps=10000),\n", "    \"medium\": dict(d_model=1024, layers=24, n_head=16, d_ff=4096, block=2048, batch_size=4,  steps=15000),\n", "    \"large\":  dict(d_model=1536, layers=24, n_head=16, d_ff=6144, block=2048, batch_size=2,  steps=20000),\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Attention dims for the \"paper_*\" experiments (matching your table)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BOTTLENECK_ATTN_DIM: Dict[str, int] = {\"tiny\": 96, \"small\": 144, \"medium\": 192, \"large\": 288}\n", "DECOUPLED_SEM_DIM:   Dict[str, int] = {\"tiny\": 32, \"small\": 48,  \"medium\": 64,  \"large\": 96}\n", "DECOUPLED_GEO_DIM:   Dict[str, int] = {\"tiny\": 64, \"small\": 96,  \"medium\": 128, \"large\": 192}\n", "DECOUPLED_ATTN_DIM:  Dict[str, int] = {\"tiny\": 96, \"small\": 144, \"medium\": 192, \"large\": 288}\n", "GQA_KV_HEAD:         Dict[str, int] = {\"tiny\": 2,  \"small\": 3,   \"medium\": 4,   \"large\": 4}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["EXP_PRESETS: Dict[str, Dict[str, Any]] = {\n", "    \"paper_baseline\": dict(attn_mode=\"standard\"),\n", "    \"paper_bottleneck\": dict(attn_mode=\"bottleneck\", null_attn=True),\n", "    \"paper_decoupled\": dict(attn_mode=\"decoupled\", tie_qk=True, null_attn=True, rope=True),\n", "    \"paper_gqa\": dict(attn_mode=\"gqa\"),\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _argv_has_flag(flag: str) -> bool:\n", "    # Detect explicit user overrides (argparse defaults are otherwise indistinguishable).\n", "    return flag in sys.argv"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def apply_size_preset(args: argparse.Namespace) -> None:\n", "    if not getattr(args, \"size\", None):\n", "        return\n", "    size = str(args.size)\n", "    if size not in SIZE_PRESETS:\n", "        raise ValueError(f\"Unknown size preset: {size}\")\n", "    p = SIZE_PRESETS[size]\n", "    # Only override if the user did not specify the corresponding CLI flag.\n", "    if not _argv_has_flag(\"--d-model\"):\n", "        args.d_model = p[\"d_model\"]\n", "    if not _argv_has_flag(\"--layers\"):\n", "        args.layers = p[\"layers\"]\n", "    if not _argv_has_flag(\"--n-head\"):\n", "        args.n_head = p[\"n_head\"]\n", "    if not _argv_has_flag(\"--d-ff\"):\n", "        args.d_ff = p[\"d_ff\"]\n", "    if not _argv_has_flag(\"--block\"):\n", "        args.block = p[\"block\"]\n", "    if not _argv_has_flag(\"--batch-size\"):\n", "        args.batch_size = p[\"batch_size\"]\n", "    if not _argv_has_flag(\"--steps\"):\n", "        args.steps = p[\"steps\"]\n", "    # default embed_dim tracks d_model unless explicitly set\n", "    if not _argv_has_flag(\"--embed-dim\"):\n", "        args.embed_dim = p[\"d_model\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def apply_exp_preset(args: argparse.Namespace) -> None:\n", "    if not getattr(args, \"exp\", None):\n", "        return\n", "    exp = str(args.exp)\n", "    if exp not in EXP_PRESETS and exp != \"paper_all\":\n", "        raise ValueError(f\"Unknown experiment preset: {exp}\")\n\n", "    # For paper_all, we don't set mode here; the runner loops over EXP_PRESETS.\n", "    if exp == \"paper_all\":\n", "        return\n", "    preset = EXP_PRESETS[exp]\n", "    size = str(getattr(args, \"size\", \"\")) if getattr(args, \"size\", None) else None\n\n", "    # attn_mode\n", "    if not _argv_has_flag(\"--attn-mode\") and \"attn_mode\" in preset:\n", "        args.attn_mode = preset[\"attn_mode\"]\n\n", "    # Experiment-specific dims (size-dependent)\n", "    if size is not None:\n", "        if exp == \"paper_bottleneck\":\n", "            if not _argv_has_flag(\"--attn-dim\"):\n", "                args.attn_dim = BOTTLENECK_ATTN_DIM[size]\n", "        if exp == \"paper_decoupled\":\n", "            if not _argv_has_flag(\"--sem-dim\"):\n", "                args.sem_dim = DECOUPLED_SEM_DIM[size]\n", "            if not _argv_has_flag(\"--geo-dim\"):\n", "                args.geo_dim = DECOUPLED_GEO_DIM[size]\n", "            if not _argv_has_flag(\"--attn-dim\"):\n", "                args.attn_dim = DECOUPLED_ATTN_DIM[size]\n", "        if exp == \"paper_gqa\":\n", "            if not _argv_has_flag(\"--kv-head\"):\n", "                args.kv_head = GQA_KV_HEAD[size]\n", "            if not _argv_has_flag(\"--attn-dim\"):\n", "                # Keep head_dim identical to baseline by default.\n", "                args.attn_dim = int(getattr(args, \"d_model\", SIZE_PRESETS[size][\"d_model\"]))\n\n", "    # Bool toggles (only set if user didn't explicitly toggle)\n", "    if \"null_attn\" in preset:\n", "        if (not _argv_has_flag(\"--null-attn\")) and (not _argv_has_flag(\"--no-null-attn\")):\n", "            args.null_attn = bool(preset[\"null_attn\"])\n", "    if \"tie_qk\" in preset:\n", "        if (not _argv_has_flag(\"--tie-qk\")) and (not _argv_has_flag(\"--no-tie-qk\")):\n", "            args.tie_qk = bool(preset[\"tie_qk\"])\n", "    if \"rope\" in preset:\n", "        if (not _argv_has_flag(\"--no-rope\")) and (not _argv_has_flag(\"--rope\")):\n", "            # v26 default is rope=True; keep explicit override logic anyway.\n", "            if preset[\"rope\"]:\n", "                args.no_rope = False\n", "            else:\n", "                args.no_rope = True"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def default_out_dir(args: argparse.Namespace) -> Optional[str]:\n", "    \"\"\"\n", "    If the user didn't set --out-dir, build it as runs/{size}_{expSuffix}.\n", "    Returns None if we cannot infer.\n", "    \"\"\"\n", "    if getattr(args, \"out_dir\", None):\n", "        return str(args.out_dir)\n", "    size = getattr(args, \"size\", None)\n", "    exp = getattr(args, \"exp\", None)\n", "    run_root = getattr(args, \"run_root\", \"runs\")\n", "    tag = getattr(args, \"run_tag\", None)\n", "    if not size or not exp or exp == \"paper_all\":\n", "        return None\n", "    suffix = str(exp).replace(\"paper_\", \"\")\n", "    name = f\"{size}_{suffix}\"\n", "    if tag:\n", "        name = f\"{name}_{tag}\"\n", "    return os.path.join(run_root, name)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def human_bytes(n: float) -> str:\n", "    n = float(n)\n", "    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n", "    u = 0\n", "    while n >= 1024.0 and u < len(units) - 1:\n", "        n /= 1024.0\n", "        u += 1\n", "    if u == 0:\n", "        return f\"{n:.0f}{units[u]}\"\n", "    if n >= 100:\n", "        return f\"{n:.1f}{units[u]}\"\n", "    return f\"{n:.2f}{units[u]}\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _safe_float(x: Any) -> float:\n", "    try:\n", "        return float(x)\n", "    except Exception:\n", "        return float(\"nan\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _now_iso() -> str:\n", "    return datetime.datetime.now(datetime.timezone.utc).astimezone().isoformat(timespec=\"seconds\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _device_summary(device: torch.device) -> str:\n", "    if device.type == \"cuda\":\n", "        try:\n", "            name = torch.cuda.get_device_name(device)\n", "        except Exception:\n", "            name = \"cuda\"\n", "        return f\"cuda:{device.index or 0} ({name})\"\n", "    if device.type == \"mps\":\n", "        return \"mps\"\n", "    return str(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _env_info(device: torch.device) -> Dict[str, Any]:\n", "    info: Dict[str, Any] = {}\n", "    info[\"time\"] = _now_iso()\n", "    info[\"python\"] = sys.version.replace(\"\\n\", \" \")\n", "    info[\"platform\"] = platform.platform()\n", "    info[\"torch\"] = getattr(torch, \"__version__\", \"unknown\")\n", "    info[\"device\"] = _device_summary(device)\n", "    info[\"triton_available\"] = bool(TRITON_AVAILABLE)\n", "    if device.type == \"cuda\":\n", "        info[\"cuda\"] = torch.version.cuda\n", "        info[\"cudnn\"] = torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else None\n", "    return info"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---- KV cache memory estimator (architecture-aware, and quant-aware) ----"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _seqcache_bytes_for(kind: KVCacheKind, *, dim: int, qblock: int, residual_len: int, batch: int, seq_len: int) -> int:\n", "    kind = str(kind)\n", "    if kind == \"fp16\":\n", "        return int(batch * seq_len * dim * 2)\n", "    if kind == \"fp32\":\n", "        return int(batch * seq_len * dim * 4)\n", "    # Quantized kinds: use the same spec logic as the cache implementation (pad_dim + n_blocks).\n", "    spec = make_quantspec(kind, dim, qblock)\n", "    if kind == \"q8_0\":\n", "        q_bytes = int(batch * seq_len * spec.pad_dim * 1)  # int8\n", "    elif kind in (\"q4_0\", \"nf4\"):\n", "        q_bytes = int(batch * seq_len * (spec.pad_dim // 2) * 1)  # packed uint8\n", "    else:\n", "        raise ValueError(kind)\n", "    s_bytes = int(batch * seq_len * spec.n_blocks * 2)  # fp16 scales\n", "    r_eff = int(max(0, residual_len))\n", "    # Residual ring is allocated even if seq_len is smaller than residual_len; for estimates, assume max_seq_len == seq_len.\n", "    r_alloc = int(min(r_eff, seq_len))\n", "    r_bytes = int(batch * r_alloc * dim * 2)\n", "    return q_bytes + s_bytes + r_bytes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def estimate_kv_cache_bytes(\n", "    cfg: ModelConfig,\n", "    *,\n", "    seq_len: int,\n", "    batch: int = 1,\n", "    kv_cache: KVCacheKind = \"fp16\",\n", "    kv_qblock: int = 32,\n", "    kv_residual: int = 0,\n", "    kv_cache_k: Optional[KVCacheKind] = None,\n", "    kv_cache_v: Optional[KVCacheKind] = None,\n", "    kv_cache_k_sem: Optional[KVCacheKind] = None,\n", "    kv_cache_k_geo: Optional[KVCacheKind] = None,\n", "    kv_qblock_k: Optional[int] = None,\n", "    kv_qblock_v: Optional[int] = None,\n", "    kv_qblock_k_sem: Optional[int] = None,\n", "    kv_qblock_k_geo: Optional[int] = None,\n", ") -> Dict[str, Any]:\n", "    \"\"\"\n", "    Architecture-aware KV cache estimate for a *single* sequence length + batch.\n", "    Returns per-layer and total sizes.\n", "    \"\"\"\n", "    def kind_of(default_kind: KVCacheKind, override: Optional[KVCacheKind]) -> KVCacheKind:\n", "        return override if override is not None else default_kind\n", "    def qb_of(default_qb: int, override: Optional[int]) -> int:\n", "        return int(override) if override is not None else int(default_qb)\n\n", "    # v26 heterogeneous default for decoupled when kv_cache == q4_0\n", "    k_sem_kind = kind_of(kv_cache, kv_cache_k_sem)\n", "    k_geo_kind = kind_of(kv_cache, kv_cache_k_geo)\n", "    v_kind = kind_of(kv_cache, kv_cache_v)\n", "    k_kind = kind_of(kv_cache, kv_cache_k)\n", "    k_sem_qb = qb_of(kv_qblock, kv_qblock_k_sem)\n", "    k_geo_qb = qb_of(kv_qblock, kv_qblock_k_geo)\n", "    k_qb = qb_of(kv_qblock, kv_qblock_k)\n", "    v_qb = qb_of(kv_qblock, kv_qblock_v)\n\n", "    # residual applies only to quant kinds (matches cache code)\n", "    def resid_for(kind: KVCacheKind) -> int:\n", "        return int(kv_residual) if str(kind) not in (\"fp16\", \"fp32\") else 0\n", "    mode = cfg.attn_mode\n", "    if mode in (\"standard\", \"bottleneck\"):\n", "        k_dim = cfg.d_model if mode == \"standard\" else cfg.attn_dim\n", "        v_dim = cfg.d_model if mode == \"standard\" else cfg.attn_dim\n", "        k_bytes = _seqcache_bytes_for(k_kind, dim=k_dim, qblock=k_qb, residual_len=resid_for(k_kind), batch=batch, seq_len=seq_len)\n", "        v_bytes = _seqcache_bytes_for(v_kind, dim=v_dim, qblock=v_qb, residual_len=resid_for(v_kind), batch=batch, seq_len=seq_len)\n", "        per_layer = k_bytes + v_bytes\n", "        total = int(cfg.n_layer * per_layer)\n", "        return dict(mode=mode, seq_len=seq_len, batch=batch, per_layer_bytes=per_layer, total_bytes=total, details=dict(k=k_bytes, v=v_bytes))\n", "    if mode == \"gqa\":\n", "        H = cfg.n_head\n", "        H_kv = cfg.kv_head if cfg.kv_head is not None else H\n", "        head_dim = cfg.attn_dim // H\n", "        kv_dim = int(H_kv * head_dim)\n", "        k_bytes = _seqcache_bytes_for(k_kind, dim=kv_dim, qblock=k_qb, residual_len=resid_for(k_kind), batch=batch, seq_len=seq_len)\n", "        v_bytes = _seqcache_bytes_for(v_kind, dim=kv_dim, qblock=v_qb, residual_len=resid_for(v_kind), batch=batch, seq_len=seq_len)\n", "        per_layer = k_bytes + v_bytes\n", "        total = int(cfg.n_layer * per_layer)\n", "        return dict(mode=mode, seq_len=seq_len, batch=batch, per_layer_bytes=per_layer, total_bytes=total, details=dict(k=k_bytes, v=v_bytes, kv_dim=kv_dim))\n", "    if mode == \"decoupled\":\n", "        # heterogeneous default: q4 semantic, q8 geo, q4 V\n", "        if str(kv_cache) == \"q4_0\":\n", "            if kv_cache_k_geo is None:\n", "                k_geo_kind = \"q8_0\"\n", "            if kv_cache_k_sem is None:\n", "                k_sem_kind = \"q4_0\"\n", "            if kv_cache_v is None:\n", "                v_kind = \"q4_0\"\n", "        k_sem_bytes = _seqcache_bytes_for(k_sem_kind, dim=cfg.sem_dim, qblock=k_sem_qb, residual_len=resid_for(k_sem_kind), batch=batch, seq_len=seq_len)\n", "        k_geo_bytes = _seqcache_bytes_for(k_geo_kind, dim=cfg.geo_dim, qblock=k_geo_qb, residual_len=resid_for(k_geo_kind), batch=batch, seq_len=seq_len)\n", "        v_bytes = _seqcache_bytes_for(v_kind, dim=cfg.attn_dim, qblock=v_qb, residual_len=resid_for(v_kind), batch=batch, seq_len=seq_len)\n", "        per_layer = k_sem_bytes + k_geo_bytes + v_bytes\n", "        total = int(cfg.n_layer * per_layer)\n", "        return dict(mode=mode, seq_len=seq_len, batch=batch, per_layer_bytes=per_layer, total_bytes=total,\n", "                    details=dict(k_sem=k_sem_bytes, k_geo=k_geo_bytes, v=v_bytes))\n", "    raise ValueError(mode)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---- Deep instrumentation: JSONL + HDF5 + plots ----"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import numpy as _np  # type: ignore\n", "except Exception:\n", "    _np = None  # type: ignore"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import h5py as _h5py  # type: ignore\n", "except Exception:\n", "    _h5py = None  # type: ignore"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class RunLogger:\n", "    def __init__(\n", "        self,\n", "        out_dir: str,\n", "        *,\n", "        instrument: str,\n", "        cfg: ModelConfig,\n", "        args: argparse.Namespace,\n", "        device: torch.device,\n", "        live_plot: bool = False,\n", "        tb: bool = False,\n", "    ):\n", "        self.out_dir = str(out_dir)\n", "        self.instrument = str(instrument)\n", "        self.cfg = cfg\n", "        self.args = args\n", "        self.device = device\n", "        self.start_time = time.time()\n", "        os.makedirs(self.out_dir, exist_ok=True)\n", "        self.train_jsonl_path = os.path.join(self.out_dir, \"train.jsonl\")\n", "        self.summary_path = os.path.join(self.out_dir, \"summary.md\")\n", "        self.h5_path = os.path.join(self.out_dir, \"analysis.h5\")\n", "        self.png_path = os.path.join(self.out_dir, \"analysis.png\")\n", "        self._jsonl_f = None\n", "        self._h5 = None\n", "        self._live = None\n", "        self._tb = None\n", "        if self.instrument != \"off\":\n", "            self._jsonl_f = open(self.train_jsonl_path, \"w\", encoding=\"utf-8\")\n", "            self.log({\"type\": \"meta\", \"step\": 0, \"env\": _env_info(device), \"argv\": sys.argv, \"args\": vars(args), \"config\": asdict(cfg)})\n\n", "        # HDF5 only in \"full\"\n", "        if self.instrument == \"full\" and _h5py is not None:\n", "            try:\n", "                self._h5 = _h5py.File(self.h5_path, \"w\")\n", "                meta = self._h5.create_group(\"meta\")\n", "                meta.attrs[\"created\"] = _now_iso()\n", "                meta.attrs[\"argv\"] = \" \".join(sys.argv)\n", "                meta.attrs[\"config_json\"] = json.dumps(asdict(cfg), separators=(\",\", \":\"), sort_keys=True)\n", "            except Exception as e:\n", "                print(f\"[warn] Could not open HDF5 at {self.h5_path}: {e}\")\n", "                self._h5 = None\n\n", "        # Optional live plot (matplotlib)\n", "        if live_plot and self.instrument != \"off\":\n", "            self._live = LivePlotter()\n", "        # Optional tensorboard (requires tensorboard package)\n", "        if tb and self.instrument != \"off\":\n", "            self._tb = TensorBoardWriter(self.out_dir)\n\n", "        # Write initial summary.md with config so runs are self-describing immediately.\n", "        self._write_summary(initial_only=True)\n", "    def close(self) -> None:\n", "        try:\n", "            if self._h5 is not None:\n", "                self._h5.flush()\n", "                self._h5.close()\n", "        except Exception:\n", "            pass\n", "        try:\n", "            if self._jsonl_f is not None:\n", "                self._jsonl_f.flush()\n", "                self._jsonl_f.close()\n", "        except Exception:\n", "            pass\n", "        try:\n", "            if self._tb is not None:\n", "                self._tb.close()\n", "        except Exception:\n", "            pass\n", "        try:\n", "            if self._live is not None:\n", "                self._live.close()\n", "        except Exception:\n", "            pass\n", "    def log(self, event: Dict[str, Any]) -> None:\n", "        if self._jsonl_f is None:\n", "            return\n", "        # Add time info for every line.\n", "        event = dict(event)\n", "        event.setdefault(\"wall_time\", _now_iso())\n", "        self._jsonl_f.write(json.dumps(event, separators=(\",\", \":\"), ensure_ascii=False) + \"\\n\")\n", "        self._jsonl_f.flush()\n", "        if self._tb is not None:\n", "            self._tb.maybe_log(event)\n", "        if self._live is not None:\n", "            self._live.maybe_update(event)\n", "    def h5_write_step(self, step: int, *, group: str, tensors: Dict[str, torch.Tensor], attrs: Optional[Dict[str, Any]] = None) -> None:\n", "        if self._h5 is None:\n", "            return\n", "        try:\n", "            g = self._h5.require_group(f\"{group}/step_{int(step)}\")\n", "            if attrs:\n", "                for k, v in attrs.items():\n", "                    try:\n", "                        g.attrs[k] = v\n", "                    except Exception:\n", "                        g.attrs[k] = str(v)\n", "            for name, t in tensors.items():\n", "                if t is None:\n", "                    continue\n", "                arr = t.detach().to(\"cpu\")\n", "                if arr.dtype in (torch.bfloat16, torch.float16):\n", "                    arr = arr.to(torch.float16)\n", "                else:\n", "                    arr = arr.to(torch.float32)\n", "                g.create_dataset(name, data=arr.numpy(), compression=\"gzip\", compression_opts=4)\n", "            self._h5.flush()\n", "        except Exception as e:\n", "            print(f\"[warn] HDF5 write failed at step {step}: {e}\")\n", "    def finalize(self, *, best_val: float, last_step: int) -> None:\n", "        # Close live plot cleanly; generate final plots; update summary.md\n", "        try:\n", "            if self.instrument != \"off\":\n", "                generate_analysis_png(self.train_jsonl_path, self.png_path)\n", "        except Exception as e:\n", "            print(f\"[warn] analysis.png generation failed: {e}\")\n", "        self._write_summary(initial_only=False, best_val=best_val, last_step=last_step)\n", "    def _write_summary(self, *, initial_only: bool, best_val: Optional[float] = None, last_step: Optional[int] = None) -> None:\n", "        try:\n", "            lines: List[str] = []\n", "            lines.append(f\"# Run Summary\")\n", "            lines.append(\"\")\n", "            lines.append(f\"- Created: `{_now_iso()}`\")\n", "            lines.append(f\"- Out dir: `{self.out_dir}`\")\n", "            lines.append(f\"- Device: `{_device_summary(self.device)}`\")\n", "            lines.append(f\"- Command: `{(' '.join(sys.argv))}`\")\n", "            if getattr(self.args, \"size\", None):\n", "                lines.append(f\"- Size preset: `{self.args.size}`\")\n", "            if getattr(self.args, \"exp\", None):\n", "                lines.append(f\"- Experiment: `{self.args.exp}`\")\n", "            lines.append(\"\")\n", "            lines.append(\"## Model Config\")\n", "            lines.append(\"\")\n", "            lines.append(\"```json\")\n", "            lines.append(json.dumps(asdict(self.cfg), indent=2, sort_keys=True))\n", "            lines.append(\"```\")\n", "            lines.append(\"\")\n", "            lines.append(\"## Training Args\")\n", "            lines.append(\"\")\n", "            # args can include non-serializable values; make a best effort\n", "            try:\n", "                args_json = json.dumps(vars(self.args), indent=2, sort_keys=True, default=str)\n", "            except Exception:\n", "                args_json = str(vars(self.args))\n", "            lines.append(\"```json\")\n", "            lines.append(args_json)\n", "            lines.append(\"```\")\n", "            lines.append(\"\")\n", "            if not initial_only and best_val is not None and last_step is not None:\n", "                ppl = math.exp(best_val) if best_val < 20 else float(\"inf\")\n", "                lines.append(\"## Results\")\n", "                lines.append(\"\")\n", "                lines.append(f\"- Last step: `{last_step}`\")\n", "                lines.append(f\"- Best val loss: `{best_val:.6f}` (ppl `{ppl:.2f}`)\")\n", "                lines.append(f\"- Files: `train.jsonl`, `analysis.h5` (if enabled), `analysis.png`, `best.pt`, `last.pt`\")\n", "                lines.append(\"\")\n", "                # KV cache memory quick summary (fp16 baseline vs chosen kv policy)\n", "                try:\n", "                    ctx = int(self.cfg.block_size)\n", "                    mem_base = estimate_kv_cache_bytes(ModelConfig(**{**asdict(self.cfg), \"attn_mode\": \"standard\"}), seq_len=ctx, batch=1, kv_cache=\"fp16\", kv_qblock=32, kv_residual=0)\n", "                    mem_this = estimate_kv_cache_bytes(self.cfg, seq_len=ctx, batch=1,\n", "                                                       kv_cache=getattr(self.args, \"kv_cache\", \"fp16\"),\n", "                                                       kv_qblock=int(getattr(self.args, \"kv_qblock\", 32)),\n", "                                                       kv_residual=int(getattr(self.args, \"kv_residual\", 0)),\n", "                                                       kv_cache_k=getattr(self.args, \"kv_cache_k\", None),\n", "                                                       kv_cache_v=getattr(self.args, \"kv_cache_v\", None),\n", "                                                       kv_cache_k_sem=getattr(self.args, \"kv_cache_k_sem\", None),\n", "                                                       kv_cache_k_geo=getattr(self.args, \"kv_cache_k_geo\", None),\n", "                                                       kv_qblock_k=getattr(self.args, \"kv_qblock_k\", None),\n", "                                                       kv_qblock_v=getattr(self.args, \"kv_qblock_v\", None),\n", "                                                       kv_qblock_k_sem=getattr(self.args, \"kv_qblock_k_sem\", None),\n", "                                                       kv_qblock_k_geo=getattr(self.args, \"kv_qblock_k_geo\", None),\n", "                                                       )\n", "                    lines.append(\"## KV Cache Memory (batch=1)\")\n", "                    lines.append(\"\")\n", "                    lines.append(f\"- Baseline fp16 (standard attn) @ ctx={ctx}: `{human_bytes(mem_base['total_bytes'])}`\")\n", "                    lines.append(f\"- This run policy @ ctx={ctx}: `{human_bytes(mem_this['total_bytes'])}`\")\n", "                    if mem_this[\"total_bytes\"] > 0:\n", "                        lines.append(f\"- Compression vs fp16 baseline: `{mem_base['total_bytes']/mem_this['total_bytes']:.2f}\u00d7`\")\n", "                    # Also probe at 128k\n", "                    mem_this_128 = estimate_kv_cache_bytes(self.cfg, seq_len=128_000, batch=1,\n", "                                                           kv_cache=getattr(self.args, \"kv_cache\", \"fp16\"),\n", "                                                           kv_qblock=int(getattr(self.args, \"kv_qblock\", 32)),\n", "                                                           kv_residual=int(getattr(self.args, \"kv_residual\", 0)),\n", "                                                           kv_cache_k=getattr(self.args, \"kv_cache_k\", None),\n", "                                                           kv_cache_v=getattr(self.args, \"kv_cache_v\", None),\n", "                                                           kv_cache_k_sem=getattr(self.args, \"kv_cache_k_sem\", None),\n", "                                                           kv_cache_k_geo=getattr(self.args, \"kv_cache_k_geo\", None),\n", "                                                           kv_qblock_k=getattr(self.args, \"kv_qblock_k\", None),\n", "                                                           kv_qblock_v=getattr(self.args, \"kv_qblock_v\", None),\n", "                                                           kv_qblock_k_sem=getattr(self.args, \"kv_qblock_k_sem\", None),\n", "                                                           kv_qblock_k_geo=getattr(self.args, \"kv_qblock_k_geo\", None),\n", "                                                           )\n", "                    lines.append(f\"- This run policy @ 128k: `{human_bytes(mem_this_128['total_bytes'])}`\")\n", "                    lines.append(\"\")\n", "                except Exception as e:\n", "                    lines.append(f\"## KV Cache Memory\")\n", "                    lines.append(\"\")\n", "                    lines.append(f\"- (Failed to compute memory estimate: {e})\")\n", "                    lines.append(\"\")\n", "            Path(self.summary_path).write_text(\"\\n\".join(lines) + \"\\n\", encoding=\"utf-8\")\n", "        except Exception as e:\n", "            print(f\"[warn] Failed to write summary.md: {e}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TensorBoardWriter:\n", "    \"\"\"\n", "    Optional: requires `pip install tensorboard`.\n", "    We keep this extremely lightweight: only scalar logging.\n", "    \"\"\"\n", "    def __init__(self, out_dir: str):\n", "        self.writer = None\n", "        try:\n", "            from torch.utils.tensorboard import SummaryWriter  # type: ignore\n", "            self.writer = SummaryWriter(log_dir=os.path.join(out_dir, \"tb\"))\n", "        except Exception as e:\n", "            print(f\"[warn] TensorBoard not available: {e}. Disable with --tb=0 or install tensorboard.\")\n", "            self.writer = None\n", "    def maybe_log(self, event: Dict[str, Any]) -> None:\n", "        if self.writer is None:\n", "            return\n", "        try:\n", "            step = int(event.get(\"step\", 0))\n", "            etype = str(event.get(\"type\", \"\"))\n", "            if etype == \"train\":\n", "                if \"loss\" in event:\n", "                    self.writer.add_scalar(\"loss/train\", float(event[\"loss\"]), step)\n", "                if \"ppl\" in event:\n", "                    self.writer.add_scalar(\"ppl/train\", float(event[\"ppl\"]), step)\n", "                if \"tok_s\" in event:\n", "                    self.writer.add_scalar(\"perf/tok_s\", float(event[\"tok_s\"]), step)\n", "            if etype == \"eval\":\n", "                if \"train_loss\" in event:\n", "                    self.writer.add_scalar(\"loss/train_eval\", float(event[\"train_loss\"]), step)\n", "                if \"val_loss\" in event:\n", "                    self.writer.add_scalar(\"loss/val\", float(event[\"val_loss\"]), step)\n", "            if etype == \"analysis\":\n", "                for k, v in event.items():\n", "                    if k in (\"type\", \"step\", \"wall_time\"):\n", "                        continue\n", "                    if isinstance(v, (int, float)):\n", "                        self.writer.add_scalar(f\"analysis/{k}\", float(v), step)\n", "        except Exception:\n", "            pass\n", "    def close(self) -> None:\n", "        if self.writer is not None:\n", "            try:\n", "                self.writer.flush()\n", "                self.writer.close()\n", "            except Exception:\n", "                pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LivePlotter:\n", "    \"\"\"\n", "    Very simple realtime plots for \"getting a feel\" during dev runs.\n", "    Uses matplotlib interactive mode; safe to disable for headless/prod.\n", "    \"\"\"\n", "    def __init__(self):\n", "        self.enabled = False\n", "        self.steps: List[int] = []\n", "        self.train_loss: List[float] = []\n", "        self.val_loss: List[float] = []\n", "        self.entropy: List[float] = []\n", "        \n", "        # Self-opt history\n", "        self.opt_steps: List[int] = []\n", "        self.opt_block: List[int] = []\n", "        self.opt_fused: List[int] = []  # 0=none, 1=1pass, 2=2pass\n", "        try:\n", "            import matplotlib.pyplot as plt  # type: ignore\n", "            self.plt = plt\n", "            self.plt.ion()\n", "            # Layout: 2x3 grid\n", "            # Row 0: Train Loss, Val Loss, Entropy\n", "            # Row 1: Decode Block, Fused Mode, (Empty/Future)\n", "            self.fig, self.ax = self.plt.subplots(2, 3, figsize=(12, 7))\n", "            self.ax = self.ax.flatten()\n", "            self.fig.tight_layout(pad=2.0)\n", "            \n", "            # 0: Train Loss\n", "            self.l1, = self.ax[0].plot([], [], label='Train')\n", "            self.ax[0].set_title(\"Train loss\")\n", "            \n", "            # 1: Val Loss\n", "            self.l2, = self.ax[1].plot([], [], label='Val', color='orange')\n", "            self.ax[1].set_title(\"Val loss\")\n", "            \n", "            # 2: Entropy\n", "            self.l3, = self.ax[2].plot([], [], color='green')\n", "            self.ax[2].set_title(\"Attn entropy\")\n", "            \n", "            # 3: Decode Block\n", "            self.l4, = self.ax[3].plot([], [], marker='o', linestyle='-', color='purple')\n", "            self.ax[3].set_title(\"Decode Block Size\")\n", "            \n", "            # 4: Fused Mode\n", "            self.l5, = self.ax[4].plot([], [], marker='x', linestyle='None', color='red')\n", "            self.ax[4].set_title(\"Fused Mode (0=none, 1=1p, 2=2p)\")\n", "            self.ax[4].set_ylim(-0.5, 2.5)\n", "            self.ax[4].set_yticks([0, 1, 2])\n", "            self.ax[4].set_yticklabels([\"none\", \"1pass\", \"2pass\"])\n", "            self.fig.show()\n", "            self.enabled = True\n", "        except Exception as e:\n", "            print(f\"[warn] Live plot disabled: {e}\")\n", "            self.enabled = False\n", "    def maybe_update(self, event: Dict[str, Any]) -> None:\n", "        if not self.enabled:\n", "            return\n", "        et = str(event.get(\"type\", \"\"))\n", "        step = int(event.get(\"step\", 0))\n", "        \n", "        updated = False\n", "        if et == \"train\" and \"loss\" in event:\n", "            self.steps.append(step)\n", "            self.train_loss.append(_safe_float(event[\"loss\"]))\n", "            updated = True\n", "        elif et == \"eval\" and \"val_loss\" in event:\n", "            # Align val points to same step index array by appending.\n", "            self.val_loss.append(_safe_float(event[\"val_loss\"]))\n", "            updated = True\n", "        elif et == \"analysis\":\n", "            if \"attn_entropy_mean\" in event:\n", "                self.entropy.append(_safe_float(event[\"attn_entropy_mean\"]))\n", "                updated = True\n", "            \n", "            if event.get(\"subtype\") == \"selfopt_decode\":\n", "                # Handle self-optimization events\n", "                # bucket_key might be useful but for now just plot the latest decision\n", "                self.opt_steps.append(len(self.opt_steps)) # Simple index for x-axis\n", "                self.opt_block.append(int(event.get(\"decode_block\", 0)))\n", "                \n", "                fstr = str(event.get(\"fused\", \"none\"))\n", "                fval = 0\n", "                if \"1pass\" in fstr: fval = 1\n", "                elif \"2pass\" in fstr: fval = 2\n", "                self.opt_fused.append(fval)\n", "                updated = True\n", "        if not updated:\n", "            return\n\n", "        # Update every time we get something new.\n", "        try:\n", "            self.l1.set_data(self.steps, self.train_loss)\n", "            self.ax[0].relim(); self.ax[0].autoscale_view()\n", "            \n", "            if self.val_loss:\n", "                xs = self.steps[-len(self.val_loss):] if len(self.val_loss) <= len(self.steps) else list(range(len(self.val_loss)))\n", "                self.l2.set_data(xs, self.val_loss)\n", "                self.ax[1].relim(); self.ax[1].autoscale_view()\n", "            \n", "            if self.entropy:\n", "                xs = self.steps[-len(self.entropy):] if len(self.entropy) <= len(self.steps) else list(range(len(self.entropy)))\n", "                self.l3.set_data(xs, self.entropy)\n", "                self.ax[2].relim(); self.ax[2].autoscale_view()\n", "                \n", "            if self.opt_block:\n", "                self.l4.set_data(self.opt_steps, self.opt_block)\n", "                self.ax[3].relim(); self.ax[3].autoscale_view()\n", "                \n", "            if self.opt_fused:\n", "                self.l5.set_data(self.opt_steps, self.opt_fused)\n", "                # Fixed Y limits for categorical, just scale X\n", "                self.ax[4].set_xlim(0, max(len(self.opt_steps), 10))\n", "            \n", "            self.fig.canvas.draw()\n", "            self.fig.canvas.flush_events()\n", "        except Exception:\n", "            pass\n", "    def close(self) -> None:\n", "        if not self.enabled:\n", "            return\n", "        try:\n", "            self.plt.ioff()\n", "            self.plt.close(self.fig)\n", "        except Exception:\n", "            pass"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-----------------------------<br>\n", "Training utilities (v28)<br>\n", "-----------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _parse_two_floats(s: str, default: Tuple[float, float]) -> Tuple[float, float]:\n", "    try:\n", "        a, b = s.split(\",\")\n", "        return float(a), float(b)\n", "    except Exception:\n", "        return default"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _supports_dtype(device: torch.device, dtype: torch.dtype) -> bool:\n", "    \"\"\"\n", "    Cheap feature probe: try a tiny op on the target device.\n", "    (Some backends claim support but will error at runtime for specific dtypes/ops.)\n", "    \"\"\"\n", "    try:\n", "        x = torch.ones(8, device=device, dtype=dtype)\n", "        y = (x * 1.0001).sum()\n", "        # Trigger execution\n", "        _ = float(y.detach().to(\"cpu\").item())\n", "        return True\n", "    except Exception:\n", "        return False"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def resolve_dtype(device: torch.device, spec: str, *, default: torch.dtype) -> torch.dtype:\n", "    spec = str(spec).lower()\n", "    if spec in (\"fp32\", \"float32\", \"f32\"):\n", "        return torch.float32\n", "    if spec in (\"bf16\", \"bfloat16\"):\n", "        dt = torch.bfloat16\n", "    elif spec in (\"fp16\", \"float16\", \"f16\"):\n", "        dt = torch.float16\n", "    else:\n", "        dt = default\n\n", "    # Backend reality check\n", "    if device.type in (\"cuda\", \"mps\"):\n", "        if dt in (torch.float16, torch.bfloat16) and not _supports_dtype(device, dt):\n", "            # last resort: fp16 -> bf16 -> fp32\n", "            if dt == torch.float16 and _supports_dtype(device, torch.bfloat16):\n", "                return torch.bfloat16\n", "            return torch.float32\n", "    if device.type == \"cpu\" and dt == torch.float16:\n", "        # CPU float16 is generally painful / unsupported for many ops.\n", "        return torch.float32\n", "    return dt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def device_synchronize(device: torch.device) -> None:\n", "    try:\n", "        if device.type == \"cuda\":\n", "            torch.cuda.synchronize(device)\n", "        elif device.type == \"mps\":\n", "            if hasattr(torch, \"mps\") and hasattr(torch.mps, \"synchronize\"):\n", "                torch.mps.synchronize()\n", "    except Exception:\n", "        pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_device_mem_stats(device: torch.device) -> Dict[str, float]:\n", "    \"\"\"\n", "    Returns memory stats in bytes where possible.\n", "    Keys are backend-specific to avoid implying false equivalence.\n", "    \"\"\"\n", "    out: Dict[str, float] = {}\n", "    try:\n", "        if device.type == \"cuda\" and torch.cuda.is_available():\n", "            out[\"cuda_mem_alloc_bytes\"] = float(torch.cuda.memory_allocated(device))\n", "            out[\"cuda_mem_reserved_bytes\"] = float(torch.cuda.memory_reserved(device))\n", "            out[\"cuda_mem_peak_bytes\"] = float(torch.cuda.max_memory_allocated(device))\n", "        elif device.type == \"mps\":\n", "            if hasattr(torch, \"mps\"):\n", "                if hasattr(torch.mps, \"current_allocated_memory\"):\n", "                    out[\"mps_mem_alloc_bytes\"] = float(torch.mps.current_allocated_memory())\n", "                if hasattr(torch.mps, \"driver_allocated_memory\"):\n", "                    out[\"mps_mem_driver_bytes\"] = float(torch.mps.driver_allocated_memory())\n", "    except Exception:\n", "        pass\n", "    return out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_process_rss_bytes() -> Optional[int]:\n", "    \"\"\"\n", "    Best-effort RSS (resident set size).\n", "    \"\"\"\n", "    # psutil is nicest if available.\n", "    try:\n", "        import psutil  # type: ignore\n", "        return int(psutil.Process(os.getpid()).memory_info().rss)\n", "    except Exception:\n", "        pass\n", "    # Fallback: resource.getrusage\n", "    try:\n", "        import resource  # type: ignore\n", "        rss = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n", "        # Linux: KB, macOS: bytes\n", "        if sys.platform == \"darwin\":\n", "            return int(rss)\n", "        return int(rss) * 1024\n", "    except Exception:\n", "        return None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Lion(torch.optim.Optimizer):\n", "    \"\"\"\n", "    Lion optimizer (https://arxiv.org/abs/2302.06675).\n", "    Memory win vs AdamW: ~1 momentum state instead of 2 (m, v).\n", "    Often competitive for transformers, especially when you crank scale on a single device.\n", "    This implementation uses decoupled weight decay.\n", "    \"\"\"\n", "    def __init__(\n", "        self,\n", "        params,\n", "        lr: float = 1e-4,\n", "        betas: Tuple[float, float] = (0.9, 0.99),\n", "        weight_decay: float = 0.0,\n", "    ):\n", "        if lr <= 0.0:\n", "            raise ValueError(f\"Invalid lr: {lr}\")\n", "        b1, b2 = betas\n", "        if not (0.0 <= b1 < 1.0 and 0.0 <= b2 < 1.0):\n", "            raise ValueError(f\"Invalid betas: {betas}\")\n", "        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n", "        super().__init__(params, defaults)\n", "    @torch.no_grad()\n", "    def step(self, closure=None):  # type: ignore\n", "        loss = None\n", "        if closure is not None:\n", "            with torch.enable_grad():\n", "                loss = closure()\n", "        for group in self.param_groups:\n", "            lr = float(group[\"lr\"])\n", "            wd = float(group.get(\"weight_decay\", 0.0))\n", "            beta1, beta2 = group[\"betas\"]\n", "            for p in group[\"params\"]:\n", "                if p.grad is None:\n", "                    continue\n", "                g = p.grad\n", "                if g.is_sparse:\n", "                    raise RuntimeError(\"Lion does not support sparse gradients.\")\n", "                # Decoupled weight decay\n", "                if wd != 0.0:\n", "                    p.mul_(1.0 - lr * wd)\n", "                state = self.state[p]\n", "                if len(state) == 0:\n", "                    state[\"exp_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n", "                exp_avg = state[\"exp_avg\"]\n", "                # First momentum update\n", "                exp_avg.mul_(beta1).add_(g, alpha=(1.0 - beta1))\n", "                # Sign update\n", "                p.add_(exp_avg.sign(), alpha=-lr)\n", "                # Second momentum update\n", "                exp_avg.mul_(beta2).add_(g, alpha=(1.0 - beta2))\n", "        return loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def lr_for_step(\n", "    step: int,\n", "    *,\n", "    base_lr: float,\n", "    total_steps: int,\n", "    schedule: str,\n", "    warmup_steps: int = 0,\n", "    min_lr: float = 0.0,\n", ") -> float:\n", "    schedule = str(schedule).lower()\n", "    total_steps = max(int(total_steps), 1)\n", "    warmup_steps = max(int(warmup_steps), 0)\n", "    if schedule == \"constant\":\n", "        if warmup_steps > 0 and step < warmup_steps:\n", "            return base_lr * (step + 1) / warmup_steps\n", "        return base_lr\n", "    if schedule == \"cosine\":\n", "        if warmup_steps > 0 and step < warmup_steps:\n", "            return base_lr * (step + 1) / warmup_steps\n", "        # cosine decay from base_lr -> min_lr\n", "        denom = max(total_steps - warmup_steps, 1)\n", "        t = (step - warmup_steps) / denom\n", "        t = min(max(t, 0.0), 1.0)\n", "        return min_lr + 0.5 * (base_lr - min_lr) * (1.0 + math.cos(math.pi * t))\n\n", "    # fallback\n", "    return base_lr"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parse_seq_schedule(spec: Optional[str]) -> Optional[List[Tuple[int, int]]]:\n", "    \"\"\"\n", "    \"256@0,512@1000,1024@3000\" -> [(0,256),(1000,512),(3000,1024)] sorted by step.\n", "    \"\"\"\n", "    if spec is None:\n", "        return None\n", "    spec = str(spec).strip()\n", "    if not spec:\n", "        return None\n", "    pairs: List[Tuple[int, int]] = []\n", "    for part in spec.split(\",\"):\n", "        part = part.strip()\n", "        if not part:\n", "            continue\n", "        if \"@\" not in part:\n", "            continue\n", "        a, b = part.split(\"@\", 1)\n", "        try:\n", "            seq = int(a)\n", "            st = int(b)\n", "            pairs.append((st, seq))\n", "        except Exception:\n", "            continue\n", "    pairs.sort(key=lambda x: x[0])\n", "    return pairs if pairs else None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def seq_len_for_step(\n", "    step: int,\n", "    *,\n", "    default_seq_len: int,\n", "    schedule: Optional[List[Tuple[int, int]]],\n", ") -> int:\n", "    if not schedule:\n", "        return int(default_seq_len)\n", "    cur = int(default_seq_len)\n", "    for st, seq in schedule:\n", "        if step >= st:\n", "            cur = int(seq)\n", "    return int(cur)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def optimizer_state_bytes(opt: torch.optim.Optimizer) -> int:\n", "    total = 0\n", "    try:\n", "        for st in opt.state.values():\n", "            if isinstance(st, dict):\n", "                for v in st.values():\n", "                    if torch.is_tensor(v):\n", "                        total += v.numel() * v.element_size()\n", "    except Exception:\n", "        return -1\n", "    return int(total)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LiveDashboard:\n", "    \"\"\"\n", "    Console \"live view\" for training: rich dashboard when available, with a basic fallback.\n", "    Goal: see *everything that matters* without drowning in logs.\n", "    \"\"\"\n", "    def __init__(\n", "        self,\n", "        mode: str,\n", "        *,\n", "        total_steps: int,\n", "        out_dir: str,\n", "        cfg: ModelConfig,\n", "        args: argparse.Namespace,\n", "        device: torch.device,\n", "    ):\n", "        self.mode = str(mode).lower()\n", "        self.total_steps = int(total_steps)\n", "        self.out_dir = str(out_dir)\n", "        self.cfg = cfg\n", "        self.args = args\n", "        self.device = device\n", "        self.last_train: Dict[str, Any] = {}\n", "        self.last_eval: Dict[str, Any] = {}\n", "        self.last_msg: str = \"\"\n", "        self.enabled = (self.mode != \"off\")\n", "        self._rich: Optional[Dict[str, Any]] = None\n", "        self._console = None\n", "        self._live = None\n", "        self._progress = None\n", "        self._task_id = None\n\n", "        # Determine backend\n", "        want_rich = self.mode in (\"auto\", \"rich\")\n", "        use_tty = hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty()\n", "        if self.enabled and want_rich and use_tty:\n", "            try:\n", "                from rich.console import Console  # type: ignore\n", "                from rich.live import Live  # type: ignore\n", "                from rich.table import Table  # type: ignore\n", "                from rich.panel import Panel  # type: ignore\n", "                from rich.progress import Progress, BarColumn, TextColumn, TimeElapsedColumn, TimeRemainingColumn  # type: ignore\n", "                from rich.columns import Columns  # type: ignore\n", "                from rich.layout import Layout  # type: ignore\n", "                from rich.text import Text  # type: ignore\n", "                from rich.align import Align  # type: ignore\n", "                from rich import box  # type: ignore\n", "                self._rich = {\n", "                    \"Table\": Table,\n", "                    \"Panel\": Panel,\n", "                    \"Progress\": Progress,\n", "                    \"Columns\": Columns,\n", "                    \"Layout\": Layout,\n", "                    \"Text\": Text,\n", "                    \"Align\": Align,\n", "                    \"Live\": Live,\n", "                    \"Console\": Console,\n", "                    \"BarColumn\": BarColumn,\n", "                    \"TextColumn\": TextColumn,\n", "                    \"TimeElapsedColumn\": TimeElapsedColumn,\n", "                    \"TimeRemainingColumn\": TimeRemainingColumn,\n", "                    \"box\": box,\n", "                }\n", "                self._console = Console()\n", "                self._progress = Progress(\n", "                    TextColumn(\"[bold]train[/bold]\"),\n", "                    BarColumn(),\n", "                    TextColumn(\"{task.completed}/{task.total}\"),\n", "                    TimeElapsedColumn(),\n", "                    TimeRemainingColumn(),\n", "                    transient=False,\n", "                )\n", "                self._task_id = self._progress.add_task(\"steps\", total=self.total_steps)\n", "                self._live = Live(refresh_per_second=8, console=self._console)\n", "                self._live.start()\n", "            except Exception:\n", "                # rich not available -> basic mode\n", "                self._rich = None\n", "                self._console = None\n", "                self._live = None\n", "                self._progress = None\n", "                self._task_id = None\n", "        if self.enabled and self._rich is None and self.mode == \"rich\":\n", "            # user explicitly requested rich but it failed: keep basic fallback enabled\n", "            self.enabled = True\n", "    def close(self) -> None:\n", "        try:\n", "            if self._live is not None:\n", "                self._live.stop()\n", "        except Exception:\n", "            pass\n", "    def update_train(self, metrics: Dict[str, Any]) -> None:\n", "        self.last_train = dict(metrics)\n", "        self._refresh()\n", "    def update_eval(self, metrics: Dict[str, Any]) -> None:\n", "        self.last_eval = dict(metrics)\n", "        self._refresh()\n", "    def message(self, msg: str) -> None:\n", "        self.last_msg = str(msg)\n", "        if self._console is not None:\n", "            try:\n", "                self._console.log(self.last_msg)\n", "            except Exception:\n", "                pass\n", "        else:\n", "            print(self.last_msg)\n", "    def _refresh(self) -> None:\n", "        if not self.enabled:\n", "            return\n", "        if self._rich is None:\n", "            # basic fallback\n", "            if self.last_train and (\"step\" in self.last_train):\n", "                s = int(self.last_train.get(\"step\", 0))\n", "                loss = self.last_train.get(\"loss\", float(\"nan\"))\n", "                tok_s = self.last_train.get(\"tok_s\", float(\"nan\"))\n", "                lr = self.last_train.get(\"lr\", float(\"nan\"))\n", "                mem = \"\"\n", "                if \"cuda_mem_alloc_bytes\" in self.last_train:\n", "                    mem = f\" cuda_alloc={human_bytes(int(self.last_train['cuda_mem_alloc_bytes']))}\"\n", "                if \"mps_mem_alloc_bytes\" in self.last_train:\n", "                    mem = f\" mps_alloc={human_bytes(int(self.last_train['mps_mem_alloc_bytes']))}\"\n", "                print(f\"[step {s}] loss={loss:.4f} lr={lr:.2e} tok/s={tok_s:.0f}{mem}\")\n", "            return\n\n", "        # rich render\n", "        try:\n", "            Table = self._rich[\"Table\"]\n", "            Panel = self._rich[\"Panel\"]\n", "            Columns = self._rich[\"Columns\"]\n", "            Text = self._rich[\"Text\"]\n", "            Align = self._rich[\"Align\"]\n", "            box = self._rich[\"box\"]\n\n", "            # progress\n", "            if self._progress is not None and self._task_id is not None:\n", "                try:\n", "                    s = int(self.last_train.get(\"step\", 0)) if self.last_train else 0\n", "                    self._progress.update(self._task_id, completed=min(s, self.total_steps))\n", "                except Exception:\n", "                    pass\n", "            def _kv(title: str, items: List[Tuple[str, Any]]) -> Any:\n", "                t = Table(title=title, box=box.SIMPLE, show_header=False, pad_edge=False)\n", "                t.add_column(\"k\", style=\"bold\")\n", "                t.add_column(\"v\")\n", "                for k, v in items:\n", "                    t.add_row(str(k), str(v))\n", "                return t\n", "            train = self.last_train\n", "            ev = self.last_eval\n\n", "            # Left: core train metrics\n", "            items1: List[Tuple[str, Any]] = []\n", "            if train:\n", "                items1 += [\n", "                    (\"step\", train.get(\"step\", \"\")),\n", "                    (\"loss\", f\"{train.get('loss', float('nan')):.6f}\" if \"loss\" in train else \"\"),\n", "                    (\"ppl\", f\"{train.get('ppl', float('nan')):.2f}\" if \"ppl\" in train else \"\"),\n", "                    (\"lr\", f\"{train.get('lr', 0.0):.3e}\" if \"lr\" in train else \"\"),\n", "                    (\"grad_norm\", f\"{train.get('grad_norm_total', float('nan')):.3f}\" if \"grad_norm_total\" in train else \"\"),\n", "                    (\"scale\", f\"{train.get('amp_scale', '')}\" if \"amp_scale\" in train else \"\"),\n", "                ]\n\n", "            # Middle: perf\n", "            items2: List[Tuple[str, Any]] = []\n", "            if train:\n", "                items2 += [\n", "                    (\"tok/s\", f\"{train.get('tok_s', 0.0):.0f}\" if \"tok_s\" in train else \"\"),\n", "                    (\"ms/step\", f\"{train.get('step_ms', 0.0):.2f}\" if \"step_ms\" in train else \"\"),\n", "                    (\"data ms\", f\"{train.get('data_ms', 0.0):.2f}\" if \"data_ms\" in train else \"\"),\n", "                    (\"fwd ms\", f\"{train.get('fwd_ms', 0.0):.2f}\" if \"fwd_ms\" in train else \"\"),\n", "                    (\"bwd ms\", f\"{train.get('bwd_ms', 0.0):.2f}\" if \"bwd_ms\" in train else \"\"),\n", "                    (\"opt ms\", f\"{train.get('opt_ms', 0.0):.2f}\" if \"opt_ms\" in train else \"\"),\n", "                    (\"seq_len\", f\"{int(train.get('seq_len', 0))}\" if \"seq_len\" in train else \"\"),\n", "                    (\"gbs\", f\"{int(train.get('global_batch', 0))}\" if \"global_batch\" in train else \"\"),\n", "                ]\n\n", "            # Right: memory\n", "            items3: List[Tuple[str, Any]] = []\n", "            rss = train.get(\"cpu_rss_bytes\", None) if train else None\n", "            if rss is not None:\n", "                items3.append((\"cpu rss\", human_bytes(int(rss))))\n", "            if train:\n", "                if \"cuda_mem_alloc_bytes\" in train:\n", "                    items3 += [\n", "                        (\"cuda alloc\", human_bytes(int(train[\"cuda_mem_alloc_bytes\"]))),\n", "                        (\"cuda reserv\", human_bytes(int(train.get(\"cuda_mem_reserved_bytes\", 0)))),\n", "                        (\"cuda peak\", human_bytes(int(train.get(\"cuda_mem_peak_bytes\", 0)))),\n", "                    ]\n", "                if \"mps_mem_alloc_bytes\" in train:\n", "                    items3 += [\n", "                        (\"mps alloc\", human_bytes(int(train[\"mps_mem_alloc_bytes\"]))),\n", "                    ]\n", "                if \"mps_mem_driver_bytes\" in train:\n", "                    items3 += [\n", "                        (\"mps driver\", human_bytes(int(train[\"mps_mem_driver_bytes\"]))),\n", "                    ]\n", "                if \"opt_state_bytes\" in train and int(train.get(\"opt_state_bytes\", -1)) >= 0:\n", "                    items3 += [\n", "                        (\"opt state\", human_bytes(int(train[\"opt_state_bytes\"]))),\n", "                    ]\n\n", "            # Eval panel\n", "            ev_items: List[Tuple[str, Any]] = []\n", "            if ev:\n", "                ev_items += [\n", "                    (\"val_loss\", f\"{ev.get('val_loss', float('nan')):.6f}\" if \"val_loss\" in ev else \"\"),\n", "                    (\"val_ppl\", f\"{ev.get('val_ppl', float('nan')):.2f}\" if \"val_ppl\" in ev else \"\"),\n", "                    (\"best_val\", f\"{ev.get('best_val', float('nan')):.6f}\" if \"best_val\" in ev else \"\"),\n", "                ]\n", "            cols = Columns(\n", "                [\n", "                    Panel(_kv(\"train\", items1), padding=(0, 1)),\n", "                    Panel(_kv(\"perf\", items2), padding=(0, 1)),\n", "                    Panel(_kv(\"mem\", items3), padding=(0, 1)),\n", "                ],\n", "                expand=True,\n", "            )\n", "            footer_text = self.last_msg or \"\"\n", "            if ev_items:\n", "                footer = Columns([Panel(_kv(\"eval\", ev_items), padding=(0, 1)), Panel(Text(footer_text), padding=(0, 1))])\n", "            else:\n", "                footer = Panel(Text(footer_text), padding=(0, 1))\n\n", "            # Vertical layout: progress (top), metrics (middle), footer (bottom)\n", "            Layout = self._rich[\"Layout\"]\n", "            layout = Layout()\n", "            layout.split_column(\n", "                Layout(Panel(self._progress), name=\"progress\", size=3),\n", "                Layout(Panel(cols), name=\"main\", ratio=1),\n", "                Layout(footer, name=\"footer\", size=7),\n", "            )\n", "            if self._live is not None:\n", "                self._live.update(layout)\n", "        except Exception:\n", "            pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_grad_norms(model: nn.Module) -> Dict[str, float]:\n", "    \"\"\"\n", "    Gradient norms grouped into {embed, attn, ffn} plus optional sem/geo for decoupled.\n", "    \"\"\"\n", "    sums: Dict[str, float] = {\"embed\": 0.0, \"attn\": 0.0, \"ffn\": 0.0, \"attn_sem\": 0.0, \"attn_geo\": 0.0}\n", "    for name, p in model.named_parameters():\n", "        if p.grad is None:\n", "            continue\n", "        g = p.grad.detach()\n", "        # Keep this cheap; avoid float64.\n", "        g2 = float(g.float().pow(2).sum().item())\n", "        if name.startswith(\"tok_emb\") or name.startswith(\"emb_in\") or name.startswith(\"emb_out\"):\n", "            sums[\"embed\"] += g2\n", "        elif \".attn.\" in name:\n", "            sums[\"attn\"] += g2\n", "            if any(s in name for s in (\".q_sem.\", \".k_sem.\")):\n", "                sums[\"attn_sem\"] += g2\n", "            if any(s in name for s in (\".q_geo.\", \".k_geo.\")):\n", "                sums[\"attn_geo\"] += g2\n", "        elif \".ff.\" in name:\n", "            sums[\"ffn\"] += g2\n", "    out: Dict[str, float] = {}\n", "    total = 0.0\n", "    for k, v in sums.items():\n", "        out[f\"grad_norm_{k}\"] = math.sqrt(max(v, 0.0))\n", "        total += float(v)\n", "    out[\"grad_norm_total\"] = math.sqrt(max(total, 0.0))\n", "    return out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _power_iter_spectral_norm(W: torch.Tensor, iters: int = 8) -> float:\n", "    \"\"\"\n", "    Estimates spectral norm ||W||_2 by power iteration.\n", "    Works on CPU for portability (MPS has gaps for some linalg ops).\n", "    \"\"\"\n", "    try:\n", "        A = W.detach().float().cpu()\n", "        if A.ndim != 2:\n", "            A = A.view(A.shape[0], -1)\n", "        m, n = A.shape\n", "        # start vector\n", "        v = torch.randn(n)\n", "        v = v / (v.norm() + 1e-9)\n", "        for _ in range(max(1, iters)):\n", "            u = A @ v\n", "            u = u / (u.norm() + 1e-9)\n", "            v = A.t() @ u\n", "            v = v / (v.norm() + 1e-9)\n", "        sigma = float((u @ (A @ v)).abs().item())\n", "        return sigma\n", "    except Exception:\n", "        return float(\"nan\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def stable_rank(W: torch.Tensor) -> float:\n", "    \"\"\"\n", "    Stable rank = ||W||_F^2 / ||W||_2^2 (robust proxy for effective rank).\n", "    \"\"\"\n", "    try:\n", "        A = W.detach().float().cpu()\n", "        if A.ndim != 2:\n", "            A = A.view(A.shape[0], -1)\n", "        fro2 = float(A.pow(2).sum().item())\n", "        spec = _power_iter_spectral_norm(A, iters=8)\n", "        denom = max(spec * spec, 1e-12)\n", "        return float(fro2 / denom)\n", "    except Exception:\n", "        return float(\"nan\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@torch.no_grad()\n", "def analyze_attention(\n", "    model: GPT,\n", "    idx: torch.Tensor,\n", "    *,\n", "    layers: List[int],\n", "    heads: List[int],\n", "    max_tokens: int,\n", "    topk: int,\n", "    local_window: int,\n", "    save_mats: bool,\n", "    save_scores: bool,\n", "    compute_svd: bool,\n", ") -> Tuple[Dict[str, float], Dict[str, torch.Tensor]]:\n", "    \"\"\"\n", "    Runs a lightweight analysis pass that:\n", "      - captures ln1(x) for selected layers\n", "      - recomputes attention probabilities explicitly (so we can measure entropy / sparsity / rank)\n", "      - optionally returns attention matrices + singular values for HDF5 persistence\n", "    \"\"\"\n", "    was_training = model.training\n", "    model.eval()\n\n", "    # Trim to analysis window\n", "    B, T = idx.shape\n", "    T = min(int(T), int(max_tokens))\n", "    idx = idx[:, :T]\n", "    device = idx.device\n", "    ninfty = neg_inf(torch.float32)\n\n", "    # causal mask: (1,1,T,T)\n", "    causal = torch.tril(torch.ones((T, T), device=device, dtype=torch.bool)).view(1, 1, T, T)\n\n", "    # capture ln1 outputs for requested layers\n", "    acts: Dict[int, torch.Tensor] = {}\n", "    hooks: List[Any] = []\n", "    def _resolve_layer(i: int) -> int:\n", "        return i if i >= 0 else (model.cfg.n_layer + i)\n", "    layer_ids = sorted(set(_resolve_layer(i) for i in layers))\n", "    for li in layer_ids:\n", "        if li < 0 or li >= model.cfg.n_layer:\n", "            continue\n", "        def _make_hook(layer_index: int):\n", "            def hook(module, inp, out):  # noqa: ANN001\n", "                # out: (B,T,d_model)\n", "                acts[layer_index] = out.detach()\n", "            return hook\n", "        hooks.append(model.blocks[li].ln1.register_forward_hook(_make_hook(li)))\n\n", "    # Run a forward to populate acts (cheap; no grads).\n", "    _ = model(idx)\n", "    for h in hooks:\n", "        try:\n", "            h.remove()\n", "        except Exception:\n", "            pass\n\n", "    # Stats accumulators\n", "    entropies: List[float] = []\n", "    topk_masses: List[float] = []\n", "    null_masses: List[float] = []\n", "    local_masses: List[float] = []\n", "    sem_ratios: List[float] = []\n", "    geo_ratios: List[float] = []\n", "    eranks: List[float] = []\n", "    tensors_out: Dict[str, torch.Tensor] = {}\n\n", "    # For weight stable rank (projection matrices) on selected layers\n", "    w_sr: List[float] = []\n", "    for li, x_ln in acts.items():\n", "        blk = model.blocks[li]\n", "        attn = blk.attn\n", "        cfg = attn.cfg\n\n", "        # Estimate stable rank of the attention projection(s) (proxy for \"effective rank of attention space\")\n", "        try:\n", "            if cfg.attn_mode in (\"standard\", \"bottleneck\", \"gqa\"):\n", "                w_sr.append(stable_rank(attn.q_proj.weight))\n", "            else:\n", "                w_sr.append(stable_rank(attn.q_sem.weight))\n", "                w_sr.append(stable_rank(attn.q_geo.weight))\n", "        except Exception:\n", "            pass\n\n", "        # Compute attention probs (explicit softmax) in fp32\n", "        x_ln_f = x_ln.float()\n", "        B2, T2, _ = x_ln_f.shape\n", "        assert T2 == T\n", "        if cfg.attn_mode in (\"standard\", \"bottleneck\"):\n", "            q = attn.q_proj(x_ln_f)\n", "            k = attn.k_proj(x_ln_f)\n", "            v = attn.v_proj(x_ln_f)\n", "            qh = attn._shape(q, attn.qk_head_dim)\n", "            kh = attn._shape(k, attn.qk_head_dim)\n", "            vh = attn._shape(v, attn.v_head_dim)\n", "            if attn.rotary is not None:\n", "                qh = attn.rotary.rotate(qh, 0)\n", "                kh = attn.rotary.rotate(kh, 0)\n", "            qh = attn._apply_logit_scale_to_q(qh)\n", "            scale = 1.0 / math.sqrt(attn.qk_head_dim)\n", "            scores = torch.matmul(qh, kh.transpose(-2, -1)) * scale  # (B,H,T,T)\n", "            scores = scores.masked_fill(~causal, ninfty)\n", "            if cfg.null_attn:\n", "                k_null = attn._shape(attn.k_null.expand(B2, 1, -1), attn.qk_head_dim)\n", "                s_null = torch.matmul(qh, k_null.transpose(-2, -1)) * scale  # (B,H,T,1)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                keep = torch.cat([torch.ones((1, 1, T, 1), device=device, dtype=torch.bool), causal], dim=-1)\n", "                scores = scores.masked_fill(~keep, ninfty)\n", "            p = F.softmax(scores, dim=-1)  # (B,H,T,K)\n\n", "            # local window mass (how much attention stays near the diagonal)\n", "            if local_window > 0:\n", "                w = int(local_window)\n", "                # key positions for each row\n", "                key_pos = torch.arange(p.size(-1), device=device)\n", "                if cfg.null_attn:\n", "                    # skip null key at index 0\n", "                    key_pos = key_pos - 1\n", "                q_pos = torch.arange(T, device=device).view(T, 1)\n", "                # allow keys in [q-w, q] (causal + local)\n", "                lo = (q_pos - w).clamp(min=0)\n", "                hi = q_pos\n", "                # mask: (T,K)\n", "                m_local = (key_pos.view(1, -1) >= lo) & (key_pos.view(1, -1) <= hi)\n", "                # broadcast to (B,H,T,K)\n", "                m_local_b = m_local.view(1, 1, T, -1)\n", "                local_mass = (p * m_local_b.float()).sum(dim=-1).mean().item()\n", "                local_masses.append(float(local_mass))\n\n", "            # entropy + topk mass\n", "            p_cl = p.clamp(min=1e-9)\n", "            ent = (-(p_cl * p_cl.log()).sum(dim=-1)).mean().item()\n", "            entropies.append(float(ent))\n", "            k = min(int(topk), p.size(-1))\n", "            top_mass = p.topk(k, dim=-1).values.sum(dim=-1).mean().item()\n", "            topk_masses.append(float(top_mass))\n", "            if cfg.null_attn:\n", "                null_masses.append(float(p[..., 0].mean().item()))\n\n", "            # effective rank via SVD on selected heads (using real-token square matrix)\n", "            if compute_svd and heads:\n", "                for h in heads:\n", "                    hh = int(h)\n", "                    if hh < 0 or hh >= attn.H:\n", "                        continue\n", "                    A = p[0, hh, :, 1:] if cfg.null_attn else p[0, hh, :, :]\n", "                    A_cpu = A.detach().float().cpu()\n", "                    try:\n", "                        s = torch.linalg.svdvals(A_cpu)\n", "                        s_sum = float(s.sum().item()) + 1e-12\n", "                        ps = (s / s_sum).clamp(min=1e-12)\n", "                        er = float(torch.exp(-(ps * ps.log()).sum()).item())\n", "                        eranks.append(er)\n", "                        if save_mats:\n", "                            tensors_out[f\"attn/L{li}/H{hh}\"] = A.detach().to(torch.float16)\n", "                        if save_mats:\n", "                            tensors_out[f\"svd/L{li}/H{hh}\"] = s.detach().to(torch.float32)\n", "                    except Exception:\n", "                        pass\n", "        elif cfg.attn_mode == \"gqa\":\n", "            q = attn.q_proj(x_ln_f)\n", "            k = attn.k_proj(x_ln_f)\n", "            v = attn.v_proj(x_ln_f)\n", "            qh = attn._shape(q, attn.qk_head_dim, H=attn.H)\n", "            kh = attn._shape(k, attn.qk_head_dim, H=attn.H_kv)\n", "            vh = attn._shape(v, attn.v_head_dim, H=attn.H_kv)\n", "            if attn.rotary is not None:\n", "                qh = attn.rotary.rotate(qh, 0)\n", "                kh = attn.rotary.rotate(kh, 0)\n", "            qh = attn._apply_logit_scale_to_q(qh)\n", "            kh_rep = kh.repeat_interleave(attn.group_size, dim=1)\n", "            vh_rep = vh.repeat_interleave(attn.group_size, dim=1)\n", "            scale = 1.0 / math.sqrt(attn.qk_head_dim)\n", "            scores = torch.matmul(qh, kh_rep.transpose(-2, -1)) * scale\n", "            scores = scores.masked_fill(~causal, ninfty)\n", "            if cfg.null_attn:\n", "                k_null = attn._shape(attn.k_null.expand(B2, 1, -1), attn.qk_head_dim, H=attn.H_kv)\n", "                k_null_rep = k_null.repeat_interleave(attn.group_size, dim=1)\n", "                s_null = torch.matmul(qh, k_null_rep.transpose(-2, -1)) * scale\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                keep = torch.cat([torch.ones((1, 1, T, 1), device=device, dtype=torch.bool), causal], dim=-1)\n", "                scores = scores.masked_fill(~keep, ninfty)\n", "            p = F.softmax(scores, dim=-1)\n", "            p_cl = p.clamp(min=1e-9)\n", "            entropies.append(float((-(p_cl * p_cl.log()).sum(dim=-1)).mean().item()))\n", "            ktop = min(int(topk), p.size(-1))\n", "            topk_masses.append(float(p.topk(ktop, dim=-1).values.sum(dim=-1).mean().item()))\n", "            if cfg.null_attn:\n", "                null_masses.append(float(p[..., 0].mean().item()))\n", "            if compute_svd and heads:\n", "                for h in heads:\n", "                    hh = int(h)\n", "                    if hh < 0 or hh >= attn.H:\n", "                        continue\n", "                    A = p[0, hh, :, 1:] if cfg.null_attn else p[0, hh, :, :]\n", "                    A_cpu = A.detach().float().cpu()\n", "                    try:\n", "                        s = torch.linalg.svdvals(A_cpu)\n", "                        s_sum = float(s.sum().item()) + 1e-12\n", "                        ps = (s / s_sum).clamp(min=1e-12)\n", "                        er = float(torch.exp(-(ps * ps.log()).sum()).item())\n", "                        eranks.append(er)\n", "                        if save_mats:\n", "                            tensors_out[f\"attn/L{li}/H{hh}\"] = A.detach().to(torch.float16)\n", "                            tensors_out[f\"svd/L{li}/H{hh}\"] = s.detach().to(torch.float32)\n", "                    except Exception:\n", "                        pass\n", "        elif cfg.attn_mode == \"decoupled\":\n", "            q_sem = attn.q_sem(x_ln_f)\n", "            k_sem = attn.k_sem(x_ln_f)\n", "            q_geo = attn.q_geo(x_ln_f)\n", "            k_geo = attn.k_geo(x_ln_f)\n", "            v = attn.v_proj(x_ln_f)\n", "            qsh = attn._shape(q_sem, attn.sem_head_dim)\n", "            ksh = attn._shape(k_sem, attn.sem_head_dim)\n", "            qgh = attn._shape(q_geo, attn.geo_head_dim)\n", "            kgh = attn._shape(k_geo, attn.geo_head_dim)\n", "            vh = attn._shape(v, attn.v_head_dim)\n", "            if attn.rotary is not None:\n", "                qgh = attn.rotary.rotate(qgh, 0)\n", "                kgh = attn.rotary.rotate(kgh, 0)\n", "            qsh = attn._apply_logit_scale_to_q(qsh)\n", "            qgh = attn._apply_logit_scale_to_q(qgh)\n", "            sem_scale = 1.0 / math.sqrt(attn.sem_head_dim)\n", "            geo_scale = 1.0 / math.sqrt(attn.geo_head_dim)\n", "            sem_logits = torch.matmul(qsh, ksh.transpose(-2, -1)) * sem_scale\n", "            geo_logits = torch.matmul(qgh, kgh.transpose(-2, -1)) * geo_scale\n", "            scores = sem_logits + geo_logits\n", "            scores = scores.masked_fill(~causal, ninfty)\n", "            if cfg.null_attn:\n", "                ksn = attn._shape(attn.k_sem_null.expand(B2, 1, -1), attn.sem_head_dim)\n", "                kgn = attn._shape(attn.k_geo_null.expand(B2, 1, -1), attn.geo_head_dim)\n", "                s_null = (torch.matmul(qsh, ksn.transpose(-2, -1)) * sem_scale + torch.matmul(qgh, kgn.transpose(-2, -1)) * geo_scale)\n", "                scores = torch.cat([s_null, scores], dim=-1)\n", "                keep = torch.cat([torch.ones((1, 1, T, 1), device=device, dtype=torch.bool), causal], dim=-1)\n", "                scores = scores.masked_fill(~keep, ninfty)\n", "            p = F.softmax(scores, dim=-1)\n\n", "            # sem/geo energy ratio\n", "            try:\n", "                sem_e = float(sem_logits.float().pow(2).mean().item())\n", "                geo_e = float(geo_logits.float().pow(2).mean().item())\n", "                denom = sem_e + geo_e + 1e-12\n", "                sem_ratios.append(sem_e / denom)\n", "                geo_ratios.append(geo_e / denom)\n", "            except Exception:\n", "                pass\n", "            p_cl = p.clamp(min=1e-9)\n", "            entropies.append(float((-(p_cl * p_cl.log()).sum(dim=-1)).mean().item()))\n", "            ktop = min(int(topk), p.size(-1))\n", "            topk_masses.append(float(p.topk(ktop, dim=-1).values.sum(dim=-1).mean().item()))\n", "            if cfg.null_attn:\n", "                null_masses.append(float(p[..., 0].mean().item()))\n\n", "            # local mass: restrict to last local_window real tokens (skip null)\n", "            if local_window > 0:\n", "                w = int(local_window)\n", "                key_pos = torch.arange(p.size(-1), device=device)\n", "                if cfg.null_attn:\n", "                    key_pos = key_pos - 1\n", "                q_pos = torch.arange(T, device=device).view(T, 1)\n", "                lo = (q_pos - w).clamp(min=0)\n", "                hi = q_pos\n", "                m_local = (key_pos.view(1, -1) >= lo) & (key_pos.view(1, -1) <= hi)\n", "                m_local_b = m_local.view(1, 1, T, -1)\n", "                local_mass = (p * m_local_b.float()).sum(dim=-1).mean().item()\n", "                local_masses.append(float(local_mass))\n", "            if compute_svd and heads:\n", "                for h in heads:\n", "                    hh = int(h)\n", "                    if hh < 0 or hh >= attn.H:\n", "                        continue\n", "                    A = p[0, hh, :, 1:] if cfg.null_attn else p[0, hh, :, :]\n", "                    A_cpu = A.detach().float().cpu()\n", "                    try:\n", "                        s = torch.linalg.svdvals(A_cpu)\n", "                        s_sum = float(s.sum().item()) + 1e-12\n", "                        ps = (s / s_sum).clamp(min=1e-12)\n", "                        er = float(torch.exp(-(ps * ps.log()).sum()).item())\n", "                        eranks.append(er)\n", "                        if save_mats:\n", "                            tensors_out[f\"attn/L{li}/H{hh}\"] = A.detach().to(torch.float16)\n", "                            tensors_out[f\"svd/L{li}/H{hh}\"] = s.detach().to(torch.float32)\n", "                        if save_scores:\n", "                            # Store the raw component scores (real tokens only).\n", "                            s_sem = sem_logits[0, hh, :, :].detach().to(torch.float16).cpu()\n", "                            s_geo = geo_logits[0, hh, :, :].detach().to(torch.float16).cpu()\n", "                            tensors_out[f\"sem_scores/L{li}/H{hh}\"] = s_sem\n", "                            tensors_out[f\"geo_scores/L{li}/H{hh}\"] = s_geo\n", "                    except Exception:\n", "                        pass\n", "        else:\n", "            continue\n\n", "    # summarize\n", "    out: Dict[str, float] = {}\n", "    if entropies:\n", "        out[\"attn_entropy_mean\"] = float(sum(entropies) / len(entropies))\n", "    if topk_masses:\n", "        out[\"attn_topk_mass_mean\"] = float(sum(topk_masses) / len(topk_masses))\n", "    if null_masses:\n", "        out[\"attn_null_mass_mean\"] = float(sum(null_masses) / len(null_masses))\n", "    if local_masses:\n", "        out[\"attn_local_mass_mean\"] = float(sum(local_masses) / len(local_masses))\n", "    if sem_ratios:\n", "        out[\"sem_energy_ratio_mean\"] = float(sum(sem_ratios) / len(sem_ratios))\n", "    if geo_ratios:\n", "        out[\"geo_energy_ratio_mean\"] = float(sum(geo_ratios) / len(geo_ratios))\n", "    if eranks:\n", "        out[\"attn_erank_mean\"] = float(sum(eranks) / len(eranks))\n", "    if w_sr:\n", "        out[\"proj_stable_rank_mean\"] = float(sum(w_sr) / len(w_sr))\n", "    if was_training:\n", "        model.train()\n", "    return out, tensors_out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate_analysis_png(jsonl_path: str, out_png: str) -> None:\n", "    \"\"\"\n", "    Small, opinionated end-of-run plot pack -> analysis.png.\n", "    \"\"\"\n", "    try:\n", "        import matplotlib.pyplot as plt  # type: ignore\n", "    except Exception as e:\n", "        raise RuntimeError(f\"matplotlib not available: {e}\")\n\n", "    # Read metrics\n", "    steps_train: List[int] = []\n", "    loss_train: List[float] = []\n", "    tok_s: List[float] = []\n", "    steps_eval: List[int] = []\n", "    loss_val: List[float] = []\n", "    loss_train_eval: List[float] = []\n", "    steps_an: List[int] = []\n", "    ent: List[float] = []\n", "    erank: List[float] = []\n", "    topk_mass: List[float] = []\n", "    sem_ratio: List[float] = []\n", "    local_mass: List[float] = []\n", "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n", "        for line in f:\n", "            line = line.strip()\n", "            if not line:\n", "                continue\n", "            try:\n", "                e = json.loads(line)\n", "            except Exception:\n", "                continue\n", "            t = str(e.get(\"type\", \"\"))\n", "            s = int(e.get(\"step\", 0))\n", "            if t == \"train\":\n", "                if \"loss\" in e:\n", "                    steps_train.append(s)\n", "                    loss_train.append(_safe_float(e[\"loss\"]))\n", "                if \"tok_s\" in e:\n", "                    tok_s.append(_safe_float(e[\"tok_s\"]))\n", "            elif t == \"eval\":\n", "                steps_eval.append(s)\n", "                if \"val_loss\" in e:\n", "                    loss_val.append(_safe_float(e[\"val_loss\"]))\n", "                if \"train_loss\" in e:\n", "                    loss_train_eval.append(_safe_float(e[\"train_loss\"]))\n", "            elif t == \"analysis\":\n", "                steps_an.append(s)\n", "                if \"attn_entropy_mean\" in e:\n", "                    ent.append(_safe_float(e[\"attn_entropy_mean\"]))\n", "                if \"attn_erank_mean\" in e:\n", "                    erank.append(_safe_float(e[\"attn_erank_mean\"]))\n", "                if \"attn_topk_mass_mean\" in e:\n", "                    topk_mass.append(_safe_float(e[\"attn_topk_mass_mean\"]))\n", "                if \"sem_energy_ratio_mean\" in e:\n", "                    sem_ratio.append(_safe_float(e[\"sem_energy_ratio_mean\"]))\n", "                if \"attn_local_mass_mean\" in e:\n", "                    local_mass.append(_safe_float(e[\"attn_local_mass_mean\"]))\n\n", "    # Make plots\n", "    fig, ax = plt.subplots(3, 2, figsize=(12, 10))\n", "    fig.tight_layout(pad=2.0)\n", "    ax[0, 0].plot(steps_train, loss_train)\n", "    ax[0, 0].set_title(\"Train loss\")\n", "    if steps_eval and loss_val:\n", "        ax[0, 1].plot(steps_eval[:len(loss_val)], loss_val)\n", "        ax[0, 1].set_title(\"Val loss\")\n", "    if tok_s:\n", "        ax[1, 0].plot(range(len(tok_s)), tok_s)\n", "        ax[1, 0].set_title(\"Throughput (tok/s) samples\")\n", "    if steps_an and ent:\n", "        ax[1, 1].plot(steps_an[:len(ent)], ent)\n", "        ax[1, 1].set_title(\"Attention entropy (mean)\")\n", "    if steps_an and erank:\n", "        ax[2, 0].plot(steps_an[:len(erank)], erank)\n", "        ax[2, 0].set_title(\"Attention effective rank (mean)\")\n", "    if steps_an and topk_mass:\n", "        ax[2, 1].plot(steps_an[:len(topk_mass)], topk_mass, label=\"topk mass\")\n", "        if sem_ratio:\n", "            ax[2, 1].plot(steps_an[:len(sem_ratio)], sem_ratio, label=\"semantic energy ratio\")\n", "        if local_mass:\n", "            ax[2, 1].plot(steps_an[:len(local_mass)], local_mass, label=\"local mass\")\n", "        ax[2, 1].set_title(\"Attention diagnostics\")\n", "        ax[2, 1].legend()\n", "    fig.savefig(out_png, dpi=150)\n", "    plt.close(fig)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main() -> None:\n", "    ap = argparse.ArgumentParser()\n\n", "    # ---- Experiment suite controls (new in v27) ----\n", "    ap.add_argument(\"--size\", type=str, default=None, choices=list(SIZE_PRESETS.keys()),\n", "                    help=\"Preset model+train size (tiny/small/medium/large). Applies only when provided.\")\n", "    ap.add_argument(\"--exp\", type=str, default=None,\n", "                    choices=[\"paper_baseline\", \"paper_bottleneck\", \"paper_decoupled\", \"paper_gqa\", \"paper_all\"],\n", "                    help=\"Preset experiment configuration matching the paper suite. Applies only when provided.\")\n", "    ap.add_argument(\"--run-root\", type=str, default=\"runs\", help=\"Root directory for auto run dirs when --out-dir is omitted.\")\n", "    ap.add_argument(\"--run-tag\", type=str, default=None, help=\"Optional suffix for auto run dirs, e.g. 'seed2' -> runs/small_decoupled_seed2\")\n", "    ap.add_argument(\"--print-config\", action=\"store_true\", help=\"Print resolved config (after presets/overrides) and exit.\")\n\n", "    # ---- Core I/O ----\n", "    ap.add_argument(\"--data\", type=str, default=None, help=\"Token dataset path. For train mode only.\")\n", "    ap.add_argument(\"--data-format\", type=str, default=\"auto\", choices=[\"auto\", \"text\", \"npy\", \"bin\", \"pt\"],\n", "                    help=\"Dataset format. 'text' expects whitespace-separated ints. 'npy' uses np.load(mmap). 'bin' uses np.memmap. 'pt' loads a torch tensor.\")\n", "    ap.add_argument(\"--data-dtype\", type=str, default=\"uint16\",\n", "                    help=\"For --data-format bin: numpy dtype (e.g. uint16, uint32, int32).\")\n", "    ap.add_argument(\"--vocab-size\", type=int, default=None,\n", "                    help=\"Explicit vocab size (recommended for binary/mmap datasets). If omitted and tokenizer=tiktoken, defaults to 50257.\")\n", "    ap.add_argument(\"--val-frac\", type=float, default=0.1, help=\"Validation fraction (tail split).\")\n", "    ap.add_argument(\"--out-dir\", type=str, default=None)\n", "    ap.add_argument(\"--seed\", type=int, default=1337)\n", "    ap.add_argument(\"--device\", type=str, default=None)\n\n", "    # ---- Compile / AMP ----\n", "    ap.add_argument(\"--compile\", action=\"store_true\", help=\"Use torch.compile(...) for speed (experimental).\")\n", "    ap.add_argument(\"--compile-mode\", type=str, default=\"default\", choices=[\"default\", \"reduce-overhead\", \"max-autotune\"],\n", "                    help=\"torch.compile mode (if --compile).\")\n", "    ap.add_argument(\"--amp\", action=\"store_true\", help=\"Enable torch.amp autocast (mixed precision) for training on CUDA/MPS/CPU (experimental).\")\n", "    ap.add_argument(\"--amp-dtype\", type=str, default=\"bf16\", choices=[\"bf16\", \"fp16\"],\n", "                    help=\"Autocast compute dtype. bf16 is usually safest; fp16 may require loss scaling.\")\n", "    ap.add_argument(\"--param-dtype\", type=str, default=\"fp32\", choices=[\"fp32\", \"bf16\", \"fp16\"],\n", "                    help=\"Model parameter dtype. fp32 baseline; bf16/fp16 reduce memory ~2x (helpful for bigger models).\")\n", "    ap.add_argument(\"--matmul-precision\", type=str, default=\"high\", choices=[\"highest\", \"high\", \"medium\"],\n", "                    help=\"torch.set_float32_matmul_precision(...) hint for float32 matmuls (may improve speed).\")\n\n", "    # ---- Model ----\n", "    ap.add_argument(\"--layers\", type=int, default=6)\n", "    ap.add_argument(\"--d-model\", type=int, default=512)\n", "    ap.add_argument(\"--n-head\", type=int, default=8)\n", "    ap.add_argument(\"--d-ff\", type=int, default=2048)\n", "    ap.add_argument(\"--block\", type=int, default=256)\n", "    ap.add_argument(\"--embed-dim\", type=int, default=512)\n", "    ap.add_argument(\"--attn-mode\", type=str, default=\"bottleneck\", choices=[\"standard\", \"bottleneck\", \"decoupled\", \"gqa\"])\n", "    ap.add_argument(\"--kv-head\", type=int, default=None, help=\"For --attn-mode gqa: number of KV heads (must divide n_head). Default = n_head\")\n", "    ap.add_argument(\"--attn-dim\", type=int, default=512)\n", "    ap.add_argument(\"--sem-dim\", type=int, default=32)\n", "    ap.add_argument(\"--geo-dim\", type=int, default=64)\n\n", "    # (Decoupled) Per-head sem/geo mixing gate. Enabled by default; disable with --no-decoupled-gate.\n", "    ap.add_argument(\"--no-decoupled-gate\", action=\"store_true\",\n", "                    help=\"Disable the per-head semantic vs geometric mixing gate (decoupled attention).\")\n", "    ap.add_argument(\"--no-rope\", action=\"store_true\")\n", "    ap.add_argument(\"--rope\", action=\"store_true\", help=\"Force-enable RoPE even if a preset would disable it.\")\n", "    ap.add_argument(\"--rope-base\", type=float, default=10000.0)\n", "    ap.add_argument(\"--tie-qk\", action=\"store_true\")\n", "    ap.add_argument(\"--no-tie-qk\", action=\"store_true\", help=\"Force-disable tie_qk (useful for overrides with presets).\")\n", "    ap.add_argument(\"--null-attn\", action=\"store_true\")\n", "    ap.add_argument(\"--no-null-attn\", action=\"store_true\", help=\"Force-disable null_attn (useful for overrides with presets).\")\n", "    ap.add_argument(\"--no-learned-temp\", action=\"store_true\")\n", "    ap.add_argument(\"--mlp\", type=str, default=\"swiglu\", choices=[\"swiglu\", \"gelu\"])\n", "    ap.add_argument(\"--dropout\", type=float, default=0.0)\n\n", "    # ---- Training ----\n", "    ap.add_argument(\"--steps\", type=int, default=6000)\n", "    ap.add_argument(\"--batch-size\", type=int, default=8, help=\"Micro-batch size (per optimizer step if --grad-accum=1).\")\n", "    ap.add_argument(\"--grad-accum\", type=int, default=1, help=\"Gradient accumulation steps (global batch = batch_size * grad_accum).\")\n", "    ap.add_argument(\"--train-seq-len\", type=int, default=0, help=\"Effective sequence length for training batches (0 = use --block).\")\n", "    ap.add_argument(\"--seq-schedule\", type=str, default=None, help=\"Optional seq-len curriculum: 'len@step,len@step,...' e.g. '256@0,512@1000,1024@3000'.\")\n", "    ap.add_argument(\"--eval-seq-len\", type=int, default=0, help=\"Eval sequence length (0 = match training seq-len).\")\n", "    ap.add_argument(\"--grad-checkpoint\", action=\"store_true\", help=\"Enable gradient checkpointing (recompute activations) to save memory.\")\n", "    ap.add_argument(\"--optimizer\", type=str, default=\"adamw\", choices=[\"adamw\", \"lion\"],\n", "                    help=\"Optimizer. lion uses ~1 momentum state (lower memory) and can be faster on big models.\")\n", "    ap.add_argument(\"--adam-betas\", type=str, default=\"0.9,0.95\", help=\"AdamW betas as 'b1,b2'.\")\n", "    ap.add_argument(\"--adam-eps\", type=float, default=1e-8, help=\"AdamW epsilon.\")\n", "    ap.add_argument(\"--lion-betas\", type=str, default=\"0.9,0.99\", help=\"Lion betas as 'b1,b2'.\")\n", "    ap.add_argument(\"--lr\", type=float, default=3e-4)\n", "    ap.add_argument(\"--lr-schedule\", type=str, default=\"constant\", choices=[\"constant\", \"cosine\"],\n", "                    help=\"Learning rate schedule.\")\n", "    ap.add_argument(\"--warmup-steps\", type=int, default=0, help=\"Warmup steps for lr schedule.\")\n", "    ap.add_argument(\"--min-lr\", type=float, default=0.0, help=\"Minimum lr for cosine schedule.\")\n", "    ap.add_argument(\"--opt-foreach\", action=\"store_true\", help=\"Use foreach optimizer implementation when available (can be faster).\")\n", "    ap.add_argument(\"--opt-fused\", action=\"store_true\", help=\"Use fused optimizer implementation when available (CUDA only).\")\n", "    ap.add_argument(\"--weight-decay\", type=float, default=0.1)\n", "    ap.add_argument(\"--grad-clip\", type=float, default=1.0)\n", "    ap.add_argument(\"--save-every\", type=int, default=0, help=\"Checkpoint interval (steps). 0 disables.\")\n", "    ap.add_argument(\"--eval-every\", type=int, default=200)\n", "    ap.add_argument(\"--eval-iters\", type=int, default=20)\n", "    ap.add_argument(\"--log-every\", type=int, default=100, help=\"Train-step logging interval (JSONL + console).\")\n\n", "    # ---- Instrumentation (new in v27) ----\n", "    ap.add_argument(\"--instrument\", type=str, default=\"full\", choices=[\"off\", \"basic\", \"medium\", \"full\"],\n", "                    help=\"off: minimal. basic/medium: JSONL+summary+entropy. full: +HDF5 matrices/SVD + analysis.png\")\n", "    ap.add_argument(\"--analysis-every\", type=int, default=100, help=\"Deep analysis interval. 0 disables.\")\n", "    ap.add_argument(\"--analysis-max-tokens\", type=int, default=256, help=\"Max tokens for attention matrix analysis.\")\n", "    ap.add_argument(\"--analysis-layers\", type=str, default=\"0,-1\", help=\"Comma-separated layer indices to analyze (supports negatives).\")\n", "    ap.add_argument(\"--analysis-heads\", type=str, default=\"0\", help=\"Comma-separated head indices to analyze for SVD/matrix dumps.\")\n", "    ap.add_argument(\"--analysis-topk\", type=int, default=8, help=\"Top-k mass metric for sparsity.\")\n", "    ap.add_argument(\"--analysis-local-window\", type=int, default=32, help=\"Locality window for 'local mass' metric.\")\n", "    ap.add_argument(\"--analysis-save-scores\", action=\"store_true\", help=\"(Decoupled) Save sem/geo score matrices into analysis.h5 (bigger).\")\n", "    ap.add_argument(\"--live\", type=str, default=\"auto\", choices=[\"auto\", \"off\", \"basic\", \"rich\"],\n", "                    help=\"Console live dashboard. 'auto' uses rich if installed + TTY.\")\n", "    ap.add_argument(\"--live-update-every\", type=int, default=1, help=\"Live dashboard refresh interval (optimizer steps).\")\n", "    ap.add_argument(\"--sync-timing\", action=\"store_true\", help=\"Synchronize device before timing/memory reads (more accurate, slightly slower).\")\n", "    ap.add_argument(\"--live-plot\", action=\"store_true\", help=\"Realtime matplotlib plots (dev only).\")\n", "    ap.add_argument(\"--tb\", action=\"store_true\", help=\"Write TensorBoard scalars (requires `tensorboard` package).\")\n\n", "    # ---- Mode ----\n", "    ap.add_argument(\"--mode\", type=str, default=\"train\", choices=[\"train\", \"sample\"])\n", "    ap.add_argument(\"--ckpt\", type=str, default=None)\n\n", "    # ---- Sampling ----\n", "    ap.add_argument(\"--prompt-tokens\", type=str, default=\"0\")\n", "    ap.add_argument(\"--max-new-tokens\", type=int, default=50)\n", "    ap.add_argument(\"--temperature\", type=float, default=1.0)\n", "    ap.add_argument(\"--top-k\", type=int, default=None)\n\n", "    # ---- KV cache / decode (generation) ----\n", "    ap.add_argument(\"--kv-cache\", type=str, default=\"fp16\", choices=[\"fp16\", \"fp32\", \"q8_0\", \"q4_0\", \"nf4\"],\n", "                    help=\"Default KV-cache format (can be overridden per-tensor with the --kv-cache-* flags).\")\n", "    ap.add_argument(\"--kv-qblock\", type=int, default=32, help=\"Quantization block size along the channel dimension.\")\n", "    ap.add_argument(\"--kv-residual\", type=int, default=128,\n", "                    help=\"Keep this many newest KV tokens in fp16 as a hot residual window (only for quantized caches).\")\n", "    ap.add_argument(\"--kv-decode-block\", type=int, default=1024,\n", "                    help=\"Sequence-block size for streaming decode attention (smaller = less memory, more Python overhead).\")\n", "    ap.add_argument(\"--kv-fused\", type=str, default=\"auto\", choices=[\"none\", \"auto\", \"triton1pass\", \"triton2pass\"],\n", "                    help=\"Use fused decode kernels when available. 'auto' picks a sensible kernel when Triton+CUDA are available.\")\n\n", "    # v25 self-optimizer (decode performance)\n", "    ap.add_argument(\"--self-opt\", type=str, default=\"none\", choices=[\"none\", \"startup\", \"online\"],\n", "                    help=\"Self-optimize decode-time knobs (decode_block, fused kernel choice, launch params).\")\n", "    ap.add_argument(\"--self-opt-cache\", type=str, default=None,\n", "                    help=\"JSON path to persist tuned plans across runs (optional).\")\n", "    ap.add_argument(\"--self-opt-decode-blocks\", type=str, default=\"256,512,1024,2048\",\n", "                    help=\"Comma-separated candidate kv_decode_block values for tuning.\")\n", "    ap.add_argument(\"--self-opt-block-n\", type=str, default=\"128\",\n", "                    help=\"Comma-separated BLOCK_N candidates for fused kernels (e.g. '64,128').\")\n", "    ap.add_argument(\"--self-opt-warps\", type=str, default=\"4,8\",\n", "                    help=\"Comma-separated num_warps candidates for fused kernels.\")\n", "    ap.add_argument(\"--self-opt-stages\", type=str, default=\"2,3\",\n", "                    help=\"Comma-separated num_stages candidates for fused kernels.\")\n", "    ap.add_argument(\"--self-opt-warmup\", type=int, default=1,\n", "                    help=\"Warmup iterations per candidate during tuning.\")\n", "    ap.add_argument(\"--self-opt-iters\", type=int, default=3,\n", "                    help=\"Timed iterations per candidate during tuning.\")\n", "    ap.add_argument(\"--self-opt-interval\", type=int, default=256,\n", "                    help=\"Online mode: tune at most once every N decode steps per bucket.\")\n", "    ap.add_argument(\"--self-opt-hysteresis\", type=float, default=0.03,\n", "                    help=\"Online mode: require this relative improvement to switch plans.\")\n", "    ap.add_argument(\"--self-opt-verbose\", action=\"store_true\",\n", "                    help=\"Print tuning decisions + chosen plans.\")\n", "    ap.add_argument(\"--self-opt-verify\", action=\"store_true\",\n", "                    help=\"Verify candidate outputs vs baseline while tuning (slow; debugging).\")\n", "    ap.add_argument(\"--self-opt-verify-tol\", type=float, default=5e-3,\n", "                    help=\"Max abs error allowed for --self-opt-verify (fp32).\")\n\n", "    # v26 cache-policy self-optimizer (kv_residual, quant kind, qblock) \u2014 decoupled only\n", "    ap.add_argument(\"--self-opt-scope\", type=str, default=\"all\", choices=[\"decode\", \"cache\", \"all\"],\n", "                    help=\"Which knobs to self-optimize. 'cache' tunes kv_residual/quant/qblock at startup; 'decode' tunes decode kernels; 'all' does both.\")\n", "    ap.add_argument(\"--self-opt-residuals\", type=str, default=\"0,32,64,128\",\n", "                    help=\"Comma-separated kv_residual candidates for cache-policy tuning.\")\n", "    ap.add_argument(\"--self-opt-qblocks\", type=str, default=\"16,32,64\",\n", "                    help=\"Comma-separated qblock candidates for cache-policy tuning (applied to all quantized decoupled tensors).\")\n", "    ap.add_argument(\"--self-opt-k-sem-kinds\", type=str, default=\"q4_0,nf4,q8_0,fp16\",\n", "                    help=\"Comma-separated semantic-K quantization kinds to consider (decoupled).\")\n", "    ap.add_argument(\"--self-opt-k-geo-kinds\", type=str, default=\"q8_0,q4_0,fp16\",\n", "                    help=\"Comma-separated geometric-K quantization kinds to consider (decoupled).\")\n", "    ap.add_argument(\"--self-opt-v-kinds\", type=str, default=\"q4_0,q8_0,fp16\",\n", "                    help=\"Comma-separated V quantization kinds to consider (decoupled).\")\n", "    ap.add_argument(\"--self-opt-mem-budget-mb\", type=float, default=None,\n", "                    help=\"Absolute memory budget in MB for KV cache-policy tuning (decoupled). If unset, uses baseline*(1+--self-opt-mem-overhead-frac).\")\n", "    ap.add_argument(\"--self-opt-mem-overhead-frac\", type=float, default=0.10,\n", "                    help=\"If --self-opt-mem-budget-mb is unset, allow this fractional overhead over baseline (residual=0).\")\n", "    ap.add_argument(\"--self-opt-policy-prefix-len\", type=int, default=None,\n", "                    help=\"Prefix length to benchmark during cache-policy tuning. If unset, derives from prompt/max_seq.\")\n", "    ap.add_argument(\"--self-opt-policy-warmup\", type=int, default=1,\n", "                    help=\"Warmup iterations for cache-policy microbench.\")\n", "    ap.add_argument(\"--self-opt-policy-iters\", type=int, default=3,\n", "                    help=\"Timed iterations for cache-policy microbench.\")\n", "    ap.add_argument(\"--self-opt-policy-hysteresis\", type=float, default=0.02,\n", "                    help=\"Cache-policy hillclimb: require this relative improvement to accept a move.\")\n", "    ap.add_argument(\"--self-opt-prefer-low-mem-within\", type=float, default=0.02,\n", "                    help=\"Cache-policy tie-break: if speed is within this fraction, prefer lower memory.\")\n", "    ap.add_argument(\"--self-opt-policy-quality\", action=\"store_true\",\n", "                    help=\"(Slow) After choosing a cache policy, run a small teacher-forced logits check vs fp16-cache baseline.\")\n", "    ap.add_argument(\"--self-opt-calib-tokens\", type=str, default=None,\n", "                    help=\"Calibration tokens for --self-opt-policy-quality (either a path to .txt/.npy or whitespace-separated ints). Defaults to --prompt-tokens.\")\n", "    ap.add_argument(\"--self-opt-calib-prefill\", type=int, default=128,\n", "                    help=\"Prefill length for policy quality check.\")\n", "    ap.add_argument(\"--self-opt-calib-decode\", type=int, default=32,\n", "                    help=\"Number of teacher-forced decode steps for policy quality check.\")\n", "    ap.add_argument(\"--self-opt-quality-tol\", type=float, default=0.5,\n", "                    help=\"Max abs logit error allowed for policy quality check.\")\n", "    ap.add_argument(\"--self-opt-quality-delta-nll-tol\", type=float, default=0.02,\n", "                    help=\"Quality gate: max allowed \u0394NLL (nats/token) vs fp16 baseline on calibration tokens. Default 0.02 (~2%% ppl hit).\")\n", "    ap.add_argument(\"--self-opt-quality-ppl-ratio-tol\", type=float, default=1.02,\n", "                    help=\"Quality gate: max allowed ppl_cand/ppl_base on calibration tokens. Default 1.02 (~2%% ppl hit).\")\n", "    ap.add_argument(\"--self-opt-quality-kl-tol\", type=float, default=None,\n", "                    help=\"Optional quality gate: max allowed KL(p_base||p_cand) in nats/token on calibration tokens.\")\n", "    ap.add_argument(\"--self-opt-quality-kl\", action=\"store_true\",\n", "                    help=\"Compute and print KL(p_base||p_cand) even if --self-opt-quality-kl-tol is unset (slow).\")\n", "    ap.add_argument(\"--kv-cache-k\", type=str, default=None, choices=[\"fp16\", \"fp32\", \"q8_0\", \"q4_0\", \"nf4\"],\n", "                    help=\"Override K cache kind (standard/bottleneck/gqa).\")\n", "    ap.add_argument(\"--kv-cache-v\", type=str, default=None, choices=[\"fp16\", \"fp32\", \"q8_0\", \"q4_0\", \"nf4\"],\n", "                    help=\"Override V cache kind (standard/bottleneck/gqa and decoupled).\")\n", "    ap.add_argument(\"--kv-cache-k-sem\", type=str, default=None, choices=[\"fp16\", \"fp32\", \"q8_0\", \"q4_0\", \"nf4\"],\n", "                    help=\"Override semantic K cache kind (decoupled only).\")\n", "    ap.add_argument(\"--kv-cache-k-geo\", type=str, default=None, choices=[\"fp16\", \"fp32\", \"q8_0\", \"q4_0\", \"nf4\"],\n", "                    help=\"Override geometric K cache kind (decoupled only).\")\n", "    ap.add_argument(\"--kv-qblock-k\", type=int, default=None, help=\"Override K qblock (standard/bottleneck/gqa).\")\n", "    ap.add_argument(\"--kv-qblock-v\", type=int, default=None, help=\"Override V qblock.\")\n", "    ap.add_argument(\"--kv-qblock-k-sem\", type=int, default=None, help=\"Override semantic K qblock.\")\n", "    ap.add_argument(\"--kv-qblock-k-geo\", type=int, default=None, help=\"Override geometric K qblock.\")\n\n", "    # Tokenizer\n", "    ap.add_argument(\"--tokenizer\", type=str, default=\"word\", choices=[\"word\", \"tiktoken\"])\n", "    args = ap.parse_args()\n\n", "    # Apply paper suite presets (only when provided)\n", "    apply_size_preset(args)\n", "    apply_exp_preset(args)\n\n", "    # Explicit \"force disable\" flags (useful because store_true args can't be negated otherwise)\n", "    if args.no_null_attn:\n", "        args.null_attn = False\n", "    if args.no_tie_qk:\n", "        args.tie_qk = False\n", "    if args.rope:\n", "        args.no_rope = False\n\n", "    # Derive out_dir if omitted and size+exp provided\n", "    inferred = default_out_dir(args)\n", "    if args.out_dir is None and inferred is not None:\n", "        args.out_dir = inferred\n", "    device = pick_device(args.device)\n", "    set_seed(args.seed)\n\n", "    # Matmul precision hint (mostly impacts float32 matmuls).\n", "    try:\n", "        if hasattr(torch, \"set_float32_matmul_precision\"):\n", "            torch.set_float32_matmul_precision(str(args.matmul_precision))\n", "    except Exception:\n", "        pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # For paper_all, run each experiment sequentially (train mode only).\n", "    if args.mode == \"train\" and args.exp == \"paper_all\":\n", "        for exp in [\"paper_baseline\", \"paper_bottleneck\", \"paper_decoupled\", \"paper_gqa\"]:\n", "            import copy\n", "            a2 = copy.deepcopy(args)\n", "            a2.exp = exp\n", "            apply_exp_preset(a2)\n", "            if a2.no_null_attn:\n", "                a2.null_attn = False\n", "            if a2.no_tie_qk:\n", "                a2.tie_qk = False\n", "            if a2.rope:\n", "                a2.no_rope = False\n", "            inferred2 = default_out_dir(a2)\n", "            if inferred2 is not None:\n", "                a2.out_dir = inferred2\n", "            _run_single(a2, device)\n", "        return\n", "    _run_single(args, device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _run_single(args: argparse.Namespace, device: torch.device) -> None:\n", "    # -------------------------\n", "    # Sample mode (no dataset needed): build model from checkpoint config\n", "    # -------------------------\n", "    if args.mode == \"sample\":\n", "        if not args.ckpt:\n", "            raise ValueError(\"--ckpt is required for --mode sample\")\n", "        ckpt = torch.load(args.ckpt, map_location=device)\n", "        cfg_dict = ckpt.get(\"config\", None)\n", "        if cfg_dict is None:\n", "            raise ValueError(\"Checkpoint missing 'config'. Can't reconstruct model safely.\")\n", "        cfg = ModelConfig(**cfg_dict)\n", "        model = GPT(cfg).to(device)\n", "        # Backwards-compatible load: allow missing decoupled_gate_logit (neutral init) when loading older checkpoints.\n", "        incompatible = model.load_state_dict(ckpt[\"model\"], strict=False)\n", "        bad_missing = [k for k in incompatible.missing_keys if \"decoupled_gate_logit\" not in k]\n", "        bad_unexpected = [k for k in incompatible.unexpected_keys if \"decoupled_gate_logit\" not in k]\n", "        if bad_missing or bad_unexpected:\n", "            # Re-run strict to raise a helpful error.\n", "            model.load_state_dict(ckpt[\"model\"], strict=True)\n", "        if incompatible.missing_keys or incompatible.unexpected_keys:\n", "            print(f\"[warn] Non-strict checkpoint load. Missing={incompatible.missing_keys} Unexpected={incompatible.unexpected_keys}\")\n", "        model.eval()\n\n", "        # Prompt: either raw token IDs or text (tiktoken only)\n", "        try:\n", "            prompt_ids = [int(t) for t in args.prompt_tokens.strip().split()]\n", "        except ValueError:\n", "            if args.tokenizer != \"tiktoken\":\n", "                raise ValueError(\"Text prompts require --tokenizer tiktoken\")\n", "            if tiktoken is None:\n", "                raise ImportError(\"tiktoken needed for text prompts\")\n", "            enc = tiktoken.get_encoding(\"gpt2\")\n", "            prompt_ids = enc.encode_ordinary(args.prompt_tokens)\n", "        prompt = torch.tensor([prompt_ids], device=device, dtype=torch.long)\n\n", "        # Self-opt config (decode + cache policy)\n", "        def _csv_ints(s: Optional[str]) -> Tuple[int, ...]:\n", "            if s is None:\n", "                return ()\n", "            parts: List[int] = []\n", "            for x in str(s).split(\",\"):\n", "                x = x.strip()\n", "                if not x:\n", "                    continue\n", "                try:\n", "                    parts.append(int(x))\n", "                except Exception:\n", "                    pass\n", "            return tuple(parts)\n", "        def _csv_strs(s: Optional[str]) -> Tuple[str, ...]:\n", "            if s is None:\n", "                return ()\n", "            parts: List[str] = []\n", "            for x in str(s).split(\",\"):\n", "                x = x.strip()\n", "                if x:\n", "                    parts.append(x)\n", "            return tuple(parts)\n", "        self_opt_cfg = None\n", "        if getattr(args, \"self_opt\", \"none\") != \"none\":\n", "            self_opt_cfg = KVSelfOptConfig(\n", "                mode=args.self_opt,\n", "                scope=getattr(args, \"self_opt_scope\", \"all\"),\n", "                decode_blocks=_csv_ints(getattr(args, \"self_opt_decode_blocks\", \"\")) or (256, 512, 1024, 2048),\n", "                block_ns=_csv_ints(getattr(args, \"self_opt_block_n\", \"\")) or (128,),\n", "                warps=_csv_ints(getattr(args, \"self_opt_warps\", \"\")) or (4, 8),\n", "                stages=_csv_ints(getattr(args, \"self_opt_stages\", \"\")) or (2, 3),\n", "                warmup=int(getattr(args, \"self_opt_warmup\", 1)),\n", "                iters=int(getattr(args, \"self_opt_iters\", 3)),\n", "                interval=int(getattr(args, \"self_opt_interval\", 256)),\n", "                hysteresis=float(getattr(args, \"self_opt_hysteresis\", 0.03)),\n", "                cache_path=getattr(args, \"self_opt_cache\", None),\n", "                verbose=bool(getattr(args, \"self_opt_verbose\", False)),\n", "                verify=bool(getattr(args, \"self_opt_verify\", False)),\n", "                verify_tol=float(getattr(args, \"self_opt_verify_tol\", 5e-3)),\n", "                residuals=_csv_ints(getattr(args, \"self_opt_residuals\", \"\")) or (0, 32, 64, 128),\n", "                qblocks=_csv_ints(getattr(args, \"self_opt_qblocks\", \"\")) or (16, 32, 64),\n", "                k_sem_kinds=_csv_strs(getattr(args, \"self_opt_k_sem_kinds\", \"\")) or (\"q4_0\", \"nf4\", \"q8_0\", \"fp16\"),\n", "                k_geo_kinds=_csv_strs(getattr(args, \"self_opt_k_geo_kinds\", \"\")) or (\"q8_0\", \"q4_0\", \"fp16\"),\n", "                v_kinds=_csv_strs(getattr(args, \"self_opt_v_kinds\", \"\")) or (\"q4_0\", \"q8_0\", \"fp16\"),\n", "                mem_budget_mb=getattr(args, \"self_opt_mem_budget_mb\", None),\n", "                mem_overhead_frac=float(getattr(args, \"self_opt_mem_overhead_frac\", 0.10)),\n", "                policy_prefix_len=getattr(args, \"self_opt_policy_prefix_len\", None),\n", "                policy_warmup=int(getattr(args, \"self_opt_policy_warmup\", 1)),\n", "                policy_iters=int(getattr(args, \"self_opt_policy_iters\", 3)),\n", "                policy_hysteresis=float(getattr(args, \"self_opt_policy_hysteresis\", 0.02)),\n", "                prefer_lower_mem_within=float(getattr(args, \"self_opt_prefer_low_mem_within\", 0.02)),\n", "                policy_quality=bool(getattr(args, \"self_opt_policy_quality\", False)),\n", "                calib_tokens=getattr(args, \"self_opt_calib_tokens\", None),\n", "                calib_prefill=int(getattr(args, \"self_opt_calib_prefill\", 64)),\n", "                calib_decode_steps=int(getattr(args, \"self_opt_calib_decode\", 8)),\n", "                quality_tol=float(getattr(args, \"self_opt_quality_tol\", 0.5)),\n", "                quality_delta_nll_tol=getattr(args, \"self_opt_quality_delta_nll_tol\", None),\n", "                quality_ppl_ratio_tol=getattr(args, \"self_opt_quality_ppl_ratio_tol\", None),\n", "                quality_kl_tol=getattr(args, \"self_opt_quality_kl_tol\", None),\n", "                quality_compute_kl=bool(getattr(args, \"self_opt_quality_kl\", False)),\n", "            )\n\n", "        # Logger for sampling (enable if --instrument/--live-plot/--tb used)\n", "        logger = None\n", "        if args.instrument != \"off\" or args.live_plot or args.tb:\n", "            logger = RunLogger(\n", "                args.out_dir, \n", "                instrument=args.instrument, \n", "                cfg=cfg, \n", "                args=args, \n", "                device=device,\n", "                live_plot=bool(args.live_plot), \n", "                tb=bool(args.tb)\n", "            )\n", "        print(f\"Generating {args.max_new_tokens} tokens...\")\n", "        t0 = time.time()\n", "        try:\n", "            out = model.generate(\n", "                prompt,\n", "                max_new_tokens=args.max_new_tokens,\n", "                temperature=args.temperature,\n", "                top_k=args.top_k,\n", "                kv_cache=args.kv_cache,\n", "                kv_qblock=args.kv_qblock,\n", "                kv_residual=args.kv_residual,\n", "                kv_decode_block=args.kv_decode_block,\n", "                kv_fused=args.kv_fused,\n", "                self_opt=self_opt_cfg,\n", "                kv_cache_k=args.kv_cache_k,\n", "                kv_cache_v=args.kv_cache_v,\n", "                kv_cache_k_sem=args.kv_cache_k_sem,\n", "                kv_cache_k_geo=args.kv_cache_k_geo,\n", "                kv_qblock_k=args.kv_qblock_k,\n", "                kv_qblock_v=args.kv_qblock_v,\n", "                kv_qblock_k_sem=args.kv_qblock_k_sem,\n", "                kv_qblock_k_geo=args.kv_qblock_k_geo,\n", "                log_callback=logger.log if logger else None,\n", "            )\n", "        finally:\n", "            if logger:\n", "                logger.close()\n", "        dt = time.time() - t0\n", "        print(f\"Time: {dt:.2f}s | Tok/s: {args.max_new_tokens/max(dt,1e-9):.2f}\")\n", "        out_ids = out[0].tolist()\n", "        if args.tokenizer == \"tiktoken\":\n", "            enc = tiktoken.get_encoding(\"gpt2\")\n", "            print(enc.decode(out_ids))\n", "        else:\n", "            print(out_ids)\n", "        return\n\n", "    # -------------------------\n", "    # Train mode\n", "    # -------------------------\n", "    if args.data is None:\n", "        raise ValueError(\"--data is required for --mode train\")\n", "    if args.out_dir is None:\n", "        raise ValueError(\"--out-dir is required for --mode train (or provide --size + --exp for auto dirs).\")\n\n", "    # ---- Load dataset (scale-aware) ----\n", "    if _np is None:\n", "        raise ImportError(\"numpy is required for training data loading in v27\")\n", "    data_path = Path(args.data)\n", "    fmt = str(args.data_format)\n", "    if fmt == \"auto\":\n", "        suf = data_path.suffix.lower()\n", "        if suf == \".npy\":\n", "            fmt = \"npy\"\n", "        elif suf == \".bin\":\n", "            fmt = \"bin\"\n", "        elif suf == \".pt\":\n", "            fmt = \"pt\"\n", "        else:\n", "            fmt = \"text\"\n", "    tokens_any: Any\n", "    if fmt == \"text\":\n", "        # Fast-ish text parsing via numpy (still RAM heavy; use .npy/.bin for real scale)\n", "        raw = data_path.read_text(encoding=\"utf-8\")\n", "        arr = _np.fromstring(raw.strip(), dtype=_np.int64, sep=\" \")\n", "        tokens_any = arr\n", "    elif fmt == \"npy\":\n", "        arr = _np.load(str(data_path), mmap_mode=\"r\")\n", "        if arr.ndim != 1:\n", "            arr = arr.reshape(-1)\n", "        tokens_any = arr\n", "    elif fmt == \"bin\":\n", "        dt = _np.dtype(str(args.data_dtype))\n", "        arr = _np.memmap(str(data_path), dtype=dt, mode=\"r\")\n", "        if arr.ndim != 1:\n", "            arr = arr.reshape(-1)\n", "        tokens_any = arr\n", "    elif fmt == \"pt\":\n", "        t = torch.load(str(data_path), map_location=\"cpu\")\n", "        if isinstance(t, dict) and \"tokens\" in t:\n", "            t = t[\"tokens\"]\n", "        if not isinstance(t, torch.Tensor):\n", "            raise ValueError(\"pt data must be a 1D torch.Tensor or dict with 'tokens'\")\n", "        t = t.view(-1).to(torch.long)\n", "        tokens_any = t\n", "    else:\n", "        raise ValueError(f\"Unknown data format: {fmt}\")\n", "    n_total = int(tokens_any.numel()) if isinstance(tokens_any, torch.Tensor) else int(len(tokens_any))\n", "    if n_total < int(args.block) + 2:\n", "        raise ValueError(f\"Dataset too small: n_tokens={n_total} block={args.block}\")\n", "    n_train = int((1.0 - float(args.val_frac)) * n_total)\n", "    n_train = max(min(n_train, n_total - 2), 2)\n", "    n_val = n_total - n_train\n", "    class TokenView:\n", "        def __init__(self, data: Any, start: int, end: int):\n", "            self.data = data\n", "            self.start = int(start)\n", "            self.end = int(end)\n", "        def __len__(self) -> int:\n", "            return int(self.end - self.start)\n", "    train_view = TokenView(tokens_any, 0, n_train)\n", "    val_view = TokenView(tokens_any, n_train, n_total)\n\n", "    # Determine vocab size\n", "    if args.vocab_size is not None:\n", "        vocab = int(args.vocab_size)\n", "    elif args.tokenizer == \"tiktoken\":\n", "        vocab = 50257\n", "    else:\n", "        # For text (or small tensors), we can compute max+1\n", "        if isinstance(tokens_any, torch.Tensor):\n", "            vocab = int(tokens_any.max().item()) + 1\n", "        else:\n", "            # Computing max over a huge memmap is expensive; warn loudly.\n", "            print(\"[warn] --vocab-size not provided; scanning dataset for max token id (can be very slow on big memmaps).\")\n", "            vocab = int(_np.max(tokens_any)) + 1  # type: ignore\n\n", "    # ---- Config ----\n", "    cfg = ModelConfig(\n", "        vocab_size=int(vocab),\n", "        block_size=int(args.block),\n", "        n_layer=int(args.layers),\n", "        n_head=int(args.n_head),\n", "        kv_head=args.kv_head,\n", "        d_model=int(args.d_model),\n", "        d_ff=int(args.d_ff),\n", "        embed_dim=int(args.embed_dim),\n", "        attn_mode=str(args.attn_mode),\n", "        attn_dim=int(args.attn_dim),\n", "        sem_dim=int(args.sem_dim),\n", "        geo_dim=int(args.geo_dim),\n", "        decoupled_gate=(not args.no_decoupled_gate),\n", "        rope=(not args.no_rope),\n", "        rope_base=float(args.rope_base),\n", "        tie_qk=bool(args.tie_qk),\n", "        null_attn=bool(args.null_attn),\n", "        learned_temp=(not args.no_learned_temp),\n", "        mlp=str(args.mlp),\n", "        dropout=float(args.dropout),\n", "    )\n\n", "    # Print config & exit (handy for make print_config)\n", "    if args.print_config:\n", "        print(json.dumps(asdict(cfg), indent=2, sort_keys=True))\n", "        try:\n", "            mem_ctx = estimate_kv_cache_bytes(cfg, seq_len=cfg.block_size, batch=1,\n", "                                             kv_cache=args.kv_cache, kv_qblock=args.kv_qblock, kv_residual=args.kv_residual,\n", "                                             kv_cache_k=args.kv_cache_k, kv_cache_v=args.kv_cache_v,\n", "                                             kv_cache_k_sem=args.kv_cache_k_sem, kv_cache_k_geo=args.kv_cache_k_geo,\n", "                                             kv_qblock_k=args.kv_qblock_k, kv_qblock_v=args.kv_qblock_v,\n", "                                             kv_qblock_k_sem=args.kv_qblock_k_sem, kv_qblock_k_geo=args.kv_qblock_k_geo)\n", "            mem_128 = estimate_kv_cache_bytes(cfg, seq_len=128_000, batch=1,\n", "                                             kv_cache=args.kv_cache, kv_qblock=args.kv_qblock, kv_residual=args.kv_residual,\n", "                                             kv_cache_k=args.kv_cache_k, kv_cache_v=args.kv_cache_v,\n", "                                             kv_cache_k_sem=args.kv_cache_k_sem, kv_cache_k_geo=args.kv_cache_k_geo,\n", "                                             kv_qblock_k=args.kv_qblock_k, kv_qblock_v=args.kv_qblock_v,\n", "                                             kv_qblock_k_sem=args.kv_qblock_k_sem, kv_qblock_k_geo=args.kv_qblock_k_geo)\n", "            print(f\"KV cache @ ctx={cfg.block_size}: {human_bytes(mem_ctx['total_bytes'])}\")\n", "            print(f\"KV cache @ 128k: {human_bytes(mem_128['total_bytes'])}\")\n", "        except Exception as e:\n", "            print(f\"[warn] KV memory estimate failed: {e}\")\n", "        return\n", "    model = GPT(cfg).to(device)\n\n", "    # Parameter dtype (memory / speed). fp32 is default; bf16/fp16 cut memory ~2x.\n", "    param_dtype = resolve_dtype(device, args.param_dtype, default=torch.float32)\n", "    if param_dtype != torch.float32:\n", "        model = model.to(dtype=param_dtype)\n\n", "    # Training-only toggle: gradient checkpointing (activation recompute).\n", "    try:\n", "        model.grad_checkpointing = bool(args.grad_checkpoint)\n", "    except Exception:\n", "        pass\n", "    if args.compile and hasattr(torch, \"compile\"):\n", "        try:\n", "            model = torch.compile(model, mode=args.compile_mode)\n", "            print(f\"torch.compile enabled (mode={args.compile_mode}).\")\n", "        except Exception as e:\n", "            print(f\"torch.compile failed, continuing without it: {e}\")\n\n", "    # Ensure training-only flags survive compile wrappers.\n", "    try:\n", "        model.grad_checkpointing = bool(args.grad_checkpoint)\n", "    except Exception:\n", "        pass\n\n", "    # ---- Batch sampling for both torch tensors and numpy memmaps ----\n", "    _offs_cache_t: Dict[int, torch.Tensor] = {}\n", "    _offs_cache_np: Dict[int, _np.ndarray] = {}\n", "    def get_batch_any(view: TokenView, batch_size: int, block_size: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:\n", "        max_start = len(view) - block_size - 1\n", "        if max_start <= 0:\n", "            raise ValueError(f\"Not enough tokens in split: len={len(view)} block={block_size}\")\n\n", "        # Offsets cache (avoid realloc every batch)\n", "        offs_t = _offs_cache_t.get(block_size)\n", "        if offs_t is None or offs_t.numel() != block_size:\n", "            offs_t = torch.arange(block_size, dtype=torch.long)\n", "            _offs_cache_t[block_size] = offs_t\n", "        ix = torch.randint(0, max_start, (batch_size,), device=\"cpu\", dtype=torch.long)\n", "        if isinstance(view.data, torch.Tensor):\n", "            # Vectorized gather from a 1D CPU tensor\n", "            base = (view.start + ix).unsqueeze(1)  # (B,1)\n", "            idx = base + offs_t.unsqueeze(0)       # (B,T)\n", "            x = view.data[idx]\n", "            y = view.data[idx + 1]\n", "            return x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n\n", "        # numpy array / memmap path (vectorized)\n", "        offs_np = _offs_cache_np.get(block_size)\n", "        if offs_np is None or offs_np.shape[0] != block_size:\n", "            offs_np = _np.arange(block_size, dtype=_np.int64)\n", "            _offs_cache_np[block_size] = offs_np\n", "        ix_np = ix.numpy().astype(_np.int64, copy=False)\n", "        idx_np = (view.start + ix_np[:, None] + offs_np[None, :]).astype(_np.int64, copy=False)\n", "        x_np = _np.asarray(view.data[idx_np], dtype=_np.int64)\n", "        y_np = _np.asarray(view.data[idx_np + 1], dtype=_np.int64)\n", "        x = torch.from_numpy(x_np)\n", "        y = torch.from_numpy(y_np)\n", "        return x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n", "    @torch.no_grad()\n", "    def estimate_loss_any(eval_iters: int, block_size: int) -> Tuple[float, float]:\n", "        \"\"\"Return (train_loss, val_loss) using random batches.\"\"\"\n", "        model.eval()\n", "        iters = int(eval_iters)\n", "        bs = int(block_size)\n", "        def _split_loss(view: TokenView) -> float:\n", "            losses: List[float] = []\n", "            for _ in range(iters):\n", "                xb, yb = get_batch_any(view, batch_size=args.batch_size, block_size=bs, device=device)\n", "                with autocast_ctx:\n", "                    logits, _ = model(xb)\n", "                    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), yb.reshape(-1))\n", "                losses.append(float(loss.detach().to(\"cpu\").item()))\n", "            return float(sum(losses) / max(1, len(losses)))\n", "        tr = _split_loss(train_view)\n", "        va = _split_loss(val_view)\n", "        model.train()\n", "        return tr, va"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # Logger (instrumentation)\n", "    logger = RunLogger(args.out_dir, instrument=args.instrument, cfg=cfg, args=args, device=device,\n", "                       live_plot=bool(args.live_plot), tb=bool(args.tb)) if args.instrument != \"off\" else None\n\n", "    # Log KV cache memory probes up front\n", "    if logger is not None:\n", "        try:\n", "            mem_ctx = estimate_kv_cache_bytes(cfg, seq_len=cfg.block_size, batch=1,\n", "                                             kv_cache=args.kv_cache, kv_qblock=args.kv_qblock, kv_residual=args.kv_residual,\n", "                                             kv_cache_k=args.kv_cache_k, kv_cache_v=args.kv_cache_v,\n", "                                             kv_cache_k_sem=args.kv_cache_k_sem, kv_cache_k_geo=args.kv_cache_k_geo,\n", "                                             kv_qblock_k=args.kv_qblock_k, kv_qblock_v=args.kv_qblock_v,\n", "                                             kv_qblock_k_sem=args.kv_qblock_k_sem, kv_qblock_k_geo=args.kv_qblock_k_geo)\n", "            mem_128 = estimate_kv_cache_bytes(cfg, seq_len=128_000, batch=1,\n", "                                             kv_cache=args.kv_cache, kv_qblock=args.kv_qblock, kv_residual=args.kv_residual,\n", "                                             kv_cache_k=args.kv_cache_k, kv_cache_v=args.kv_cache_v,\n", "                                             kv_cache_k_sem=args.kv_cache_k_sem, kv_cache_k_geo=args.kv_cache_k_geo,\n", "                                             kv_qblock_k=args.kv_qblock_k, kv_qblock_v=args.kv_qblock_v,\n", "                                             kv_qblock_k_sem=args.kv_qblock_k_sem, kv_qblock_k_geo=args.kv_qblock_k_geo)\n", "            logger.log({\"type\": \"mem\", \"step\": 0,\n", "                        \"kv_ctx_bytes\": int(mem_ctx[\"total_bytes\"]),\n", "                        \"kv_128k_bytes\": int(mem_128[\"total_bytes\"]),\n", "                        \"data_format\": fmt,\n", "                        \"data_dtype\": str(args.data_dtype),\n", "                        \"n_tokens_total\": int(n_total),\n", "                        \"n_tokens_train\": int(n_train),\n", "                        \"n_tokens_val\": int(n_val),\n", "                        \"vocab_size\": int(vocab)})\n", "        except Exception as e:\n", "            logger.log({\"type\": \"mem\", \"step\": 0, \"error\": str(e)})\n\n", "    # -----------------------------\n", "    # Optimizer / AMP / schedules\n", "    # -----------------------------\n", "    grad_accum = max(1, int(args.grad_accum))\n", "    global_batch = int(args.batch_size) * grad_accum\n\n", "    # Sequence length curriculum (optional)\n", "    seq_schedule = parse_seq_schedule(args.seq_schedule)\n", "    base_seq_len = int(args.train_seq_len) if int(args.train_seq_len) > 0 else int(cfg.block_size)\n", "    base_seq_len = min(base_seq_len, int(cfg.block_size))\n", "    fixed_eval_seq_len = int(args.eval_seq_len) if int(args.eval_seq_len) > 0 else 0\n\n", "    # Optimizer\n", "    if str(args.optimizer).lower() == \"lion\":\n", "        lion_betas = _parse_two_floats(args.lion_betas, default=(0.9, 0.99))\n", "        opt = Lion(model.parameters(), lr=args.lr, betas=lion_betas, weight_decay=args.weight_decay)\n", "    else:\n", "        adam_betas = _parse_two_floats(args.adam_betas, default=(0.9, 0.95))\n", "        opt_kwargs: Dict[str, Any] = dict(lr=args.lr, weight_decay=args.weight_decay, betas=adam_betas, eps=float(args.adam_eps))\n", "        if bool(args.opt_foreach):\n", "            opt_kwargs[\"foreach\"] = True\n", "        if bool(args.opt_fused) and device.type == \"cuda\":\n", "            opt_kwargs[\"fused\"] = True\n", "        try:\n", "            opt = torch.optim.AdamW(model.parameters(), **opt_kwargs)\n", "        except TypeError:\n", "            # Older torch: drop unsupported keys\n", "            opt_kwargs.pop(\"foreach\", None)\n", "            opt_kwargs.pop(\"fused\", None)\n", "            opt = torch.optim.AdamW(model.parameters(), **opt_kwargs)\n\n", "    # AMP (torch.amp for CUDA/MPS/CPU)\n", "    amp_enabled = bool(args.amp)\n", "    try:\n", "        if hasattr(torch, \"amp\") and hasattr(torch.amp, \"is_autocast_available\"):\n", "            amp_enabled = amp_enabled and bool(torch.amp.is_autocast_available(device.type))\n", "    except Exception:\n", "        amp_enabled = False\n", "    amp_dtype = resolve_dtype(device, args.amp_dtype, default=torch.bfloat16)\n", "    autocast_ctx = contextlib.nullcontext()\n", "    scaler = None\n", "    try:\n", "        if amp_enabled and hasattr(torch, \"amp\") and hasattr(torch.amp, \"autocast\"):\n", "            autocast_ctx = torch.amp.autocast(device_type=device.type, dtype=amp_dtype, enabled=True)\n", "        if hasattr(torch, \"amp\") and hasattr(torch.amp, \"GradScaler\"):\n", "            scaler = torch.amp.GradScaler(device=device.type, enabled=(amp_enabled and amp_dtype == torch.float16))\n", "    except Exception:\n", "        autocast_ctx = contextlib.nullcontext()\n", "        scaler = None\n\n", "    # analysis layers/heads parsing\n", "    def _parse_csv_int_list(s: str) -> List[int]:\n", "        s = s.strip()\n", "        if not s:\n", "            return []\n", "        out: List[int] = []\n", "        for part in s.split(\",\"):\n", "            part = part.strip()\n", "            if part == \"\":\n", "                continue\n", "            try:\n", "                out.append(int(part))\n", "            except Exception:\n", "                pass\n", "        return out\n", "    analysis_layers = _parse_csv_int_list(getattr(args, \"analysis_layers\", \"\")) or [0]\n", "    analysis_heads = _parse_csv_int_list(getattr(args, \"analysis_heads\", \"\")) or [0]\n", "    analysis_tokens = max(2, int(getattr(args, \"analysis_max_tokens\", 256)))\n\n", "    # Console live dashboard\n", "    dashboard = LiveDashboard(args.live, total_steps=args.steps, out_dir=args.out_dir, cfg=cfg, args=args, device=device)\n", "    dash_every = max(1, int(getattr(args, \"live_update_every\", 1)))\n\n", "    # One-time run summary for the live console.\n", "    try:\n", "        n_params = sum(p.numel() for p in model.parameters())\n", "        dashboard.message(\n", "            f\"run: params={n_params/1e6:.2f}M | opt={args.optimizer} | gbs={global_batch} \"\n", "            f\"| param_dtype={str(param_dtype).replace('torch.', '')} | amp={amp_enabled} \"\n", "            f\"| amp_dtype={str(amp_dtype).replace('torch.', '')} | grad_ckpt={bool(args.grad_checkpoint)}\"\n", "        )\n", "    except Exception:\n", "        pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    best_val = float(\"inf\")\n\n", "    # Interval accumulators for stable perf readouts\n", "    tok_count = 0\n", "    dt_acc = 0.0\n", "    data_acc = 0.0\n", "    fwd_acc = 0.0\n", "    bwd_acc = 0.0\n", "    opt_acc = 0.0\n", "    steps_in_acc = 0\n\n", "    # A one-time expensive measurement after optimizer state materializes\n", "    opt_state_bytes_cached: Optional[int] = None\n", "    def maybe_sync() -> None:\n", "        if bool(getattr(args, \"sync_timing\", False)):\n", "            device_synchronize(device)\n", "    @torch.no_grad()\n", "    def do_eval(step: int, *, seq_len_hint: int) -> Dict[str, float]:\n", "        model.eval()\n", "        eval_seq = fixed_eval_seq_len if fixed_eval_seq_len > 0 else seq_len_hint\n", "        eval_seq = int(min(max(2, eval_seq), cfg.block_size))\n", "        tr_loss, va_loss = estimate_loss_any(eval_iters=args.eval_iters, block_size=eval_seq)\n", "        val_loss = float(va_loss)\n", "        out = {\n", "            \"type\": \"eval\",\n", "            \"step\": int(step),\n", "            \"train_loss\": float(tr_loss),\n", "            \"val_loss\": val_loss,\n", "            \"val_ppl\": float(math.exp(val_loss)),\n", "        }\n", "        return out\n", "    try:\n", "        # Baseline eval at step 0\n", "        eval0 = do_eval(0, seq_len_hint=base_seq_len)\n", "        best_val = min(best_val, eval0[\"val_loss\"])\n", "        eval0[\"best_val\"] = best_val\n", "        if logger is not None:\n", "            logger.log(eval0)\n", "        dashboard.update_eval(eval0)\n", "        dashboard.message(f\"eval@0: val_loss={eval0['val_loss']:.6f} val_ppl={eval0['val_ppl']:.2f}\")\n", "        for step in range(1, args.steps + 1):\n", "            step_idx = step - 1\n\n", "            # LR schedule\n", "            lr = lr_for_step(\n", "                step_idx,\n", "                base_lr=float(args.lr),\n", "                total_steps=int(args.steps),\n", "                schedule=str(args.lr_schedule),\n", "                warmup_steps=int(args.warmup_steps),\n", "                min_lr=float(args.min_lr),\n", "            )\n", "            for pg in opt.param_groups:\n", "                pg[\"lr\"] = lr\n\n", "            # Current training seq-len (curriculum)\n", "            seq_len = seq_len_for_step(step_idx, default_seq_len=base_seq_len, schedule=seq_schedule)\n", "            seq_len = int(min(max(2, seq_len), cfg.block_size))\n", "            model.train()\n", "            opt.zero_grad(set_to_none=True)\n\n", "            # Timers (optionally synchronized)\n", "            maybe_sync()\n", "            t_step0 = time.perf_counter()\n", "            loss_sum_t: Optional[torch.Tensor] = None\n", "            data_t = 0.0\n", "            fwd_t = 0.0\n", "            bwd_t = 0.0\n", "            for micro in range(grad_accum):\n", "                t0 = time.perf_counter()\n", "                xb, yb = get_batch_any(train_view, batch_size=args.batch_size, block_size=seq_len, device=device)\n", "                maybe_sync()\n", "                data_t += time.perf_counter() - t0\n", "                with autocast_ctx:\n", "                    t1 = time.perf_counter()\n", "                    logits, _ = model(xb)\n", "                    # mean loss per-token\n", "                    loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), yb.reshape(-1))\n", "                    maybe_sync()\n", "                    fwd_t += time.perf_counter() - t1\n", "                if loss_sum_t is None:\n", "                    loss_sum_t = loss.detach()\n", "                else:\n", "                    loss_sum_t = loss_sum_t + loss.detach()\n", "                # Normalize for gradient accumulation\n", "                loss_to_back = loss / grad_accum\n", "                t2 = time.perf_counter()\n", "                if scaler is not None and scaler.is_enabled():\n", "                    scaler.scale(loss_to_back).backward()\n", "                else:\n", "                    loss_to_back.backward()\n", "                maybe_sync()\n", "                bwd_t += time.perf_counter() - t2\n\n", "            # Backward done -> optimizer step\n", "            t3 = time.perf_counter()\n", "            grad_norm_clip = None\n", "            if scaler is not None and scaler.is_enabled():\n", "                # Unscale before clipping / measuring\n", "                try:\n", "                    scaler.unscale_(opt)\n", "                except Exception:\n", "                    pass\n", "            if args.grad_clip and args.grad_clip > 0:\n", "                grad_norm_clip = float(torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip).detach().to(\"cpu\").item())\n\n", "            # Light-weight grad norm for dashboard/logs\n", "            grad_stats: Dict[str, float] = {}\n", "            if (step % args.log_every) == 0 or step == 1:\n", "                try:\n", "                    grad_stats = compute_grad_norms(model)\n", "                except Exception:\n", "                    grad_stats = {}\n", "            if scaler is not None and scaler.is_enabled():\n", "                scaler.step(opt)\n", "                scaler.update()\n", "            else:\n", "                opt.step()\n", "            maybe_sync()\n", "            opt_t = time.perf_counter() - t3\n", "            maybe_sync()\n", "            step_dt = time.perf_counter() - t_step0\n\n", "            # Update interval accumulators\n", "            tok_count += int(args.batch_size) * seq_len * grad_accum\n", "            dt_acc += step_dt\n", "            data_acc += data_t\n", "            fwd_acc += fwd_t\n", "            bwd_acc += bwd_t\n", "            opt_acc += opt_t\n", "            steps_in_acc += 1\n\n", "            # Eval / analysis checkpoints\n", "            if (step % args.eval_every) == 0 or step == args.steps:\n", "                ev = do_eval(step, seq_len_hint=seq_len)\n", "                val_loss = ev[\"val_loss\"]\n", "                if val_loss < best_val:\n", "                    best_val = val_loss\n", "                    save_ckpt(args.out_dir, \"best.pt\", model, cfg, step, best_val)\n", "                    dashboard.message(f\"new best @ step {step}: val_loss={best_val:.6f}\")\n", "                ev[\"best_val\"] = best_val\n", "                if logger is not None:\n", "                    logger.log(ev)\n", "                dashboard.update_eval(ev)\n", "            if args.analysis_every and (step % args.analysis_every) == 0:\n", "                try:\n", "                    # Use current seq_len (or smaller) to keep analysis cheap\n", "                    ab = min(seq_len, analysis_tokens)\n", "                    xb_a, yb_a = get_batch_any(train_view, batch_size=1, block_size=ab, device=device)\n", "                    analysis_metrics, analysis_tensors = analyze_attention(\n", "                        model,\n", "                        xb_a,\n", "                        layers=analysis_layers,\n", "                        heads=analysis_heads,\n", "                        max_tokens=ab,\n", "                        topk=int(getattr(args, \"analysis_topk\", 8)),\n", "                        local_window=int(getattr(args, \"analysis_local_window\", 32)),\n", "                        save_mats=True,\n", "                        save_scores=bool(getattr(args, \"analysis_save_scores\", False)),\n", "                        compute_svd=True,\n", "                    )\n", "                    if logger is not None:\n", "                        logger.log({\n", "                            \"type\": \"analysis\",\n", "                            \"step\": int(step),\n", "                            **analysis_metrics,\n", "                        })\n", "                        if analysis_tensors:\n", "                            logger.h5_write_step(step, group=\"analysis\", tensors=analysis_tensors, attrs=analysis_metrics)\n", "                except Exception as e:\n", "                    dashboard.message(f\"[warn] analysis failed @ step {step}: {e}\")\n\n", "            # Logging + live dashboard\n", "            if (step % args.log_every) == 0 or step == 1:\n", "                # interval averages\n", "                tok_s = float(tok_count / max(dt_acc, 1e-9))\n", "                if loss_sum_t is None:\n", "                    loss_step = float(\"nan\")\n", "                else:\n", "                    loss_step = float((loss_sum_t / grad_accum).detach().to(\"cpu\").item())\n", "                ppl_step = float(math.exp(loss_step))\n", "                # Memory stats\n", "                mem = get_device_mem_stats(device)\n", "                rss = get_process_rss_bytes()\n", "                if rss is not None:\n", "                    mem[\"cpu_rss_bytes\"] = float(rss)\n", "                # Optimizer state bytes (once)\n", "                nonlocal_opt_state = opt_state_bytes_cached\n", "                if nonlocal_opt_state is None:\n", "                    try:\n", "                        nonlocal_opt_state = optimizer_state_bytes(opt)\n", "                    except Exception:\n", "                        nonlocal_opt_state = -1\n", "                    opt_state_bytes_cached = nonlocal_opt_state\n", "                # AMP scale\n", "                amp_scale = None\n", "                try:\n", "                    if scaler is not None and scaler.is_enabled():\n", "                        amp_scale = float(scaler.get_scale())\n", "                except Exception:\n", "                    amp_scale = None\n", "                evt: Dict[str, Any] = {\n", "                    \"type\": \"train\",\n", "                    \"step\": int(step),\n", "                    \"loss\": loss_step,\n", "                    \"ppl\": ppl_step,\n", "                    \"lr\": float(lr),\n", "                    \"tok_s\": tok_s,\n", "                    \"seq_len\": int(seq_len),\n", "                    \"grad_accum\": int(grad_accum),\n", "                    \"global_batch\": int(global_batch),\n", "                    \"step_ms\": float((dt_acc / max(steps_in_acc, 1)) * 1000.0),\n", "                    \"data_ms\": float((data_acc / max(steps_in_acc, 1)) * 1000.0),\n", "                    \"fwd_ms\": float((fwd_acc / max(steps_in_acc, 1)) * 1000.0),\n", "                    \"bwd_ms\": float((bwd_acc / max(steps_in_acc, 1)) * 1000.0),\n", "                    \"opt_ms\": float((opt_acc / max(steps_in_acc, 1)) * 1000.0),\n", "                    \"grad_clip_norm\": grad_norm_clip,\n", "                    \"opt_state_bytes\": int(opt_state_bytes_cached) if opt_state_bytes_cached is not None else -1,\n", "                }\n", "                if amp_scale is not None:\n", "                    evt[\"amp_scale\"] = amp_scale\n", "                evt.update(mem)\n", "                evt.update(grad_stats)\n", "                if logger is not None:\n", "                    logger.log(evt)\n", "                # Dashboard update (throttled)\n", "                if (step % dash_every) == 0 or step == 1:\n", "                    dashboard.update_train(evt)\n", "                # reset interval accumulators\n", "                tok_count = 0\n", "                dt_acc = 0.0\n", "                data_acc = 0.0\n", "                fwd_acc = 0.0\n", "                bwd_acc = 0.0\n", "                opt_acc = 0.0\n", "                steps_in_acc = 0\n\n", "            # Periodic checkpoint\n", "            if args.save_every and (step % args.save_every) == 0:\n", "                save_ckpt(args.out_dir, f\"step{step}.pt\", model, cfg, step, best_val)\n\n", "        # Save final checkpoint\n", "        save_ckpt(args.out_dir, \"last.pt\", model, cfg, args.steps, best_val)\n", "        if logger is not None:\n", "            logger.finalize(best_val=best_val, last_step=args.steps)\n", "        dashboard.message(\"training complete\")\n", "    finally:\n", "        _dash = locals().get(\"dashboard\", None)\n", "        if _dash is not None:\n", "            try:\n", "                _dash.close()\n", "            except Exception:\n", "                pass\n", "        if logger is not None:\n", "            logger.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}