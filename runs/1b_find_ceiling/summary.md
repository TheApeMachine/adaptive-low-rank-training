# Run Summary

- Created: `2025-12-18T12:43:04+01:00`
- Out dir: `runs/1b_find_ceiling`
- Device: `mps`
- Command: `v29_transformer_decoupled_bottleneck_instrumented.py --mode train --size 1b --attn-mode decoupled --tie-qk --no-null-attn --param-dtype bf16 --amp --amp-dtype bf16 --grad-checkpoint --optimizer lion --lr 1e-4 --lr-schedule cosine --warmup-steps 200 --data fineweb_1b.npy --data-format npy --vocab-size 50257 --steps 50 --eval-every 0 --analysis-every 0 --instrument basic --log-every 1 --batch-size 16 --grad-accum 4 --train-seq-len 2048 --opt-foreach --out-dir=runs/1b_find_ceiling`
- Size preset: `1b`

## Model Config

```json
{
  "attn_dim": 512,
  "attn_mode": "decoupled",
  "block_size": 2048,
  "d_ff": 8192,
  "d_model": 2048,
  "dropout": 0.0,
  "embed_dim": 2048,
  "geo_dim": 64,
  "kv_head": null,
  "learned_temp": true,
  "mlp": "swiglu",
  "n_head": 16,
  "n_layer": 18,
  "null_attn": false,
  "rope": true,
  "rope_base": 10000.0,
  "sem_dim": 32,
  "tie_qk": true,
  "vocab_size": 50257
}
```

## Training Args

```json
{
  "adam_betas": "0.9,0.95",
  "adam_eps": 1e-08,
  "amp": true,
  "amp_dtype": "bf16",
  "analysis_every": 0,
  "analysis_heads": "0",
  "analysis_layers": "0,-1",
  "analysis_local_window": 32,
  "analysis_max_tokens": 256,
  "analysis_save_scores": false,
  "analysis_topk": 8,
  "attn_dim": 512,
  "attn_mode": "decoupled",
  "batch_size": 16,
  "block": 2048,
  "ckpt": null,
  "compile": false,
  "compile_mode": "default",
  "d_ff": 8192,
  "d_model": 2048,
  "data": "fineweb_1b.npy",
  "data_dtype": "uint16",
  "data_format": "npy",
  "device": null,
  "dropout": 0.0,
  "embed_dim": 2048,
  "eval_every": 0,
  "eval_iters": 20,
  "eval_seq_len": 0,
  "exp": null,
  "geo_dim": 64,
  "grad_accum": 4,
  "grad_checkpoint": true,
  "grad_clip": 1.0,
  "instrument": "basic",
  "kv_cache": "fp16",
  "kv_cache_k": null,
  "kv_cache_k_geo": null,
  "kv_cache_k_sem": null,
  "kv_cache_v": null,
  "kv_decode_block": 1024,
  "kv_fused": "auto",
  "kv_head": null,
  "kv_qblock": 32,
  "kv_qblock_k": null,
  "kv_qblock_k_geo": null,
  "kv_qblock_k_sem": null,
  "kv_qblock_v": null,
  "kv_residual": 128,
  "layers": 18,
  "lion_betas": "0.9,0.99",
  "live": "auto",
  "live_plot": false,
  "live_update_every": 1,
  "log_every": 1,
  "lr": 0.0001,
  "lr_schedule": "cosine",
  "matmul_precision": "high",
  "max_new_tokens": 50,
  "min_lr": 0.0,
  "mlp": "swiglu",
  "mode": "train",
  "n_head": 16,
  "no_learned_temp": false,
  "no_null_attn": true,
  "no_rope": false,
  "no_tie_qk": false,
  "null_attn": false,
  "opt_foreach": true,
  "opt_fused": false,
  "optimizer": "lion",
  "out_dir": "runs/1b_find_ceiling",
  "param_dtype": "bf16",
  "print_config": false,
  "prompt_tokens": "0",
  "rope": false,
  "rope_base": 10000.0,
  "run_root": "runs",
  "run_tag": null,
  "save_every": 0,
  "seed": 1337,
  "self_opt": "none",
  "self_opt_block_n": "128",
  "self_opt_cache": null,
  "self_opt_calib_decode": 32,
  "self_opt_calib_prefill": 128,
  "self_opt_calib_tokens": null,
  "self_opt_decode_blocks": "256,512,1024,2048",
  "self_opt_hysteresis": 0.03,
  "self_opt_interval": 256,
  "self_opt_iters": 3,
  "self_opt_k_geo_kinds": "q8_0,q4_0,fp16",
  "self_opt_k_sem_kinds": "q4_0,nf4,q8_0,fp16",
  "self_opt_mem_budget_mb": null,
  "self_opt_mem_overhead_frac": 0.1,
  "self_opt_policy_hysteresis": 0.02,
  "self_opt_policy_iters": 3,
  "self_opt_policy_prefix_len": null,
  "self_opt_policy_quality": false,
  "self_opt_policy_warmup": 1,
  "self_opt_prefer_low_mem_within": 0.02,
  "self_opt_qblocks": "16,32,64",
  "self_opt_quality_delta_nll_tol": 0.02,
  "self_opt_quality_kl": false,
  "self_opt_quality_kl_tol": null,
  "self_opt_quality_ppl_ratio_tol": 1.02,
  "self_opt_quality_tol": 0.5,
  "self_opt_residuals": "0,32,64,128",
  "self_opt_scope": "all",
  "self_opt_stages": "2,3",
  "self_opt_v_kinds": "q4_0,q8_0,fp16",
  "self_opt_verbose": false,
  "self_opt_verify": false,
  "self_opt_verify_tol": 0.005,
  "self_opt_warmup": 1,
  "self_opt_warps": "4,8",
  "sem_dim": 32,
  "seq_schedule": null,
  "size": "1b",
  "steps": 50,
  "sync_timing": false,
  "tb": false,
  "temperature": 1.0,
  "tie_qk": true,
  "tokenizer": "word",
  "top_k": null,
  "train_seq_len": 2048,
  "val_frac": 0.1,
  "vocab_size": 50257,
  "warmup_steps": 200,
  "weight_decay": 0.1
}
```

